{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ELBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xQyYsax2NlCp"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUluMeh8vhFK",
        "outputId": "11d4da13-b11f-4d08-807c-fdade4f3c8b0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zd7BymCwD8a",
        "outputId": "c85d5efb-7183-44f9-cb3f-a1071a8debbf"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY9BrKNmxY21"
      },
      "source": [
        "# BERT 학습을 위한 vocab을 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDOWsss0xfvU"
      },
      "source": [
        "학습에 사용될 vocab을 만들어보겠습니다.\n",
        "\n",
        "아래 코드를 실행하시면, vocab을 만들 수 있습니다.\n",
        "\n",
        "이번 예제에서는 결과를 빠르게 확인하기 위해 iter를 20으로 두었으나, \n",
        "\n",
        "wiki를 기준으로 1000 정도로 iter를 설정하면 대략 30,000 vocab정도 만들어집니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCqqzd2Ox2ih",
        "outputId": "ec33ee19-f36f-4bc9-be3f-8eeb0f35a2c2"
      },
      "source": [
        "!python drive/My\\ Drive/Elegant_Friends/practice/src/make_vocab/wordpiece.py \\\n",
        "--corpus=drive/My\\ Drive/Elegant_Friends/practice/rsc/training_data/service_center_small.txt \\\n",
        "--iter=20 \\\n",
        "--fname=drive/MyDrive/Elegant_Friends/practice/rsc/my_conf/my_vocab.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin vocabulary scanning\rterminated vocabulary scanning\n",
            "('##.', '##.')\n",
            "('##는', '##데')\n",
            "('##니', '##다')\n",
            "('##네', '##요')\n",
            "('##데', '##이')\n",
            "('##데이', '##트')\n",
            "('업', '##데이트')\n",
            "('위', '##젯')\n",
            "('##아', '##요')\n",
            "('##..', '##.')\n",
            "('사', '##용')\n",
            "('##세', '##요')\n",
            "('데', '##이')\n",
            "('##하', '##고')\n",
            "('안', '##되')\n",
            "('데이', '##터')\n",
            "('##들', '##어')\n",
            "('##ㅋ', '##ㅋ')\n",
            "('##니다', '##.')\n",
            "('##!', '##!')\n",
            "('##요', '##?')\n",
            "training bpe was done                                        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyv47UR0SIdd"
      },
      "source": [
        "#BERT 학습을 위한 Preprocessed data 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_UcTWFhSPHS"
      },
      "source": [
        "이제 vocab 이 준비되었으니, BERT 학습을 위한 corpus를 preprocessing 해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM6i3hylSl24",
        "outputId": "06087223-46e9-4f24-d95b-7ed10fc53bbf"
      },
      "source": [
        "!python drive/My\\ Drive/Elegant_Friends/practice/src/make_preprocessed_data/create_pretraining_data.py \\\n",
        "--input_file=drive/My\\ Drive/Elegant_Friends/practice/rsc/training_data/service_center_small.txt \\\n",
        "--vocab_file=drive/My\\ Drive/Elegant_Friends/practice/rsc/my_conf/my_vocab.txt \\\n",
        "--do_lower_case=False \\\n",
        "--max_seq_length=512 \\\n",
        "--output_file=drive/My\\ Drive/Elegant_Friends/practice/rsc/my_preprocessed_training_data/service_center_small_512_tf.record"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-30 08:20:59.249788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"drive/My Drive/Elegant_Friends/practice/src/make_preprocessed_data/create_pretraining_data.py\", line 30, in <module>\n",
            "    flags = tf.flags\n",
            "AttributeError: module 'tensorflow' has no attribute 'flags'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmF713AzWl1B"
      },
      "source": [
        "# BERT 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBl1RNviWrEJ"
      },
      "source": [
        "이제 만들어진 학습 데이터를 이용해서 실제로 BERT를 학습해보도록 하겠습니다.\n",
        "\n",
        "이번 학습에선 앞서 만든 wiki_small이 아니라, 제가 미리 만들어 배포드린 전체 wiki 데이터를 이용해 학습해보겠습니다.\n",
        "\n",
        "참고로, train_batch_size를 4보다 크게 할 경우, colab에서 제공하는 GPU로는 메모리가 부족해서 에러가 발생합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GcqCexeMW7fz",
        "outputId": "034cb0e0-cb84-4d8f-ab48-4d8c947cdfbb"
      },
      "source": [
        "!python drive/My\\ Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py \\\n",
        "--input_file=drive/My\\ Drive/bert_for_practics/t_academy/rsc/preprocessed_training_data/wiki_20190620_512_tf.record \\\n",
        "--output_dir=drive/My\\ Drive/bert_for_practics/t_academy/rsc/my_pretrained_model \\\n",
        "--do_train=True \\\n",
        "--do_eval=True \\\n",
        "--bert_config_file=drive/My\\ Drive/bert_for_practics/t_academy/rsc/my_conf/bert_config.json \\\n",
        "--train_batch_size=4 \\\n",
        "--max_seq_length=512 \\\n",
        "--max_predictions_per_seq=20 \\\n",
        "--num_train_steps=10 \\\n",
        "--learning_rate=1e-4 \\\n",
        "--save_checkpoints_steps=5 \\\n",
        "--do_lower_case=False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0804 16:07:48.198168 140318809827200 deprecation_wrapper.py:119] From /content/drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/optimization.py:84: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0804 16:07:48.199471 140318809827200 deprecation_wrapper.py:119] From drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py:496: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0804 16:07:48.200252 140318809827200 deprecation_wrapper.py:119] From drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py:410: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0804 16:07:48.200482 140318809827200 deprecation_wrapper.py:119] From drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py:410: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0804 16:07:48.200672 140318809827200 deprecation_wrapper.py:119] From /content/drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0804 16:07:48.203277 140318809827200 deprecation_wrapper.py:119] From drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py:417: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0804 16:07:48.203794 140318809827200 deprecation_wrapper.py:119] From drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py:421: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0804 16:07:48.205323 140318809827200 deprecation_wrapper.py:119] From drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py:423: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0804 16:07:48.205482 140318809827200 run_pretraining.py:423] *** Input Files ***\n",
            "I0804 16:07:48.205641 140318809827200 run_pretraining.py:425] input_file_name:  drive/My Drive/bert_for_practics/t_academy/rsc/preprocessed_training_data/wiki_20190620_512_tf.record\n",
            "W0804 16:07:49.552560 140318809827200 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0804 16:07:49.553456 140318809827200 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f9e49ce1620>) includes params argument, but params are not passed to Estimator.\n",
            "I0804 16:07:49.554841 140318809827200 estimator.py:209] Using config: {'_model_dir': 'drive/My Drive/bert_for_practics/t_academy/rsc/my_pretrained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9e3b816550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
            "I0804 16:07:49.555160 140318809827200 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
            "W0804 16:07:49.556042 140318809827200 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.\n",
            "I0804 16:07:49.556231 140318809827200 run_pretraining.py:462] ***** Running training *****\n",
            "I0804 16:07:49.556410 140318809827200 run_pretraining.py:463]   Batch size = 4\n",
            "W0804 16:07:49.574732 140318809827200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0804 16:07:49.587878 140318809827200 deprecation_wrapper.py:119] From drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py:340: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0804 16:07:49.594317 140318809827200 deprecation.py:323] From drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py:371: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0804 16:07:49.594497 140318809827200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0804 16:07:49.621658 140318809827200 deprecation.py:323] From drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py:388: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0804 16:07:49.621823 140318809827200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0804 16:07:49.623466 140318809827200 deprecation_wrapper.py:119] From drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py:396: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0804 16:07:49.629612 140318809827200 deprecation.py:323] From drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py:403: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "I0804 16:07:49.659842 140318809827200 estimator.py:1145] Calling model_fn.\n",
            "I0804 16:07:49.660080 140318809827200 tpu_estimator.py:2965] Running train on CPU\n",
            "I0804 16:07:49.660479 140318809827200 run_pretraining.py:120] *** Features ***\n",
            "I0804 16:07:49.660648 140318809827200 run_pretraining.py:122]   name = input_ids, shape = (4, 512)\n",
            "I0804 16:07:49.660796 140318809827200 run_pretraining.py:122]   name = input_mask, shape = (4, 512)\n",
            "I0804 16:07:49.660957 140318809827200 run_pretraining.py:122]   name = masked_lm_ids, shape = (4, 20)\n",
            "I0804 16:07:49.661100 140318809827200 run_pretraining.py:122]   name = masked_lm_positions, shape = (4, 20)\n",
            "I0804 16:07:49.661239 140318809827200 run_pretraining.py:122]   name = masked_lm_weights, shape = (4, 20)\n",
            "I0804 16:07:49.661393 140318809827200 run_pretraining.py:122]   name = next_sentence_labels, shape = (4, 1)\n",
            "I0804 16:07:49.661536 140318809827200 run_pretraining.py:122]   name = segment_ids, shape = (4, 512)\n",
            "W0804 16:07:49.661823 140318809827200 deprecation_wrapper.py:119] From /content/drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0804 16:07:49.663900 140318809827200 deprecation_wrapper.py:119] From /content/drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/modeling.py:411: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0804 16:07:49.718950 140318809827200 deprecation.py:506] From /content/drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/modeling.py:359: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0804 16:07:49.737046 140318809827200 deprecation.py:323] From /content/drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0804 16:07:50.332789 140318809827200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "I0804 16:07:52.894136 140318809827200 run_pretraining.py:170] **** Trainable Variables ****\n",
            "I0804 16:07:52.894360 140318809827200 run_pretraining.py:176]   name = bert/embeddings/word_embeddings:0, shape = (49541, 768)\n",
            "I0804 16:07:52.894539 140318809827200 run_pretraining.py:176]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "I0804 16:07:52.894738 140318809827200 run_pretraining.py:176]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "I0804 16:07:52.894904 140318809827200 run_pretraining.py:176]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.895058 140318809827200 run_pretraining.py:176]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.895210 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.895395 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:07:52.895565 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.895719 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:07:52.895869 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.896028 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:07:52.896163 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.896313 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.896444 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.896583 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.896748 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:07:52.896919 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:07:52.897073 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:07:52.897206 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.897363 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.897490 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.897633 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.897761 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:07:52.897959 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.898114 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:07:52.898241 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.898421 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:07:52.898583 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.898742 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.898883 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.899019 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.899163 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:07:52.899337 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:07:52.899466 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:07:52.899661 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.899875 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.900063 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.900184 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.900322 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:07:52.900470 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.900593 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:07:52.900762 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.900911 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:07:52.901052 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.901186 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.901316 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.901451 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.901632 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:07:52.901800 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:07:52.901958 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:07:52.902121 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.902246 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.902372 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.902498 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.902640 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:07:52.902768 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.902911 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:07:52.903049 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.903180 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:07:52.903307 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.903438 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.903566 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.903693 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.903882 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:07:52.904050 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:07:52.904179 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:07:52.904309 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.904434 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.904568 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.904696 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.904824 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:07:52.904995 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.905128 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:07:52.905255 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.905383 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:07:52.905525 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.905664 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.905806 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.905954 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.906085 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:07:52.906355 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:07:52.906496 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:07:52.906649 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.906782 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.906917 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.907067 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.907230 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:07:52.907392 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.907524 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:07:52.907652 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.907780 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:07:52.907923 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.908063 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.908187 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.908311 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.908445 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:07:52.908602 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:07:52.908732 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:07:52.908896 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.909040 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.909163 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.909346 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.909507 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:07:52.909652 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.909780 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:07:52.909921 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.910061 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:07:52.910198 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.910341 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.910481 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.910604 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.910727 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:07:52.910868 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:07:52.911005 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:07:52.911133 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.911254 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.911375 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.911499 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.911649 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:07:52.911803 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.911978 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:07:52.912109 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.912234 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:07:52.982163 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.982357 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.982535 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.982705 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.982930 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:07:52.983193 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:07:52.983452 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:07:52.983676 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.983896 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.984165 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.984387 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.984566 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:07:52.984794 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.985127 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:07:52.985395 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.985576 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:07:52.985767 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.985985 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.986163 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.986372 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.986585 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:07:52.986766 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:07:52.986977 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:07:52.987159 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.987331 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.987524 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.987704 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.987924 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:07:52.988131 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.988359 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:07:52.988572 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.988811 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:07:52.989113 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.989307 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.989479 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.989678 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.989930 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:07:52.990162 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:07:52.990341 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:07:52.990520 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.990694 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.990918 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.991173 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.991393 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:07:52.991574 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.991760 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:07:52.991981 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.992164 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:07:52.992342 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.992531 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.992717 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.992952 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.993163 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:07:52.993361 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:07:52.993545 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:07:52.993753 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.994011 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.994216 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.994418 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.994630 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:07:52.994803 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.995039 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:07:52.995266 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.995497 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:07:52.995733 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.995963 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.996222 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.996442 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.996696 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:07:52.996999 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:07:52.997318 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:07:52.997628 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.997935 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.998252 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:52.998699 140318809827200 run_pretraining.py:176]   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.998912 140318809827200 run_pretraining.py:176]   name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.999174 140318809827200 run_pretraining.py:176]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:07:52.999489 140318809827200 run_pretraining.py:176]   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
            "I0804 16:07:52.999721 140318809827200 run_pretraining.py:176]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:07:52.999919 140318809827200 run_pretraining.py:176]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:07:53.000108 140318809827200 run_pretraining.py:176]   name = cls/predictions/output_bias:0, shape = (49541,)\n",
            "I0804 16:07:53.000293 140318809827200 run_pretraining.py:176]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "I0804 16:07:53.000506 140318809827200 run_pretraining.py:176]   name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "W0804 16:07:53.000753 140318809827200 deprecation_wrapper.py:119] From /content/drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0804 16:07:53.002025 140318809827200 deprecation_wrapper.py:119] From /content/drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0804 16:07:53.007714 140318809827200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0804 16:07:56.998507 140318809827200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "I0804 16:08:02.662749 140318809827200 estimator.py:1147] Done calling model_fn.\n",
            "I0804 16:08:02.664541 140318809827200 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0804 16:08:06.148581 140318809827200 monitored_session.py:240] Graph was finalized.\n",
            "2019-08-04 16:08:06.154252: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-08-04 16:08:06.154540: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x288cf40 executing computations on platform Host. Devices:\n",
            "2019-08-04 16:08:06.154577: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-04 16:08:06.169531: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-04 16:08:06.264567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-04 16:08:06.265153: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x288d9c0 executing computations on platform CUDA. Devices:\n",
            "2019-08-04 16:08:06.265186: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-08-04 16:08:06.265400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-04 16:08:06.265746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-04 16:08:06.269406: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-04 16:08:06.275367: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-04 16:08:06.279025: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-04 16:08:06.286511: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-04 16:08:06.295339: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-04 16:08:06.300801: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-04 16:08:06.322064: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-04 16:08:06.322206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-04 16:08:06.322629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-04 16:08:06.322998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-04 16:08:06.323066: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-04 16:08:06.324178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-04 16:08:06.324210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-04 16:08:06.324226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-04 16:08:06.324527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-04 16:08:06.324948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-04 16:08:06.325312: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-08-04 16:08:06.325434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0804 16:08:06.328614 140318809827200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0804 16:08:06.330746 140318809827200 saver.py:1280] Restoring parameters from drive/My Drive/bert_for_practics/t_academy/rsc/my_pretrained_model/model.ckpt-0\n",
            "W0804 16:08:12.328297 140318809827200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "2019-08-04 16:08:12.911531: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "I0804 16:08:12.988477 140318809827200 session_manager.py:500] Running local_init_op.\n",
            "I0804 16:08:13.136305 140318809827200 session_manager.py:502] Done running local_init_op.\n",
            "I0804 16:08:20.244336 140318809827200 basic_session_run_hooks.py:606] Saving checkpoints for 0 into drive/My Drive/bert_for_practics/t_academy/rsc/my_pretrained_model/model.ckpt.\n",
            "2019-08-04 16:08:39.650069: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "I0804 16:08:56.036216 140318809827200 tpu_estimator.py:2159] global_step/sec: 0.0686212\n",
            "I0804 16:08:56.037184 140318809827200 tpu_estimator.py:2160] examples/sec: 0.274485\n",
            "I0804 16:08:57.091719 140318809827200 tpu_estimator.py:2159] global_step/sec: 0.947431\n",
            "I0804 16:08:57.092249 140318809827200 tpu_estimator.py:2160] examples/sec: 3.78972\n",
            "I0804 16:08:58.154702 140318809827200 tpu_estimator.py:2159] global_step/sec: 0.940709\n",
            "I0804 16:08:58.155161 140318809827200 tpu_estimator.py:2160] examples/sec: 3.76283\n",
            "I0804 16:08:59.377439 140318809827200 basic_session_run_hooks.py:606] Saving checkpoints for 5 into drive/My Drive/bert_for_practics/t_academy/rsc/my_pretrained_model/model.ckpt.\n",
            "I0804 16:09:16.114013 140318809827200 tpu_estimator.py:2159] global_step/sec: 0.0556816\n",
            "I0804 16:09:16.114295 140318809827200 tpu_estimator.py:2160] examples/sec: 0.222727\n",
            "I0804 16:09:17.310117 140318809827200 tpu_estimator.py:2159] global_step/sec: 0.836007\n",
            "I0804 16:09:17.310341 140318809827200 tpu_estimator.py:2160] examples/sec: 3.34403\n",
            "I0804 16:09:18.371519 140318809827200 tpu_estimator.py:2159] global_step/sec: 0.9422\n",
            "I0804 16:09:18.372129 140318809827200 tpu_estimator.py:2160] examples/sec: 3.7688\n",
            "I0804 16:09:19.444218 140318809827200 tpu_estimator.py:2159] global_step/sec: 0.932237\n",
            "I0804 16:09:19.444792 140318809827200 tpu_estimator.py:2160] examples/sec: 3.72895\n",
            "I0804 16:09:20.585207 140318809827200 tpu_estimator.py:2159] global_step/sec: 0.87643\n",
            "I0804 16:09:20.585602 140318809827200 tpu_estimator.py:2160] examples/sec: 3.50572\n",
            "I0804 16:09:21.655581 140318809827200 basic_session_run_hooks.py:606] Saving checkpoints for 10 into drive/My Drive/bert_for_practics/t_academy/rsc/my_pretrained_model/model.ckpt.\n",
            "I0804 16:09:34.902907 140318809827200 tpu_estimator.py:2159] global_step/sec: 0.0698434\n",
            "I0804 16:09:34.903220 140318809827200 tpu_estimator.py:2160] examples/sec: 0.279374\n",
            "I0804 16:09:35.117548 140318809827200 estimator.py:368] Loss for final step: 11.68679.\n",
            "I0804 16:09:35.118536 140318809827200 error_handling.py:96] training_loop marked as finished\n",
            "I0804 16:09:35.118716 140318809827200 run_pretraining.py:472] ***** Running evaluation *****\n",
            "I0804 16:09:35.118884 140318809827200 run_pretraining.py:473]   Batch size = 8\n",
            "I0804 16:09:35.181179 140318809827200 estimator.py:1145] Calling model_fn.\n",
            "I0804 16:09:35.181586 140318809827200 tpu_estimator.py:2965] Running eval on CPU\n",
            "I0804 16:09:35.182309 140318809827200 run_pretraining.py:120] *** Features ***\n",
            "I0804 16:09:35.182537 140318809827200 run_pretraining.py:122]   name = input_ids, shape = (8, 512)\n",
            "I0804 16:09:35.182781 140318809827200 run_pretraining.py:122]   name = input_mask, shape = (8, 512)\n",
            "I0804 16:09:35.183084 140318809827200 run_pretraining.py:122]   name = masked_lm_ids, shape = (8, 20)\n",
            "I0804 16:09:35.183298 140318809827200 run_pretraining.py:122]   name = masked_lm_positions, shape = (8, 20)\n",
            "I0804 16:09:35.183550 140318809827200 run_pretraining.py:122]   name = masked_lm_weights, shape = (8, 20)\n",
            "I0804 16:09:35.183747 140318809827200 run_pretraining.py:122]   name = next_sentence_labels, shape = (8, 1)\n",
            "I0804 16:09:35.183951 140318809827200 run_pretraining.py:122]   name = segment_ids, shape = (8, 512)\n",
            "I0804 16:09:37.817736 140318809827200 run_pretraining.py:170] **** Trainable Variables ****\n",
            "I0804 16:09:37.818023 140318809827200 run_pretraining.py:176]   name = bert/embeddings/word_embeddings:0, shape = (49541, 768)\n",
            "I0804 16:09:37.818188 140318809827200 run_pretraining.py:176]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "I0804 16:09:37.818361 140318809827200 run_pretraining.py:176]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "I0804 16:09:37.818487 140318809827200 run_pretraining.py:176]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.818639 140318809827200 run_pretraining.py:176]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.818787 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.818998 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:09:37.819150 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.819314 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:09:37.819463 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.819588 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:09:37.819710 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.819863 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.819992 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.820158 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.820286 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:09:37.820452 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:09:37.820575 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:09:37.820698 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.820819 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.820956 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.821078 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.821200 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:09:37.821321 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.821450 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:09:37.821604 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.821731 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:09:37.821900 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.822026 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.822144 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.822262 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.822388 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:09:37.822528 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:09:37.822668 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:09:37.822865 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.822991 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.823137 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.823279 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.823447 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:09:37.823601 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.823738 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:09:37.823890 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.824116 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:09:37.824266 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.824428 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.824609 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.824741 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.824900 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:09:37.825034 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:09:37.825223 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:09:37.825409 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.825633 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.825776 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.825968 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.826114 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:09:37.826303 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.826434 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:09:37.826557 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.826681 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:09:37.826804 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.826966 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.827090 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.827210 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.827334 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:09:37.827476 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:09:37.827616 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:09:37.827757 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.827910 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.828032 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.828168 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.828294 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:09:37.828453 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.828584 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:09:37.828736 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.828875 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:09:37.829016 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.829156 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.829278 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.829419 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.829627 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:09:37.829761 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:09:37.829947 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:09:37.830125 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.830282 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.830443 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.830567 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.830691 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:09:37.830827 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.830975 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:09:37.831099 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.831236 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:09:37.831413 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.831539 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.831688 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.831804 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.831959 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:09:37.832098 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:09:37.832218 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:09:37.832361 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.832499 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.832650 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.832789 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.832944 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:09:37.833065 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.833187 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:09:37.833306 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.833434 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:09:37.833603 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.833756 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.833924 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.834060 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.834179 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:09:37.834302 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:09:37.834431 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:09:37.834567 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.834718 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.834875 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.835050 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.835172 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:09:37.835291 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.835418 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:09:37.835537 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.835657 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:09:37.888316 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.888553 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.888765 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.888969 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.889154 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:09:37.889340 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:09:37.889572 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:09:37.889766 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.889973 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.890161 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.890399 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.890609 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:09:37.890799 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.891005 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:09:37.891173 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.891344 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:09:37.891525 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.891698 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.891883 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.892051 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.892218 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:09:37.892398 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:09:37.892568 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:09:37.892759 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.892991 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.893177 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.893370 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.893543 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:09:37.893763 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.893979 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:09:37.894179 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.894413 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:09:37.894633 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.894817 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.895009 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.895221 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.895464 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:09:37.895697 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:09:37.895909 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:09:37.896099 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.896267 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.896458 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.896646 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.896830 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:09:37.897026 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.897212 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:09:37.897387 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.897560 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:09:37.897728 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.897917 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.898084 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.898263 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.898460 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:09:37.898676 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:09:37.898900 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:09:37.899109 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.899275 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.899449 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.899616 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.899782 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "I0804 16:09:37.900002 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.900195 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "I0804 16:09:37.900443 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.900654 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "I0804 16:09:37.900911 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.901130 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.901331 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.901563 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.901760 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0804 16:09:37.902010 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0804 16:09:37.902258 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0804 16:09:37.902439 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.902642 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.902879 140318809827200 run_pretraining.py:176]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.903082 140318809827200 run_pretraining.py:176]   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.903261 140318809827200 run_pretraining.py:176]   name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.903453 140318809827200 run_pretraining.py:176]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
            "I0804 16:09:37.903667 140318809827200 run_pretraining.py:176]   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
            "I0804 16:09:37.903873 140318809827200 run_pretraining.py:176]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
            "I0804 16:09:37.904058 140318809827200 run_pretraining.py:176]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
            "I0804 16:09:37.904238 140318809827200 run_pretraining.py:176]   name = cls/predictions/output_bias:0, shape = (49541,)\n",
            "I0804 16:09:37.904448 140318809827200 run_pretraining.py:176]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "I0804 16:09:37.904638 140318809827200 run_pretraining.py:176]   name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "W0804 16:09:37.913483 140318809827200 deprecation_wrapper.py:119] From drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py:201: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "W0804 16:09:37.930908 140318809827200 deprecation_wrapper.py:119] From drive/My Drive/bert_for_practics/t_academy/src/make_bert_model/run_pretraining.py:205: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "I0804 16:09:37.991643 140318809827200 estimator.py:1147] Done calling model_fn.\n",
            "I0804 16:09:38.015900 140318809827200 evaluation.py:255] Starting evaluation at 2019-08-04T16:09:38Z\n",
            "I0804 16:09:38.633633 140318809827200 monitored_session.py:240] Graph was finalized.\n",
            "2019-08-04 16:09:38.634453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-04 16:09:38.634882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-04 16:09:38.635004: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-04 16:09:38.635044: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-04 16:09:38.635081: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-04 16:09:38.635117: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-04 16:09:38.635159: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-04 16:09:38.635207: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-04 16:09:38.635243: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-04 16:09:38.635386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-04 16:09:38.635719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-04 16:09:38.635983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-04 16:09:38.636039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-04 16:09:38.636059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-04 16:09:38.636074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-04 16:09:38.636277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-04 16:09:38.636604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-04 16:09:38.636873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "I0804 16:09:38.639749 140318809827200 saver.py:1280] Restoring parameters from drive/My Drive/bert_for_practics/t_academy/rsc/my_pretrained_model/model.ckpt-10\n",
            "I0804 16:09:40.013061 140318809827200 session_manager.py:500] Running local_init_op.\n",
            "I0804 16:09:40.065443 140318809827200 session_manager.py:502] Done running local_init_op.\n",
            "I0804 16:09:46.859243 140318809827200 evaluation.py:167] Evaluation [10/100]\n",
            "I0804 16:09:52.989824 140318809827200 evaluation.py:167] Evaluation [20/100]\n",
            "I0804 16:09:59.160028 140318809827200 evaluation.py:167] Evaluation [30/100]\n",
            "I0804 16:10:05.352177 140318809827200 evaluation.py:167] Evaluation [40/100]\n",
            "I0804 16:10:11.646096 140318809827200 evaluation.py:167] Evaluation [50/100]\n",
            "I0804 16:10:17.847025 140318809827200 evaluation.py:167] Evaluation [60/100]\n",
            "I0804 16:10:24.168485 140318809827200 evaluation.py:167] Evaluation [70/100]\n",
            "I0804 16:10:30.406323 140318809827200 evaluation.py:167] Evaluation [80/100]\n",
            "I0804 16:10:36.680615 140318809827200 evaluation.py:167] Evaluation [90/100]\n",
            "I0804 16:10:42.962445 140318809827200 evaluation.py:167] Evaluation [100/100]\n",
            "I0804 16:10:43.056548 140318809827200 evaluation.py:275] Finished evaluation at 2019-08-04-16:10:43\n",
            "I0804 16:10:43.056896 140318809827200 estimator.py:2039] Saving dict for global step 10: global_step = 10, loss = 11.629292, masked_lm_accuracy = 0.0, masked_lm_loss = 10.944028, next_sentence_accuracy = 0.5725, next_sentence_loss = 0.68523407\n",
            "I0804 16:10:43.499190 140318809827200 estimator.py:2099] Saving 'checkpoint_path' summary for global step 10: drive/My Drive/bert_for_practics/t_academy/rsc/my_pretrained_model/model.ckpt-10\n",
            "I0804 16:10:43.500309 140318809827200 error_handling.py:96] evaluation_loop marked as finished\n",
            "I0804 16:10:43.500593 140318809827200 run_pretraining.py:486] ***** Eval results *****\n",
            "I0804 16:10:43.500724 140318809827200 run_pretraining.py:488]   global_step = 10\n",
            "I0804 16:10:43.505882 140318809827200 run_pretraining.py:488]   loss = 11.629292\n",
            "I0804 16:10:43.506028 140318809827200 run_pretraining.py:488]   masked_lm_accuracy = 0.0\n",
            "I0804 16:10:43.506148 140318809827200 run_pretraining.py:488]   masked_lm_loss = 10.944028\n",
            "I0804 16:10:43.506258 140318809827200 run_pretraining.py:488]   next_sentence_accuracy = 0.5725\n",
            "I0804 16:10:43.506380 140318809827200 run_pretraining.py:488]   next_sentence_loss = 0.68523407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEbC-RxlBZkl"
      },
      "source": [
        "# BERT 감정 데이터 분류 실습\n",
        "******이 부분 해보깅*********"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQyYsax2NlCp"
      },
      "source": [
        "## 패키지 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6g7_3aFtvUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f2cce7-b72d-46e7-9779-9a99870112ef"
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip uninstall keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.4.1.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "y\n",
            "y\n",
            "y\n",
            "  Successfully uninstalled tensorflow-2.4.1\n",
            "Uninstalling Keras-2.4.3:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/Keras-2.4.3.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/docs/*\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/docs/md_autogen.py\n",
            "    /usr/local/lib/python3.7/dist-packages/docs/update_docs.py\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled Keras-2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jslC1eNvgqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e343f75a-7624-4b9c-bf02-b9541b447252"
      },
      "source": [
        "!pip install tensorflow==1.14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 104kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.12.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.19.5)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 38.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (54.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires keras>=2.0.0, which is not installed.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIgDOnqjNcbL"
      },
      "source": [
        "## Service center app 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r99q1AnGXdH",
        "outputId": "92b8ea2a-2701-44c6-d811-182b6a386ea5"
      },
      "source": [
        "!python drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py \\\n",
        "--task_name=nsmc \\\n",
        "--do_train=true \\\n",
        "--do_predict=true \\\n",
        "--do_eval=true \\\n",
        "--data_dir=drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/nsmc/service_center \\\n",
        "--vocab_file=drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/T_conf/vocab.txt \\\n",
        "--bert_config_file=drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/T_conf/bert_config.json \\\n",
        "--init_checkpoint=drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/pretrained_model/wiki/model_output_512_model.ckpt-200000 \\\n",
        "--max_seq_length=128 \\\n",
        "--train_batch_size=32 \\\n",
        "--num_train_epochs=3.0 \\\n",
        "--learning_rate=3e-5 \\\n",
        "--do_lower_case=false \\\n",
        "--output_dir=drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/optimization.py:84: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:954: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:783: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0407 12:30:44.678355 139835423807360 deprecation_wrapper.py:119] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:783: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:783: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0407 12:30:44.678630 139835423807360 deprecation_wrapper.py:119] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:783: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0407 12:30:44.678886 139835423807360 deprecation_wrapper.py:119] From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:805: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0407 12:30:44.680779 139835423807360 deprecation_wrapper.py:119] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:805: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "I0407 12:30:46.558328 139835423807360 utils.py:157] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0407 12:30:47.028060 139835423807360 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:180: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0407 12:30:47.028622 139835423807360 deprecation_wrapper.py:119] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:180: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2db675c8c0>) includes params argument, but params are not passed to Estimator.\n",
            "W0407 12:30:47.852048 139835423807360 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2db675c8c0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output/pre_training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2db6b9d410>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
            "I0407 12:30:47.853094 139835423807360 estimator.py:209] Using config: {'_model_dir': 'drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output/pre_training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2db6b9d410>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "I0407 12:30:47.853431 139835423807360 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "W0407 12:30:47.853677 139835423807360 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:495: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0407 12:30:47.853898 139835423807360 deprecation_wrapper.py:119] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:495: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:499: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0407 12:30:47.856571 139835423807360 deprecation_wrapper.py:119] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:499: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Writing example 0 of 10001\n",
            "I0407 12:30:47.856755 139835423807360 run_classifier.py:499] Writing example 0 of 10001\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 12:30:47.857785 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: train-0\n",
            "I0407 12:30:47.857945 139835423807360 run_classifier.py:475] guid: train-0\n",
            "INFO:tensorflow:tokens: [CLS] 데이 ##타 ##속 ##토 너무너무 ##느 ##립 ##니 ##다 ##. 집 ##에 kt ##인터넷 ##와이 ##파이 ##쓰 ##는 ##데 와이파이 ##없 ##으면 폰 ##업 ##뎃 ##도 [UNK] 집 ##밖 ##에 ##나오 ##면 속 ##터 ##져 ##죽 ##을 ##지 ##경 ##. 5 ##G ##는 아예 [UNK] 8 ##하 ##던지 핸드폰 ##에 ##서 5 ##G ##이 ##름 ##박 ##은 ##거 빼 ##고 요금 ##제도 LTE ##요금 ##제 ##로 쓰 ##게 ##하 ##세 ##요 ##. 양심 ##이 있 ##으면 이런 인터넷 ##속 ##도로 5 ##G ##라고 둔갑 ##해 ##서 이런 ##비 ##싼 ##요금 받 ##으면 ##안 ##되 ##죠 ##. 안 ##그 ##래 ##요 ##? 통신망 ##을 늘리 ##던지 개선 ##하 ##던지 ##. ##. ##회 ##원 ##들 다 빠져나가 ##면 그때 ##서 ##야 고치 ##던지 알아 ##서 ##하 ##세 ##요 [SEP]\n",
            "I0407 12:30:47.858103 139835423807360 run_classifier.py:477] tokens: [CLS] 데이 ##타 ##속 ##토 너무너무 ##느 ##립 ##니 ##다 ##. 집 ##에 kt ##인터넷 ##와이 ##파이 ##쓰 ##는 ##데 와이파이 ##없 ##으면 폰 ##업 ##뎃 ##도 [UNK] 집 ##밖 ##에 ##나오 ##면 속 ##터 ##져 ##죽 ##을 ##지 ##경 ##. 5 ##G ##는 아예 [UNK] 8 ##하 ##던지 핸드폰 ##에 ##서 5 ##G ##이 ##름 ##박 ##은 ##거 빼 ##고 요금 ##제도 LTE ##요금 ##제 ##로 쓰 ##게 ##하 ##세 ##요 ##. 양심 ##이 있 ##으면 이런 인터넷 ##속 ##도로 5 ##G ##라고 둔갑 ##해 ##서 이런 ##비 ##싼 ##요금 받 ##으면 ##안 ##되 ##죠 ##. 안 ##그 ##래 ##요 ##? 통신망 ##을 늘리 ##던지 개선 ##하 ##던지 ##. ##. ##회 ##원 ##들 다 빠져나가 ##면 그때 ##서 ##야 고치 ##던지 알아 ##서 ##하 ##세 ##요 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4571 2686 4929 4723 34702 18410 9541 3052 3305 37606 521 4498 23618 29562 35093 30239 10763 12333 6029 8946 8466 41271 4373 2670 45857 1701 100 521 23134 4498 43357 2754 454 3450 7075 14663 9506 1161 2621 37606 174 7398 12333 4077 100 200 2283 29738 18257 4498 2003 174 7398 1291 7806 5250 4155 5820 2794 1590 1615 29871 3274 42019 2389 1834 949 7228 2283 2960 5721 37606 7885 1291 122 41271 562 889 4929 30493 174 7398 35693 28169 3074 2003 562 1673 27168 42019 177 41271 2838 32143 32059 37606 273 5353 7050 5721 20689 11170 9506 3268 29738 502 2283 29738 37606 37606 2307 1611 4496 107 9250 2754 2700 2003 4545 12663 29738 14102 2003 2283 2960 5721 102\n",
            "I0407 12:30:47.858276 139835423807360 run_classifier.py:478] input_ids: 101 4571 2686 4929 4723 34702 18410 9541 3052 3305 37606 521 4498 23618 29562 35093 30239 10763 12333 6029 8946 8466 41271 4373 2670 45857 1701 100 521 23134 4498 43357 2754 454 3450 7075 14663 9506 1161 2621 37606 174 7398 12333 4077 100 200 2283 29738 18257 4498 2003 174 7398 1291 7806 5250 4155 5820 2794 1590 1615 29871 3274 42019 2389 1834 949 7228 2283 2960 5721 37606 7885 1291 122 41271 562 889 4929 30493 174 7398 35693 28169 3074 2003 562 1673 27168 42019 177 41271 2838 32143 32059 37606 273 5353 7050 5721 20689 11170 9506 3268 29738 502 2283 29738 37606 37606 2307 1611 4496 107 9250 2754 2700 2003 4545 12663 29738 14102 2003 2283 2960 5721 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0407 12:30:47.858427 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 12:30:47.858570 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 12:30:47.858670 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 12:30:47.859749 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: train-1\n",
            "I0407 12:30:47.859921 139835423807360 run_classifier.py:475] guid: train-1\n",
            "INFO:tensorflow:tokens: [CLS] 결제 ##정보 ##를 변경 ##하 ##려 ##고 ##하 ##는 ##데 [UNK] 통신망 이용 ##고 ##객 ##이 아니 ##면 인증 ##할 방법 ##이 없 ##네요 ##. ##( ##x ##같 ##은 아이 ##핀 인증 ##은 [UNK] PC ##로 접속 ##하 ##는 홈페이지 ##에 ##서 ##도 언제 ##적 N ##PA ##PI 설정 ##을 [UNK] N ##PS ##KC ##om ##m 플러그 ##인 ##은 검색 ##해 ##도 안나 ##옵 ##니 ##다 ##. UI ##만 리 ##뉴 ##얼 ##하면 뭐 ##합 ##니까 ##. 사용 ##하 ##는 ##데 답답 ##해 ##서 글 남 ##깁 ##니 ##다 ##. [SEP]\n",
            "I0407 12:30:47.860065 139835423807360 run_classifier.py:477] tokens: [CLS] 결제 ##정보 ##를 변경 ##하 ##려 ##고 ##하 ##는 ##데 [UNK] 통신망 이용 ##고 ##객 ##이 아니 ##면 인증 ##할 방법 ##이 없 ##네요 ##. ##( ##x ##같 ##은 아이 ##핀 인증 ##은 [UNK] PC ##로 접속 ##하 ##는 홈페이지 ##에 ##서 ##도 언제 ##적 N ##PA ##PI 설정 ##을 [UNK] N ##PS ##KC ##om ##m 플러그 ##인 ##은 검색 ##해 ##도 안나 ##옵 ##니 ##다 ##. UI ##만 리 ##뉴 ##얼 ##하면 뭐 ##합 ##니까 ##. 사용 ##하 ##는 ##데 답답 ##해 ##서 글 남 ##깁 ##니 ##다 ##. [SEP]\n",
            "INFO:tensorflow:input_ids: 101 3160 19917 8072 1141 2283 4250 1590 2283 12333 6029 100 11170 504 1590 7853 1291 266 2754 1616 6914 1099 1291 181 35405 37606 36369 11635 31305 4155 780 13717 1616 4155 100 1848 1834 3545 2283 12333 1059 4498 2003 1701 1723 5259 3296 25876 42392 2272 9506 100 3296 30698 41313 13506 4718 20253 1340 4155 2448 3074 1701 16094 22584 3052 3305 37606 13316 2582 1434 27095 9322 22194 2681 6011 25400 37606 440 2283 12333 6029 7501 3074 2003 676 553 20283 3052 3305 37606 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 12:30:47.860235 139835423807360 run_classifier.py:478] input_ids: 101 3160 19917 8072 1141 2283 4250 1590 2283 12333 6029 100 11170 504 1590 7853 1291 266 2754 1616 6914 1099 1291 181 35405 37606 36369 11635 31305 4155 780 13717 1616 4155 100 1848 1834 3545 2283 12333 1059 4498 2003 1701 1723 5259 3296 25876 42392 2272 9506 100 3296 30698 41313 13506 4718 20253 1340 4155 2448 3074 1701 16094 22584 3052 3305 37606 13316 2582 1434 27095 9322 22194 2681 6011 25400 37606 440 2283 12333 6029 7501 3074 2003 676 553 20283 3052 3305 37606 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 12:30:47.860384 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 12:30:47.860524 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 12:30:47.860625 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 12:30:47.861272 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: train-2\n",
            "I0407 12:30:47.861406 139835423807360 run_classifier.py:475] guid: train-2\n",
            "INFO:tensorflow:tokens: [CLS] 유플러스 봇 아이콘 ##이 보고자 ##하 ##는 정보 ##를 가리 ##고 있 ##어 ##서 어떻 ##게 해 ##도 화면 ##을 볼 수 ##가 없 ##습 ##니 ##다 ##. 상식 ##적 ##으로 이런 아이콘 ##은 위치 이동 ##이 가능 ##해 ##야 하 ##지 않 ##나 ##요 ##? [SEP]\n",
            "I0407 12:30:47.861528 139835423807360 run_classifier.py:477] tokens: [CLS] 유플러스 봇 아이콘 ##이 보고자 ##하 ##는 정보 ##를 가리 ##고 있 ##어 ##서 어떻 ##게 해 ##도 화면 ##을 볼 수 ##가 없 ##습 ##니 ##다 ##. 상식 ##적 ##으로 이런 아이콘 ##은 위치 이동 ##이 가능 ##해 ##야 하 ##지 않 ##나 ##요 ##? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 5406 49313 4257 1291 46980 2283 12333 395 8072 3360 1590 122 2479 2003 1027 7228 134 1701 1422 9506 577 152 1952 181 7597 3052 3305 37606 4951 5259 44942 562 4257 4155 992 1235 1291 279 3074 4545 116 1161 167 2353 5721 20689 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 12:30:47.861686 139835423807360 run_classifier.py:478] input_ids: 101 5406 49313 4257 1291 46980 2283 12333 395 8072 3360 1590 122 2479 2003 1027 7228 134 1701 1422 9506 577 152 1952 181 7597 3052 3305 37606 4951 5259 44942 562 4257 4155 992 1235 1291 279 3074 4545 116 1161 167 2353 5721 20689 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 12:30:47.861837 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 12:30:47.861992 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 12:30:47.862081 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 12:30:47.863239 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: train-3\n",
            "I0407 12:30:47.863378 139835423807360 run_classifier.py:475] guid: train-3\n",
            "INFO:tensorflow:tokens: [CLS] 별 한 ##개 ##도 [UNK] 약정 ##때 ##는 6 ##기 ##가 사용 ##중 ##에 매달 5 ##기 ##가 ##만 쓰 ##고 1 ##기 ##가 ##는 그냥 [UNK] 약정 ##후 ##에 [UNK] 기기 ##값 잔금 남아 ##서 1 ##년 ##약 ##정 ##으로 쓰 ##고 있 ##는 ##데 매달 5 ##기 ##가 ##로 한 ##달 ##을 썼 ##는 ##데 1 ##년 ##약 ##정 ##후 ##에 ##는 10 ##일 ##만 ##에 6 ##기 ##가 오 ##링 ##되 ##고 . ##6 ##기 ##가 리필 ##받아 ##서 또 10 ##일 ##되 ##면 오 ##링 ##된 ##다 ##. ##인터넷 ##검색 ##이 ##나 동영상 ##을 항상 똑같이 보 ##는 ##데 1 ##년 ##약 ##정 한 ##후 ##에 ##는 데이 ##타 ##는 깎 ##이 ##는 ##데 검색 연결 ##은 [UNK] 연결 ##되 ##니 한 [SEP]\n",
            "I0407 12:30:47.863528 139835423807360 run_classifier.py:477] tokens: [CLS] 별 한 ##개 ##도 [UNK] 약정 ##때 ##는 6 ##기 ##가 사용 ##중 ##에 매달 5 ##기 ##가 ##만 쓰 ##고 1 ##기 ##가 ##는 그냥 [UNK] 약정 ##후 ##에 [UNK] 기기 ##값 잔금 남아 ##서 1 ##년 ##약 ##정 ##으로 쓰 ##고 있 ##는 ##데 매달 5 ##기 ##가 ##로 한 ##달 ##을 썼 ##는 ##데 1 ##년 ##약 ##정 ##후 ##에 ##는 10 ##일 ##만 ##에 6 ##기 ##가 오 ##링 ##되 ##고 . ##6 ##기 ##가 리필 ##받아 ##서 또 10 ##일 ##되 ##면 오 ##링 ##된 ##다 ##. ##인터넷 ##검색 ##이 ##나 동영상 ##을 항상 똑같이 보 ##는 ##데 1 ##년 ##약 ##정 한 ##후 ##에 ##는 데이 ##타 ##는 깎 ##이 ##는 ##데 검색 연결 ##은 [UNK] 연결 ##되 ##니 한 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 411 118 4722 1701 100 5587 11802 12333 195 1261 1952 440 2782 4498 5874 174 1261 1952 2582 949 1590 137 1261 1952 12333 3396 100 5587 5914 4498 100 1526 13768 10433 21193 2003 137 7213 5174 2514 44942 949 1590 122 12333 6029 5874 174 1261 1952 1834 118 5339 9506 3245 12333 6029 137 7213 5174 2514 5914 4498 12333 159 1379 2582 4498 195 1261 1952 284 4309 32143 1590 106 20686 1261 1952 28463 43505 2003 255 159 1379 32143 2754 284 4309 32283 3305 37606 29562 35643 1291 2353 3044 9506 2767 8468 209 12333 6029 137 7213 5174 2514 118 5914 4498 12333 4571 2686 12333 7183 1291 12333 6029 2448 1255 4155 100 1255 32143 3052 118 102\n",
            "I0407 12:30:47.937052 139835423807360 run_classifier.py:478] input_ids: 101 411 118 4722 1701 100 5587 11802 12333 195 1261 1952 440 2782 4498 5874 174 1261 1952 2582 949 1590 137 1261 1952 12333 3396 100 5587 5914 4498 100 1526 13768 10433 21193 2003 137 7213 5174 2514 44942 949 1590 122 12333 6029 5874 174 1261 1952 1834 118 5339 9506 3245 12333 6029 137 7213 5174 2514 5914 4498 12333 159 1379 2582 4498 195 1261 1952 284 4309 32143 1590 106 20686 1261 1952 28463 43505 2003 255 159 1379 32143 2754 284 4309 32283 3305 37606 29562 35643 1291 2353 3044 9506 2767 8468 209 12333 6029 137 7213 5174 2514 118 5914 4498 12333 4571 2686 12333 7183 1291 12333 6029 2448 1255 4155 100 1255 32143 3052 118 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0407 12:30:47.937394 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 12:30:47.937600 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 12:30:47.937737 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 12:30:47.938951 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: train-4\n",
            "I0407 12:30:47.939155 139835423807360 run_classifier.py:475] guid: train-4\n",
            "INFO:tensorflow:tokens: [CLS] P ##I ##N ##유 ##효 ##기 ##간 ##이 만료 ##되 ##서 다시 ##등 ##록 ##하라 ##는 메세 ##지 ##에 따라 본인 ##확 ##인 ##하 ##고 P ##I ##N ##등 ##록 ##하 ##려 ##니 P ##I ##N ##유 ##효 ##기 ##간 ##이 만료 ##되 ##었 ##다 ##고 ##하 ##고 다시 [UNK] P ##I ##N ##유 ##효 ##기 ##간 ##만 ##료 무한 ##반 ##복 ##이 ##네요 [SEP]\n",
            "I0407 12:30:47.939342 139835423807360 run_classifier.py:477] tokens: [CLS] P ##I ##N ##유 ##효 ##기 ##간 ##이 만료 ##되 ##서 다시 ##등 ##록 ##하라 ##는 메세 ##지 ##에 따라 본인 ##확 ##인 ##하 ##고 P ##I ##N ##등 ##록 ##하 ##려 ##니 P ##I ##N ##유 ##효 ##기 ##간 ##이 만료 ##되 ##었 ##다 ##고 ##하 ##고 다시 [UNK] P ##I ##N ##유 ##효 ##기 ##간 ##만 ##료 무한 ##반 ##복 ##이 ##네요 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1285 4607 11138 4201 7818 1261 3303 1291 5383 32143 2003 458 6237 5942 19941 12333 27882 1161 4498 352 1707 23006 1340 2283 1590 1285 4607 11138 6237 5942 2283 4250 3052 1285 4607 11138 4201 7818 1261 3303 1291 5383 32143 18398 3305 1590 2283 1590 458 100 1285 4607 11138 4201 7818 1261 3303 2582 6634 1471 4066 3176 1291 35405 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 12:30:47.939553 139835423807360 run_classifier.py:478] input_ids: 101 1285 4607 11138 4201 7818 1261 3303 1291 5383 32143 2003 458 6237 5942 19941 12333 27882 1161 4498 352 1707 23006 1340 2283 1590 1285 4607 11138 6237 5942 2283 4250 3052 1285 4607 11138 4201 7818 1261 3303 1291 5383 32143 18398 3305 1590 2283 1590 458 100 1285 4607 11138 4201 7818 1261 3303 2582 6634 1471 4066 3176 1291 35405 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 12:30:47.939752 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 12:30:47.939956 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 12:30:47.940098 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:Writing example 10000 of 10001\n",
            "I0407 12:30:51.376308 139835423807360 run_classifier.py:499] Writing example 10000 of 10001\n",
            "INFO:tensorflow:***** Running training *****\n",
            "I0407 12:30:51.379033 139835423807360 run_classifier.py:868] ***** Running training *****\n",
            "INFO:tensorflow:  Num examples = 10001\n",
            "I0407 12:30:51.379333 139835423807360 run_classifier.py:869]   Num examples = 10001\n",
            "INFO:tensorflow:  Batch size = 32\n",
            "I0407 12:30:51.379541 139835423807360 run_classifier.py:870]   Batch size = 32\n",
            "INFO:tensorflow:  Num steps = 312\n",
            "I0407 12:30:51.379681 139835423807360 run_classifier.py:871]   Num steps = 312\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:523: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0407 12:30:51.379907 139835423807360 deprecation_wrapper.py:119] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:523: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0407 12:30:51.389410 139835423807360 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:558: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0407 12:30:51.418099 139835423807360 deprecation.py:323] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:558: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0407 12:30:51.418392 139835423807360 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:531: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0407 12:30:51.419901 139835423807360 deprecation_wrapper.py:119] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:531: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:538: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0407 12:30:51.424000 139835423807360 deprecation.py:323] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:538: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0407 12:30:51.440829 139835423807360 estimator.py:1145] Calling model_fn.\n",
            "INFO:tensorflow:Running train on CPU\n",
            "I0407 12:30:51.441166 139835423807360 tpu_estimator.py:2965] Running train on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0407 12:30:51.441565 139835423807360 run_classifier.py:635] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (32, 128)\n",
            "I0407 12:30:51.441746 139835423807360 run_classifier.py:637]   name = input_ids, shape = (32, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (32, 128)\n",
            "I0407 12:30:51.441902 139835423807360 run_classifier.py:637]   name = input_mask, shape = (32, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (32,)\n",
            "I0407 12:30:51.442032 139835423807360 run_classifier.py:637]   name = label_ids, shape = (32,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (32, 128)\n",
            "I0407 12:30:51.442162 139835423807360 run_classifier.py:637]   name = segment_ids, shape = (32, 128)\n",
            "WARNING:tensorflow:From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0407 12:30:51.442402 139835423807360 deprecation_wrapper.py:119] From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/modeling.py:411: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0407 12:30:51.444268 139835423807360 deprecation_wrapper.py:119] From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/modeling.py:411: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/modeling.py:359: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0407 12:30:51.497969 139835423807360 deprecation.py:506] From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/modeling.py:359: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0407 12:30:51.513427 139835423807360 deprecation.py:323] From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b16d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b16d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:51.613125 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b16d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b16d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b16d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b16d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:51.721935 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b16d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b16d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6af7690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6af7690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:51.821520 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6af7690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6af7690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a5e050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a5e050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:51.950903 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a5e050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a5e050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a78810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a78810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:52.090368 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a78810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a78810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/modeling.py:277: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "W0407 12:30:52.092549 139835423807360 deprecation_wrapper.py:119] From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/modeling.py:277: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b163d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b163d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:52.203296 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b163d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b163d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db69bedd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db69bedd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:52.451063 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db69bedd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db69bedd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6ac7450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6ac7450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:52.554917 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6ac7450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6ac7450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6980710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6980710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:52.658258 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6980710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6980710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a78950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a78950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:52.799639 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a78950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a78950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6abed10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6abed10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:52.941490 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6abed10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6abed10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6889c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6889c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:53.052272 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6889c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6889c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5a62f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5a62f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:53.194480 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5a62f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5a62f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db64659d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db64659d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:53.306465 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db64659d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db64659d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2dc2777fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2dc2777fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:53.407070 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2dc2777fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2dc2777fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b16c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b16c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:53.555860 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b16c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b16c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a78950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a78950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:53.691620 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a78950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a78950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db698bd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db698bd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:53.806369 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db698bd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db698bd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db583ff10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db583ff10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:53.939263 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db583ff10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db583ff10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db599ecd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db599ecd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:54.050598 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db599ecd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db599ecd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db599ecd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db599ecd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:54.151647 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db599ecd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db599ecd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6465e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6465e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:54.300209 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6465e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6465e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:54.429172 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db681cd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db681cd50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:54.535174 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db681cd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db681cd50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db573eb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db573eb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:54.674288 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db573eb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db573eb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db688d050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db688d050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:54.779952 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db688d050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db688d050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db688d050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db688d050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:54.881438 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db688d050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db688d050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db585ce50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db585ce50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:55.021731 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db585ce50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db585ce50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db58d3910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db58d3910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:55.154876 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db58d3910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db58d3910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db598f5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db598f5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:55.270496 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db598f5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db598f5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db54e8890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db54e8890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:55.419301 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db54e8890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db54e8890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db56b6e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db56b6e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:55.523622 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db56b6e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db56b6e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db56b6e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db56b6e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:55.625093 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db56b6e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db56b6e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db53c1b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db53c1b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:55.752716 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db53c1b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db53c1b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55ab610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55ab610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:55.995182 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55ab610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55ab610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db673b910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db673b910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:56.101125 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db673b910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db673b910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67c1a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67c1a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:56.246308 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67c1a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67c1a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55a3b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55a3b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:56.357512 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55a3b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55a3b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55a3b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55a3b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:56.456440 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55a3b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55a3b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db58d3910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db58d3910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:56.586111 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db58d3910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db58d3910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5831810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5831810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:56.712129 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5831810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5831810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db576bd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db576bd10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:56.820234 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db576bd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db576bd10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5139c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5139c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:56.957062 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5139c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5139c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db532a3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db532a3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:57.059137 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db532a3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db532a3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db532a3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db532a3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:57.161877 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db532a3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db532a3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52be150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52be150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:57.298273 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52be150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52be150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5831810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5831810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:57.431389 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5831810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5831810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6af7990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6af7990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:57.542332 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6af7990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6af7990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db51991d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db51991d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:57.678928 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db51991d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db51991d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5010790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5010790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:57.779732 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5010790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5010790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5010790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5010790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:57.901122 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5010790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5010790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5117250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5117250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:58.040484 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5117250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5117250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:58.177747 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b56a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b56a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:58.288300 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b56a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b56a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4db6490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4db6490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:58.422274 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4db6490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4db6490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4ef3e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4ef3e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:58.526256 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4ef3e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4ef3e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4ef3e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4ef3e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:58.626524 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4ef3e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4ef3e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4e7f490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4e7f490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:58.757324 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4e7f490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4e7f490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:58.890539 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5124a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5124a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:58.998538 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5124a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5124a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4b91f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4b91f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:59.137142 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4b91f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4b91f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c6a0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c6a0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:59.247445 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c6a0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c6a0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c6a0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c6a0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:59.347052 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c6a0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c6a0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4ba0450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4ba0450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:59.502671 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4ba0450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4ba0450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55ab610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55ab610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:59.633250 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55ab610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55ab610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4e8b890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4e8b890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:59.740280 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4e8b890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4e8b890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db49fec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db49fec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:59.874144 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db49fec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db49fec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4b9fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4b9fd50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:30:59.974235 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4b9fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4b9fd50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c0fdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c0fdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:31:00.074617 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c0fdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c0fdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a9cf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a9cf50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:31:00.338537 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a9cf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a9cf50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:31:00.477555 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a5690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db576b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db576b550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:31:00.588352 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db576b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db576b550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db485b710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db485b710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 12:31:00.732084 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db485b710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db485b710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:664: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0407 12:31:01.218077 139835423807360 deprecation_wrapper.py:119] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:664: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0407 12:31:01.881734 139835423807360 run_classifier.py:666] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (49541, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.882066 139835423807360 run_classifier.py:672]   name = bert/embeddings/word_embeddings:0, shape = (49541, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.882266 139835423807360 run_classifier.py:672]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.882453 139835423807360 run_classifier.py:672]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.882611 139835423807360 run_classifier.py:672]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.882738 139835423807360 run_classifier.py:672]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.882859 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.883027 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.883169 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.883317 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.883438 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.883562 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.883681 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.883810 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.883947 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.884066 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.884195 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.884332 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.884452 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.884580 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.884700 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.884818 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.884958 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.885087 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.885212 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.885342 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.885476 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.885605 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.885725 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.885853 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.885994 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.886112 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.886242 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.886368 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.886499 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.886630 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.886755 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.886891 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.887010 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.887142 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.887267 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.887391 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.887509 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.887652 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.887773 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.887913 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.888041 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.888160 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.888288 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.888420 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.888541 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.888679 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.888806 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.888946 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.889066 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.889199 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.889322 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.889447 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.889564 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.889691 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.889819 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.889962 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.890081 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.890209 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.890328 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.890454 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.964072 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.964484 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.964685 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.964907 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.965076 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.965290 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.965458 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.965611 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.965786 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.965961 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.966120 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.966361 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.966540 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.966704 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.966878 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.967059 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.967231 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.967461 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.967646 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.967824 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.968004 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.968166 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.968327 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.968544 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.968718 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.968904 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.969066 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.969238 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.969391 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.969547 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.969773 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.969962 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.970121 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.970299 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.970458 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.970613 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.970838 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.971031 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.971191 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.971370 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.971534 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.971705 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.971953 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.972132 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.972306 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.972469 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.972630 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.972803 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.973062 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.973238 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.973394 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.973549 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.973704 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.973882 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.974072 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.974247 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.974407 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.974571 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.974732 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.974924 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.975159 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.975340 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.975508 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.975681 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.975887 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.976102 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.976345 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.976510 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.976664 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.976828 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.976999 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.977162 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.977377 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.977547 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.977706 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.977885 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.978044 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.978209 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.978367 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.978530 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.978682 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.978851 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.979023 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.979183 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.979348 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.979517 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.979676 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.979847 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.980024 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.980193 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.980370 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.980538 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.980697 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.980857 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.981026 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.981183 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.981348 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.981510 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.981664 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.981818 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.981989 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.982162 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.982335 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.982507 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.982691 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.982878 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.983061 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.983244 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.983409 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.983562 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.983710 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.983888 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.984049 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.984224 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.984386 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.984538 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.984692 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.984857 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.985030 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.985193 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.985359 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.985522 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.985674 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.985838 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.986016 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.986219 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.986390 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.986561 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.986722 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.986910 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.987073 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.987241 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.987404 139835423807360 run_classifier.py:672]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 12:31:01.987578 139835423807360 run_classifier.py:672]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (3, 768)\n",
            "I0407 12:31:01.987797 139835423807360 run_classifier.py:672]   name = output_weights:0, shape = (3, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (3,)\n",
            "I0407 12:31:01.988019 139835423807360 run_classifier.py:672]   name = output_bias:0, shape = (3,)\n",
            "WARNING:tensorflow:From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0407 12:31:01.988275 139835423807360 deprecation_wrapper.py:119] From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0407 12:31:01.989806 139835423807360 deprecation_wrapper.py:119] From /content/drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0407 12:31:01.997225 139835423807360 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0407 12:31:05.488813 139835423807360 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0407 12:31:10.245336 139835423807360 estimator.py:1147] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0407 12:31:10.246899 139835423807360 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0407 12:31:13.252184 139835423807360 monitored_session.py:240] Graph was finalized.\n",
            "2021-04-07 12:31:13.252962: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-04-07 12:31:13.259454: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200140000 Hz\n",
            "2021-04-07 12:31:13.259992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55efee506fc0 executing computations on platform Host. Devices:\n",
            "2021-04-07 12:31:13.260047: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2021-04-07 12:31:16.465847: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0407 12:32:13.185283 139835423807360 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0407 12:32:13.328531 139835423807360 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output/pre_training/model.ckpt.\n",
            "I0407 12:32:19.696043 139835423807360 basic_session_run_hooks.py:606] Saving checkpoints for 0 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output/pre_training/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0193903\n",
            "I0407 12:34:19.168844 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0193903\n",
            "INFO:tensorflow:examples/sec: 0.62049\n",
            "I0407 12:34:19.169641 139835423807360 tpu_estimator.py:2160] examples/sec: 0.62049\n",
            "INFO:tensorflow:global_step/sec: 0.0223438\n",
            "I0407 12:35:03.923975 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223438\n",
            "INFO:tensorflow:examples/sec: 0.715001\n",
            "I0407 12:35:03.924418 139835423807360 tpu_estimator.py:2160] examples/sec: 0.715001\n",
            "INFO:tensorflow:global_step/sec: 0.0224625\n",
            "I0407 12:35:48.442653 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224625\n",
            "INFO:tensorflow:examples/sec: 0.7188\n",
            "I0407 12:35:48.442964 139835423807360 tpu_estimator.py:2160] examples/sec: 0.7188\n",
            "INFO:tensorflow:global_step/sec: 0.0223825\n",
            "I0407 12:36:33.120325 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223825\n",
            "INFO:tensorflow:examples/sec: 0.71624\n",
            "I0407 12:36:33.120765 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71624\n",
            "INFO:tensorflow:global_step/sec: 0.0223873\n",
            "I0407 12:37:17.788634 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223873\n",
            "INFO:tensorflow:examples/sec: 0.716393\n",
            "I0407 12:37:17.789080 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716393\n",
            "INFO:tensorflow:global_step/sec: 0.0222982\n",
            "I0407 12:38:02.635281 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222982\n",
            "INFO:tensorflow:examples/sec: 0.713542\n",
            "I0407 12:38:02.636905 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713542\n",
            "INFO:tensorflow:global_step/sec: 0.0221857\n",
            "I0407 12:38:47.709486 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221857\n",
            "INFO:tensorflow:examples/sec: 0.709942\n",
            "I0407 12:38:47.709964 139835423807360 tpu_estimator.py:2160] examples/sec: 0.709942\n",
            "INFO:tensorflow:global_step/sec: 0.0223226\n",
            "I0407 12:39:32.507063 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223226\n",
            "INFO:tensorflow:examples/sec: 0.714324\n",
            "I0407 12:39:32.507468 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714324\n",
            "INFO:tensorflow:global_step/sec: 0.0223966\n",
            "I0407 12:40:17.156662 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223966\n",
            "INFO:tensorflow:examples/sec: 0.716691\n",
            "I0407 12:40:17.157898 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716691\n",
            "INFO:tensorflow:global_step/sec: 0.022354\n",
            "I0407 12:41:01.891387 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022354\n",
            "INFO:tensorflow:examples/sec: 0.715329\n",
            "I0407 12:41:01.891860 139835423807360 tpu_estimator.py:2160] examples/sec: 0.715329\n",
            "INFO:tensorflow:global_step/sec: 0.0225921\n",
            "I0407 12:41:46.154532 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225921\n",
            "INFO:tensorflow:examples/sec: 0.722949\n",
            "I0407 12:41:46.154982 139835423807360 tpu_estimator.py:2160] examples/sec: 0.722949\n",
            "INFO:tensorflow:global_step/sec: 0.0224526\n",
            "I0407 12:42:30.692817 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224526\n",
            "INFO:tensorflow:examples/sec: 0.718483\n",
            "I0407 12:42:30.694358 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718483\n",
            "INFO:tensorflow:global_step/sec: 0.0225362\n",
            "I0407 12:43:15.065942 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225362\n",
            "INFO:tensorflow:examples/sec: 0.721157\n",
            "I0407 12:43:15.066377 139835423807360 tpu_estimator.py:2160] examples/sec: 0.721157\n",
            "INFO:tensorflow:global_step/sec: 0.0225096\n",
            "I0407 12:43:59.491368 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225096\n",
            "INFO:tensorflow:examples/sec: 0.720308\n",
            "I0407 12:43:59.492297 139835423807360 tpu_estimator.py:2160] examples/sec: 0.720308\n",
            "INFO:tensorflow:global_step/sec: 0.0225331\n",
            "I0407 12:44:43.870515 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225331\n",
            "INFO:tensorflow:examples/sec: 0.721058\n",
            "I0407 12:44:43.870813 139835423807360 tpu_estimator.py:2160] examples/sec: 0.721058\n",
            "INFO:tensorflow:global_step/sec: 0.0224453\n",
            "I0407 12:45:28.423272 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224453\n",
            "INFO:tensorflow:examples/sec: 0.71825\n",
            "I0407 12:45:28.423711 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71825\n",
            "INFO:tensorflow:global_step/sec: 0.0223826\n",
            "I0407 12:46:13.100731 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223826\n",
            "INFO:tensorflow:examples/sec: 0.716245\n",
            "I0407 12:46:13.101254 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716245\n",
            "INFO:tensorflow:global_step/sec: 0.0224429\n",
            "I0407 12:46:57.658264 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224429\n",
            "INFO:tensorflow:examples/sec: 0.718172\n",
            "I0407 12:46:57.659459 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718172\n",
            "INFO:tensorflow:global_step/sec: 0.022452\n",
            "I0407 12:47:42.197730 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022452\n",
            "INFO:tensorflow:examples/sec: 0.718464\n",
            "I0407 12:47:42.198196 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718464\n",
            "INFO:tensorflow:global_step/sec: 0.0223456\n",
            "I0407 12:48:26.949235 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223456\n",
            "INFO:tensorflow:examples/sec: 0.71506\n",
            "I0407 12:48:26.949702 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71506\n",
            "INFO:tensorflow:global_step/sec: 0.0224697\n",
            "I0407 12:49:11.453674 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224697\n",
            "INFO:tensorflow:examples/sec: 0.71903\n",
            "I0407 12:49:11.454807 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71903\n",
            "INFO:tensorflow:global_step/sec: 0.0222527\n",
            "I0407 12:49:56.392057 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222527\n",
            "INFO:tensorflow:examples/sec: 0.712086\n",
            "I0407 12:49:56.392539 139835423807360 tpu_estimator.py:2160] examples/sec: 0.712086\n",
            "INFO:tensorflow:global_step/sec: 0.0222094\n",
            "I0407 12:50:41.418177 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222094\n",
            "INFO:tensorflow:examples/sec: 0.7107\n",
            "I0407 12:50:41.418466 139835423807360 tpu_estimator.py:2160] examples/sec: 0.7107\n",
            "INFO:tensorflow:global_step/sec: 0.022301\n",
            "I0407 12:51:26.259185 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022301\n",
            "INFO:tensorflow:examples/sec: 0.713631\n",
            "I0407 12:51:26.260692 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713631\n",
            "INFO:tensorflow:global_step/sec: 0.0224527\n",
            "I0407 12:52:10.797247 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224527\n",
            "INFO:tensorflow:examples/sec: 0.718487\n",
            "I0407 12:52:10.797696 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718487\n",
            "INFO:tensorflow:global_step/sec: 0.0224623\n",
            "I0407 12:52:55.316260 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224623\n",
            "INFO:tensorflow:examples/sec: 0.718794\n",
            "I0407 12:52:55.316747 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718794\n",
            "INFO:tensorflow:global_step/sec: 0.0223253\n",
            "I0407 12:53:40.108568 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223253\n",
            "INFO:tensorflow:examples/sec: 0.714409\n",
            "I0407 12:53:40.110082 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714409\n",
            "INFO:tensorflow:global_step/sec: 0.0223508\n",
            "I0407 12:54:24.849684 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223508\n",
            "INFO:tensorflow:examples/sec: 0.715226\n",
            "I0407 12:54:24.850145 139835423807360 tpu_estimator.py:2160] examples/sec: 0.715226\n",
            "INFO:tensorflow:global_step/sec: 0.022466\n",
            "I0407 12:55:09.361452 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022466\n",
            "INFO:tensorflow:examples/sec: 0.718911\n",
            "I0407 12:55:09.361957 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718911\n",
            "INFO:tensorflow:global_step/sec: 0.0225037\n",
            "I0407 12:55:53.798669 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225037\n",
            "INFO:tensorflow:examples/sec: 0.720117\n",
            "I0407 12:55:53.800161 139835423807360 tpu_estimator.py:2160] examples/sec: 0.720117\n",
            "INFO:tensorflow:global_step/sec: 0.0223085\n",
            "I0407 12:56:38.624618 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223085\n",
            "INFO:tensorflow:examples/sec: 0.713872\n",
            "I0407 12:56:38.625077 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713872\n",
            "INFO:tensorflow:global_step/sec: 0.0221867\n",
            "I0407 12:57:23.696683 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221867\n",
            "INFO:tensorflow:examples/sec: 0.709974\n",
            "I0407 12:57:23.697180 139835423807360 tpu_estimator.py:2160] examples/sec: 0.709974\n",
            "INFO:tensorflow:global_step/sec: 0.022317\n",
            "I0407 12:58:08.505574 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022317\n",
            "INFO:tensorflow:examples/sec: 0.714144\n",
            "I0407 12:58:08.507102 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714144\n",
            "INFO:tensorflow:global_step/sec: 0.0213864\n",
            "I0407 12:58:55.264342 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0213864\n",
            "INFO:tensorflow:examples/sec: 0.684364\n",
            "I0407 12:58:55.264816 139835423807360 tpu_estimator.py:2160] examples/sec: 0.684364\n",
            "INFO:tensorflow:global_step/sec: 0.0222996\n",
            "I0407 12:59:40.108248 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222996\n",
            "INFO:tensorflow:examples/sec: 0.713586\n",
            "I0407 12:59:40.108691 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713586\n",
            "INFO:tensorflow:global_step/sec: 0.0222379\n",
            "I0407 13:00:25.076439 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222379\n",
            "INFO:tensorflow:examples/sec: 0.711614\n",
            "I0407 13:00:25.077614 139835423807360 tpu_estimator.py:2160] examples/sec: 0.711614\n",
            "INFO:tensorflow:global_step/sec: 0.0223209\n",
            "I0407 13:01:09.877484 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223209\n",
            "INFO:tensorflow:examples/sec: 0.71427\n",
            "I0407 13:01:09.877961 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71427\n",
            "INFO:tensorflow:global_step/sec: 0.022395\n",
            "I0407 13:01:54.530158 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022395\n",
            "INFO:tensorflow:examples/sec: 0.716641\n",
            "I0407 13:01:54.530425 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716641\n",
            "INFO:tensorflow:global_step/sec: 0.0223245\n",
            "I0407 13:02:39.323998 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223245\n",
            "INFO:tensorflow:examples/sec: 0.714384\n",
            "I0407 13:02:39.325556 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714384\n",
            "INFO:tensorflow:global_step/sec: 0.0223942\n",
            "I0407 13:03:23.978411 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223942\n",
            "INFO:tensorflow:examples/sec: 0.716615\n",
            "I0407 13:03:23.978878 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716615\n",
            "INFO:tensorflow:global_step/sec: 0.0224851\n",
            "I0407 13:04:08.452337 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224851\n",
            "INFO:tensorflow:examples/sec: 0.719522\n",
            "I0407 13:04:08.452818 139835423807360 tpu_estimator.py:2160] examples/sec: 0.719522\n",
            "INFO:tensorflow:global_step/sec: 0.0223474\n",
            "I0407 13:04:53.200357 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223474\n",
            "INFO:tensorflow:examples/sec: 0.715117\n",
            "I0407 13:04:53.201798 139835423807360 tpu_estimator.py:2160] examples/sec: 0.715117\n",
            "INFO:tensorflow:global_step/sec: 0.0221003\n",
            "I0407 13:05:38.448580 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221003\n",
            "INFO:tensorflow:examples/sec: 0.707209\n",
            "I0407 13:05:38.448985 139835423807360 tpu_estimator.py:2160] examples/sec: 0.707209\n",
            "INFO:tensorflow:global_step/sec: 0.0221574\n",
            "I0407 13:06:23.580215 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221574\n",
            "INFO:tensorflow:examples/sec: 0.709037\n",
            "I0407 13:06:23.580591 139835423807360 tpu_estimator.py:2160] examples/sec: 0.709037\n",
            "INFO:tensorflow:global_step/sec: 0.0222071\n",
            "I0407 13:07:08.610829 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222071\n",
            "INFO:tensorflow:examples/sec: 0.710627\n",
            "I0407 13:07:08.612429 139835423807360 tpu_estimator.py:2160] examples/sec: 0.710627\n",
            "INFO:tensorflow:global_step/sec: 0.0221958\n",
            "I0407 13:07:53.664355 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221958\n",
            "INFO:tensorflow:examples/sec: 0.710267\n",
            "I0407 13:07:53.664806 139835423807360 tpu_estimator.py:2160] examples/sec: 0.710267\n",
            "INFO:tensorflow:global_step/sec: 0.0222826\n",
            "I0407 13:08:38.542360 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222826\n",
            "INFO:tensorflow:examples/sec: 0.713044\n",
            "I0407 13:08:38.542637 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713044\n",
            "INFO:tensorflow:global_step/sec: 0.0221714\n",
            "I0407 13:09:23.645547 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221714\n",
            "INFO:tensorflow:examples/sec: 0.709484\n",
            "I0407 13:09:23.647042 139835423807360 tpu_estimator.py:2160] examples/sec: 0.709484\n",
            "INFO:tensorflow:global_step/sec: 0.0222678\n",
            "I0407 13:10:08.553519 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222678\n",
            "INFO:tensorflow:examples/sec: 0.712569\n",
            "I0407 13:10:08.554016 139835423807360 tpu_estimator.py:2160] examples/sec: 0.712569\n",
            "INFO:tensorflow:global_step/sec: 0.0221275\n",
            "I0407 13:10:53.746146 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221275\n",
            "INFO:tensorflow:examples/sec: 0.70808\n",
            "I0407 13:10:53.746719 139835423807360 tpu_estimator.py:2160] examples/sec: 0.70808\n",
            "INFO:tensorflow:global_step/sec: 0.0224361\n",
            "I0407 13:11:38.317108 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224361\n",
            "INFO:tensorflow:examples/sec: 0.717956\n",
            "I0407 13:11:38.318326 139835423807360 tpu_estimator.py:2160] examples/sec: 0.717956\n",
            "INFO:tensorflow:global_step/sec: 0.0223382\n",
            "I0407 13:12:23.083429 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223382\n",
            "INFO:tensorflow:examples/sec: 0.714822\n",
            "I0407 13:12:23.083731 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714822\n",
            "INFO:tensorflow:global_step/sec: 0.0222405\n",
            "I0407 13:13:08.046406 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222405\n",
            "INFO:tensorflow:examples/sec: 0.711697\n",
            "I0407 13:13:08.046895 139835423807360 tpu_estimator.py:2160] examples/sec: 0.711697\n",
            "INFO:tensorflow:global_step/sec: 0.0223632\n",
            "I0407 13:13:52.762700 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223632\n",
            "INFO:tensorflow:examples/sec: 0.715623\n",
            "I0407 13:13:52.764008 139835423807360 tpu_estimator.py:2160] examples/sec: 0.715623\n",
            "INFO:tensorflow:global_step/sec: 0.0222289\n",
            "I0407 13:14:37.749239 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222289\n",
            "INFO:tensorflow:examples/sec: 0.711324\n",
            "I0407 13:14:37.749525 139835423807360 tpu_estimator.py:2160] examples/sec: 0.711324\n",
            "INFO:tensorflow:global_step/sec: 0.0221329\n",
            "I0407 13:15:22.930968 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221329\n",
            "INFO:tensorflow:examples/sec: 0.708253\n",
            "I0407 13:15:22.931241 139835423807360 tpu_estimator.py:2160] examples/sec: 0.708253\n",
            "INFO:tensorflow:global_step/sec: 0.0223069\n",
            "I0407 13:16:07.760086 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223069\n",
            "INFO:tensorflow:examples/sec: 0.713821\n",
            "I0407 13:16:07.761643 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713821\n",
            "INFO:tensorflow:global_step/sec: 0.0221044\n",
            "I0407 13:16:52.999983 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221044\n",
            "INFO:tensorflow:examples/sec: 0.707341\n",
            "I0407 13:16:53.000705 139835423807360 tpu_estimator.py:2160] examples/sec: 0.707341\n",
            "INFO:tensorflow:global_step/sec: 0.0221006\n",
            "I0407 13:17:38.247556 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221006\n",
            "INFO:tensorflow:examples/sec: 0.707219\n",
            "I0407 13:17:38.248056 139835423807360 tpu_estimator.py:2160] examples/sec: 0.707219\n",
            "INFO:tensorflow:global_step/sec: 0.0223309\n",
            "I0407 13:18:23.028499 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223309\n",
            "INFO:tensorflow:examples/sec: 0.71459\n",
            "I0407 13:18:23.030049 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71459\n",
            "INFO:tensorflow:global_step/sec: 0.0222538\n",
            "I0407 13:19:07.964694 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222538\n",
            "INFO:tensorflow:examples/sec: 0.712121\n",
            "I0407 13:19:07.965178 139835423807360 tpu_estimator.py:2160] examples/sec: 0.712121\n",
            "INFO:tensorflow:global_step/sec: 0.0222891\n",
            "I0407 13:19:52.829618 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222891\n",
            "INFO:tensorflow:examples/sec: 0.713252\n",
            "I0407 13:19:52.830085 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713252\n",
            "INFO:tensorflow:global_step/sec: 0.0223567\n",
            "I0407 13:20:37.559027 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223567\n",
            "INFO:tensorflow:examples/sec: 0.715413\n",
            "I0407 13:20:37.559318 139835423807360 tpu_estimator.py:2160] examples/sec: 0.715413\n",
            "INFO:tensorflow:global_step/sec: 0.0224145\n",
            "I0407 13:21:22.173063 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224145\n",
            "INFO:tensorflow:examples/sec: 0.717263\n",
            "I0407 13:21:22.173334 139835423807360 tpu_estimator.py:2160] examples/sec: 0.717263\n",
            "INFO:tensorflow:global_step/sec: 0.0220885\n",
            "I0407 13:22:07.445407 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220885\n",
            "INFO:tensorflow:examples/sec: 0.706833\n",
            "I0407 13:22:07.445882 139835423807360 tpu_estimator.py:2160] examples/sec: 0.706833\n",
            "INFO:tensorflow:global_step/sec: 0.021994\n",
            "I0407 13:22:52.912369 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.021994\n",
            "INFO:tensorflow:examples/sec: 0.703808\n",
            "I0407 13:22:52.913893 139835423807360 tpu_estimator.py:2160] examples/sec: 0.703808\n",
            "INFO:tensorflow:global_step/sec: 0.0222114\n",
            "I0407 13:23:37.934286 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222114\n",
            "INFO:tensorflow:examples/sec: 0.710765\n",
            "I0407 13:23:37.934778 139835423807360 tpu_estimator.py:2160] examples/sec: 0.710765\n",
            "INFO:tensorflow:global_step/sec: 0.0221653\n",
            "I0407 13:24:23.049994 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221653\n",
            "INFO:tensorflow:examples/sec: 0.709288\n",
            "I0407 13:24:23.050472 139835423807360 tpu_estimator.py:2160] examples/sec: 0.709288\n",
            "INFO:tensorflow:global_step/sec: 0.0224053\n",
            "I0407 13:25:07.682253 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224053\n",
            "INFO:tensorflow:examples/sec: 0.71697\n",
            "I0407 13:25:07.683572 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71697\n",
            "INFO:tensorflow:global_step/sec: 0.0221576\n",
            "I0407 13:25:52.813536 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221576\n",
            "INFO:tensorflow:examples/sec: 0.709045\n",
            "I0407 13:25:52.814022 139835423807360 tpu_estimator.py:2160] examples/sec: 0.709045\n",
            "INFO:tensorflow:global_step/sec: 0.0221787\n",
            "I0407 13:26:37.901627 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221787\n",
            "INFO:tensorflow:examples/sec: 0.70972\n",
            "I0407 13:26:37.902159 139835423807360 tpu_estimator.py:2160] examples/sec: 0.70972\n",
            "INFO:tensorflow:global_step/sec: 0.0220464\n",
            "I0407 13:27:23.260402 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220464\n",
            "INFO:tensorflow:examples/sec: 0.705486\n",
            "I0407 13:27:23.260674 139835423807360 tpu_estimator.py:2160] examples/sec: 0.705486\n",
            "INFO:tensorflow:global_step/sec: 0.0221197\n",
            "I0407 13:28:08.469006 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221197\n",
            "INFO:tensorflow:examples/sec: 0.70783\n",
            "I0407 13:28:08.469282 139835423807360 tpu_estimator.py:2160] examples/sec: 0.70783\n",
            "INFO:tensorflow:global_step/sec: 0.0222561\n",
            "I0407 13:28:53.400477 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222561\n",
            "INFO:tensorflow:examples/sec: 0.712195\n",
            "I0407 13:28:53.400984 139835423807360 tpu_estimator.py:2160] examples/sec: 0.712195\n",
            "INFO:tensorflow:global_step/sec: 0.0223608\n",
            "I0407 13:29:38.121597 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223608\n",
            "INFO:tensorflow:examples/sec: 0.715546\n",
            "I0407 13:29:38.122912 139835423807360 tpu_estimator.py:2160] examples/sec: 0.715546\n",
            "INFO:tensorflow:global_step/sec: 0.0221329\n",
            "I0407 13:30:23.303291 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221329\n",
            "INFO:tensorflow:examples/sec: 0.708252\n",
            "I0407 13:30:23.303795 139835423807360 tpu_estimator.py:2160] examples/sec: 0.708252\n",
            "INFO:tensorflow:global_step/sec: 0.0220111\n",
            "I0407 13:31:08.734896 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220111\n",
            "INFO:tensorflow:examples/sec: 0.704356\n",
            "I0407 13:31:08.735376 139835423807360 tpu_estimator.py:2160] examples/sec: 0.704356\n",
            "INFO:tensorflow:global_step/sec: 0.0220321\n",
            "I0407 13:31:54.123210 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220321\n",
            "INFO:tensorflow:examples/sec: 0.705026\n",
            "I0407 13:31:54.124751 139835423807360 tpu_estimator.py:2160] examples/sec: 0.705026\n",
            "INFO:tensorflow:global_step/sec: 0.0221185\n",
            "I0407 13:32:39.334329 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221185\n",
            "INFO:tensorflow:examples/sec: 0.707792\n",
            "I0407 13:32:39.334811 139835423807360 tpu_estimator.py:2160] examples/sec: 0.707792\n",
            "INFO:tensorflow:global_step/sec: 0.0223454\n",
            "I0407 13:33:24.086269 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223454\n",
            "INFO:tensorflow:examples/sec: 0.715052\n",
            "I0407 13:33:24.086764 139835423807360 tpu_estimator.py:2160] examples/sec: 0.715052\n",
            "INFO:tensorflow:global_step/sec: 0.0224332\n",
            "I0407 13:34:08.663008 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224332\n",
            "INFO:tensorflow:examples/sec: 0.717863\n",
            "I0407 13:34:08.664716 139835423807360 tpu_estimator.py:2160] examples/sec: 0.717863\n",
            "INFO:tensorflow:global_step/sec: 0.0220227\n",
            "I0407 13:34:54.070696 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220227\n",
            "INFO:tensorflow:examples/sec: 0.704726\n",
            "I0407 13:34:54.071205 139835423807360 tpu_estimator.py:2160] examples/sec: 0.704726\n",
            "INFO:tensorflow:global_step/sec: 0.0223024\n",
            "I0407 13:35:38.908917 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223024\n",
            "INFO:tensorflow:examples/sec: 0.713677\n",
            "I0407 13:35:38.909180 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713677\n",
            "INFO:tensorflow:global_step/sec: 0.0223245\n",
            "I0407 13:36:23.702824 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223245\n",
            "INFO:tensorflow:examples/sec: 0.714383\n",
            "I0407 13:36:23.704540 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714383\n",
            "INFO:tensorflow:global_step/sec: 0.0223645\n",
            "I0407 13:37:08.416553 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223645\n",
            "INFO:tensorflow:examples/sec: 0.715664\n",
            "I0407 13:37:08.417034 139835423807360 tpu_estimator.py:2160] examples/sec: 0.715664\n",
            "INFO:tensorflow:global_step/sec: 0.02239\n",
            "I0407 13:37:53.079369 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.02239\n",
            "INFO:tensorflow:examples/sec: 0.71648\n",
            "I0407 13:37:53.079693 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71648\n",
            "INFO:tensorflow:global_step/sec: 0.0223996\n",
            "I0407 13:38:37.723088 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223996\n",
            "INFO:tensorflow:examples/sec: 0.716786\n",
            "I0407 13:38:37.724337 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716786\n",
            "INFO:tensorflow:global_step/sec: 0.0224268\n",
            "I0407 13:39:22.312551 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224268\n",
            "INFO:tensorflow:examples/sec: 0.717658\n",
            "I0407 13:39:22.313035 139835423807360 tpu_estimator.py:2160] examples/sec: 0.717658\n",
            "INFO:tensorflow:global_step/sec: 0.0223834\n",
            "I0407 13:40:06.988575 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223834\n",
            "INFO:tensorflow:examples/sec: 0.716267\n",
            "I0407 13:40:06.989092 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716267\n",
            "INFO:tensorflow:global_step/sec: 0.0222668\n",
            "I0407 13:40:51.898725 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222668\n",
            "INFO:tensorflow:examples/sec: 0.712538\n",
            "I0407 13:40:51.899020 139835423807360 tpu_estimator.py:2160] examples/sec: 0.712538\n",
            "INFO:tensorflow:global_step/sec: 0.0224178\n",
            "I0407 13:41:36.505926 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224178\n",
            "INFO:tensorflow:examples/sec: 0.71737\n",
            "I0407 13:41:36.506386 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71737\n",
            "INFO:tensorflow:global_step/sec: 0.022455\n",
            "I0407 13:42:21.039363 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022455\n",
            "INFO:tensorflow:examples/sec: 0.718561\n",
            "I0407 13:42:21.039691 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718561\n",
            "INFO:tensorflow:global_step/sec: 0.0221439\n",
            "I0407 13:43:06.198647 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221439\n",
            "INFO:tensorflow:examples/sec: 0.708603\n",
            "I0407 13:43:06.199902 139835423807360 tpu_estimator.py:2160] examples/sec: 0.708603\n",
            "INFO:tensorflow:global_step/sec: 0.0221476\n",
            "I0407 13:43:51.350286 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221476\n",
            "INFO:tensorflow:examples/sec: 0.708722\n",
            "I0407 13:43:51.350805 139835423807360 tpu_estimator.py:2160] examples/sec: 0.708722\n",
            "INFO:tensorflow:global_step/sec: 0.0221941\n",
            "I0407 13:44:36.407229 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221941\n",
            "INFO:tensorflow:examples/sec: 0.710213\n",
            "I0407 13:44:36.407747 139835423807360 tpu_estimator.py:2160] examples/sec: 0.710213\n",
            "INFO:tensorflow:global_step/sec: 0.0221823\n",
            "I0407 13:45:21.488234 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221823\n",
            "INFO:tensorflow:examples/sec: 0.709833\n",
            "I0407 13:45:21.489441 139835423807360 tpu_estimator.py:2160] examples/sec: 0.709833\n",
            "INFO:tensorflow:global_step/sec: 0.0224415\n",
            "I0407 13:46:06.048570 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224415\n",
            "INFO:tensorflow:examples/sec: 0.718127\n",
            "I0407 13:46:06.048831 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718127\n",
            "INFO:tensorflow:global_step/sec: 0.0225392\n",
            "I0407 13:46:50.415704 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225392\n",
            "INFO:tensorflow:examples/sec: 0.721255\n",
            "I0407 13:46:50.416187 139835423807360 tpu_estimator.py:2160] examples/sec: 0.721255\n",
            "INFO:tensorflow:global_step/sec: 0.0226628\n",
            "I0407 13:47:34.540840 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0226628\n",
            "INFO:tensorflow:examples/sec: 0.725209\n",
            "I0407 13:47:34.541108 139835423807360 tpu_estimator.py:2160] examples/sec: 0.725209\n",
            "INFO:tensorflow:global_step/sec: 0.0228778\n",
            "I0407 13:48:18.251425 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0228778\n",
            "INFO:tensorflow:examples/sec: 0.732089\n",
            "I0407 13:48:18.251942 139835423807360 tpu_estimator.py:2160] examples/sec: 0.732089\n",
            "INFO:tensorflow:global_step/sec: 0.0227117\n",
            "I0407 13:49:02.281534 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0227117\n",
            "INFO:tensorflow:examples/sec: 0.726776\n",
            "I0407 13:49:02.282036 139835423807360 tpu_estimator.py:2160] examples/sec: 0.726776\n",
            "INFO:tensorflow:global_step/sec: 0.0227347\n",
            "I0407 13:49:46.267162 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0227347\n",
            "INFO:tensorflow:examples/sec: 0.72751\n",
            "I0407 13:49:46.268728 139835423807360 tpu_estimator.py:2160] examples/sec: 0.72751\n",
            "INFO:tensorflow:global_step/sec: 0.0227031\n",
            "I0407 13:50:30.314038 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0227031\n",
            "INFO:tensorflow:examples/sec: 0.726499\n",
            "I0407 13:50:30.314540 139835423807360 tpu_estimator.py:2160] examples/sec: 0.726499\n",
            "INFO:tensorflow:global_step/sec: 0.0223137\n",
            "I0407 13:51:15.129518 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223137\n",
            "INFO:tensorflow:examples/sec: 0.71404\n",
            "I0407 13:51:15.130019 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71404\n",
            "INFO:tensorflow:global_step/sec: 0.0228207\n",
            "I0407 13:51:58.949254 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0228207\n",
            "INFO:tensorflow:examples/sec: 0.730264\n",
            "I0407 13:51:58.949512 139835423807360 tpu_estimator.py:2160] examples/sec: 0.730264\n",
            "INFO:tensorflow:global_step/sec: 0.0227062\n",
            "I0407 13:52:42.990076 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0227062\n",
            "INFO:tensorflow:examples/sec: 0.726599\n",
            "I0407 13:52:42.990538 139835423807360 tpu_estimator.py:2160] examples/sec: 0.726599\n",
            "INFO:tensorflow:global_step/sec: 0.0227164\n",
            "I0407 13:53:27.011085 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0227164\n",
            "INFO:tensorflow:examples/sec: 0.726926\n",
            "I0407 13:53:27.011474 139835423807360 tpu_estimator.py:2160] examples/sec: 0.726926\n",
            "INFO:tensorflow:global_step/sec: 0.0226549\n",
            "I0407 13:54:11.151574 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0226549\n",
            "INFO:tensorflow:examples/sec: 0.724958\n",
            "I0407 13:54:11.153165 139835423807360 tpu_estimator.py:2160] examples/sec: 0.724958\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 108 vs previous value: 108. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "W0407 13:54:11.153356 139835423807360 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 108 vs previous value: 108. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 0.02266\n",
            "I0407 13:54:55.282362 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.02266\n",
            "INFO:tensorflow:examples/sec: 0.725119\n",
            "I0407 13:54:55.282639 139835423807360 tpu_estimator.py:2160] examples/sec: 0.725119\n",
            "INFO:tensorflow:global_step/sec: 0.0227055\n",
            "I0407 13:55:39.324410 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0227055\n",
            "INFO:tensorflow:examples/sec: 0.726576\n",
            "I0407 13:55:39.324894 139835423807360 tpu_estimator.py:2160] examples/sec: 0.726576\n",
            "INFO:tensorflow:global_step/sec: 0.0223027\n",
            "I0407 13:56:24.162149 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223027\n",
            "INFO:tensorflow:examples/sec: 0.713686\n",
            "I0407 13:56:24.163401 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713686\n",
            "INFO:tensorflow:global_step/sec: 0.0222366\n",
            "I0407 13:57:09.132976 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222366\n",
            "INFO:tensorflow:examples/sec: 0.711571\n",
            "I0407 13:57:09.133469 139835423807360 tpu_estimator.py:2160] examples/sec: 0.711571\n",
            "INFO:tensorflow:global_step/sec: 0.0226002\n",
            "I0407 13:57:53.380331 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0226002\n",
            "INFO:tensorflow:examples/sec: 0.723207\n",
            "I0407 13:57:53.380849 139835423807360 tpu_estimator.py:2160] examples/sec: 0.723207\n",
            "INFO:tensorflow:global_step/sec: 0.0224574\n",
            "I0407 13:58:37.909198 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224574\n",
            "INFO:tensorflow:examples/sec: 0.718636\n",
            "I0407 13:58:37.910457 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718636\n",
            "INFO:tensorflow:global_step/sec: 0.0223846\n",
            "I0407 13:59:22.582653 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223846\n",
            "INFO:tensorflow:examples/sec: 0.716309\n",
            "I0407 13:59:22.583136 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716309\n",
            "INFO:tensorflow:global_step/sec: 0.0224253\n",
            "I0407 14:00:07.175116 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224253\n",
            "INFO:tensorflow:examples/sec: 0.717609\n",
            "I0407 14:00:07.175592 139835423807360 tpu_estimator.py:2160] examples/sec: 0.717609\n",
            "INFO:tensorflow:global_step/sec: 0.0223044\n",
            "I0407 14:00:52.009269 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223044\n",
            "INFO:tensorflow:examples/sec: 0.713742\n",
            "I0407 14:00:52.010497 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713742\n",
            "INFO:tensorflow:global_step/sec: 0.0225832\n",
            "I0407 14:01:36.289996 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225832\n",
            "INFO:tensorflow:examples/sec: 0.722662\n",
            "I0407 14:01:36.290468 139835423807360 tpu_estimator.py:2160] examples/sec: 0.722662\n",
            "INFO:tensorflow:global_step/sec: 0.0225455\n",
            "I0407 14:02:20.644798 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225455\n",
            "INFO:tensorflow:examples/sec: 0.721455\n",
            "I0407 14:02:20.645080 139835423807360 tpu_estimator.py:2160] examples/sec: 0.721455\n",
            "INFO:tensorflow:global_step/sec: 0.0224243\n",
            "I0407 14:03:05.239183 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224243\n",
            "INFO:tensorflow:examples/sec: 0.717579\n",
            "I0407 14:03:05.239453 139835423807360 tpu_estimator.py:2160] examples/sec: 0.717579\n",
            "INFO:tensorflow:global_step/sec: 0.0225444\n",
            "I0407 14:03:49.596123 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225444\n",
            "INFO:tensorflow:examples/sec: 0.721422\n",
            "I0407 14:03:49.596521 139835423807360 tpu_estimator.py:2160] examples/sec: 0.721422\n",
            "INFO:tensorflow:global_step/sec: 0.0225071\n",
            "I0407 14:04:34.026542 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225071\n",
            "INFO:tensorflow:examples/sec: 0.720226\n",
            "I0407 14:04:34.026961 139835423807360 tpu_estimator.py:2160] examples/sec: 0.720226\n",
            "INFO:tensorflow:global_step/sec: 0.0225151\n",
            "I0407 14:05:18.441197 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225151\n",
            "INFO:tensorflow:examples/sec: 0.720483\n",
            "I0407 14:05:18.442758 139835423807360 tpu_estimator.py:2160] examples/sec: 0.720483\n",
            "INFO:tensorflow:global_step/sec: 0.0226401\n",
            "I0407 14:06:02.610682 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0226401\n",
            "INFO:tensorflow:examples/sec: 0.724482\n",
            "I0407 14:06:02.611168 139835423807360 tpu_estimator.py:2160] examples/sec: 0.724482\n",
            "INFO:tensorflow:global_step/sec: 0.0226851\n",
            "I0407 14:06:46.692589 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0226851\n",
            "INFO:tensorflow:examples/sec: 0.725922\n",
            "I0407 14:06:46.692859 139835423807360 tpu_estimator.py:2160] examples/sec: 0.725922\n",
            "INFO:tensorflow:global_step/sec: 0.0224427\n",
            "I0407 14:07:31.250426 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224427\n",
            "INFO:tensorflow:examples/sec: 0.718167\n",
            "I0407 14:07:31.251668 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718167\n",
            "INFO:tensorflow:global_step/sec: 0.0224682\n",
            "I0407 14:08:15.757774 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224682\n",
            "INFO:tensorflow:examples/sec: 0.718984\n",
            "I0407 14:08:15.758280 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718984\n",
            "INFO:tensorflow:global_step/sec: 0.0224616\n",
            "I0407 14:09:00.278224 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224616\n",
            "INFO:tensorflow:examples/sec: 0.71877\n",
            "I0407 14:09:00.278508 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71877\n",
            "INFO:tensorflow:global_step/sec: 0.0224594\n",
            "I0407 14:09:44.803044 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224594\n",
            "INFO:tensorflow:examples/sec: 0.718701\n",
            "I0407 14:09:44.804224 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718701\n",
            "INFO:tensorflow:global_step/sec: 0.0224132\n",
            "I0407 14:10:29.419653 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224132\n",
            "INFO:tensorflow:examples/sec: 0.717221\n",
            "I0407 14:10:29.420097 139835423807360 tpu_estimator.py:2160] examples/sec: 0.717221\n",
            "INFO:tensorflow:global_step/sec: 0.022532\n",
            "I0407 14:11:13.801142 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022532\n",
            "INFO:tensorflow:examples/sec: 0.721024\n",
            "I0407 14:11:13.801568 139835423807360 tpu_estimator.py:2160] examples/sec: 0.721024\n",
            "INFO:tensorflow:global_step/sec: 0.022609\n",
            "I0407 14:11:58.031188 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022609\n",
            "INFO:tensorflow:examples/sec: 0.723487\n",
            "I0407 14:11:58.032305 139835423807360 tpu_estimator.py:2160] examples/sec: 0.723487\n",
            "INFO:tensorflow:global_step/sec: 0.0222758\n",
            "I0407 14:12:42.922950 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222758\n",
            "INFO:tensorflow:examples/sec: 0.712826\n",
            "I0407 14:12:42.923464 139835423807360 tpu_estimator.py:2160] examples/sec: 0.712826\n",
            "INFO:tensorflow:global_step/sec: 0.0225543\n",
            "I0407 14:13:27.260408 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225543\n",
            "INFO:tensorflow:examples/sec: 0.721738\n",
            "I0407 14:13:27.260839 139835423807360 tpu_estimator.py:2160] examples/sec: 0.721738\n",
            "INFO:tensorflow:global_step/sec: 0.0222149\n",
            "I0407 14:14:12.275260 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222149\n",
            "INFO:tensorflow:examples/sec: 0.710877\n",
            "I0407 14:14:12.275548 139835423807360 tpu_estimator.py:2160] examples/sec: 0.710877\n",
            "INFO:tensorflow:global_step/sec: 0.0220174\n",
            "I0407 14:14:57.693834 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220174\n",
            "INFO:tensorflow:examples/sec: 0.704557\n",
            "I0407 14:14:57.694324 139835423807360 tpu_estimator.py:2160] examples/sec: 0.704557\n",
            "INFO:tensorflow:global_step/sec: 0.0227137\n",
            "I0407 14:15:41.720052 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0227137\n",
            "INFO:tensorflow:examples/sec: 0.726839\n",
            "I0407 14:15:41.720481 139835423807360 tpu_estimator.py:2160] examples/sec: 0.726839\n",
            "INFO:tensorflow:global_step/sec: 0.0224092\n",
            "I0407 14:16:26.344484 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224092\n",
            "INFO:tensorflow:examples/sec: 0.717096\n",
            "I0407 14:16:26.345959 139835423807360 tpu_estimator.py:2160] examples/sec: 0.717096\n",
            "INFO:tensorflow:global_step/sec: 0.0225071\n",
            "I0407 14:17:10.774984 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225071\n",
            "INFO:tensorflow:examples/sec: 0.720227\n",
            "I0407 14:17:10.775416 139835423807360 tpu_estimator.py:2160] examples/sec: 0.720227\n",
            "INFO:tensorflow:global_step/sec: 0.0225776\n",
            "I0407 14:17:55.066691 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225776\n",
            "INFO:tensorflow:examples/sec: 0.722483\n",
            "I0407 14:17:55.067136 139835423807360 tpu_estimator.py:2160] examples/sec: 0.722483\n",
            "INFO:tensorflow:global_step/sec: 0.0224056\n",
            "I0407 14:18:39.698354 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224056\n",
            "INFO:tensorflow:examples/sec: 0.716979\n",
            "I0407 14:18:39.698665 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716979\n",
            "INFO:tensorflow:global_step/sec: 0.0225363\n",
            "I0407 14:19:24.071075 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225363\n",
            "INFO:tensorflow:examples/sec: 0.721163\n",
            "I0407 14:19:24.071465 139835423807360 tpu_estimator.py:2160] examples/sec: 0.721163\n",
            "INFO:tensorflow:global_step/sec: 0.0225125\n",
            "I0407 14:20:08.490778 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225125\n",
            "INFO:tensorflow:examples/sec: 0.7204\n",
            "I0407 14:20:08.491112 139835423807360 tpu_estimator.py:2160] examples/sec: 0.7204\n",
            "INFO:tensorflow:global_step/sec: 0.022284\n",
            "I0407 14:20:53.366109 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022284\n",
            "INFO:tensorflow:examples/sec: 0.713088\n",
            "I0407 14:20:53.367253 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713088\n",
            "INFO:tensorflow:global_step/sec: 0.0223219\n",
            "I0407 14:21:38.165119 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223219\n",
            "INFO:tensorflow:examples/sec: 0.714301\n",
            "I0407 14:21:38.165400 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714301\n",
            "INFO:tensorflow:global_step/sec: 0.0225531\n",
            "I0407 14:22:22.504943 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225531\n",
            "INFO:tensorflow:examples/sec: 0.721699\n",
            "I0407 14:22:22.505231 139835423807360 tpu_estimator.py:2160] examples/sec: 0.721699\n",
            "INFO:tensorflow:global_step/sec: 0.0226219\n",
            "I0407 14:23:06.709925 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0226219\n",
            "INFO:tensorflow:examples/sec: 0.7239\n",
            "I0407 14:23:06.711207 139835423807360 tpu_estimator.py:2160] examples/sec: 0.7239\n",
            "INFO:tensorflow:global_step/sec: 0.0223838\n",
            "I0407 14:23:51.385162 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223838\n",
            "INFO:tensorflow:examples/sec: 0.71628\n",
            "I0407 14:23:51.385484 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71628\n",
            "INFO:tensorflow:global_step/sec: 0.0222968\n",
            "I0407 14:24:36.234823 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222968\n",
            "INFO:tensorflow:examples/sec: 0.713496\n",
            "I0407 14:24:36.235217 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713496\n",
            "INFO:tensorflow:global_step/sec: 0.022391\n",
            "I0407 14:25:20.895602 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022391\n",
            "INFO:tensorflow:examples/sec: 0.716511\n",
            "I0407 14:25:20.896980 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716511\n",
            "INFO:tensorflow:global_step/sec: 0.022641\n",
            "I0407 14:26:05.063259 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022641\n",
            "INFO:tensorflow:examples/sec: 0.724513\n",
            "I0407 14:26:05.063544 139835423807360 tpu_estimator.py:2160] examples/sec: 0.724513\n",
            "INFO:tensorflow:global_step/sec: 0.0222577\n",
            "I0407 14:26:49.991501 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222577\n",
            "INFO:tensorflow:examples/sec: 0.712245\n",
            "I0407 14:26:49.991979 139835423807360 tpu_estimator.py:2160] examples/sec: 0.712245\n",
            "INFO:tensorflow:global_step/sec: 0.0223337\n",
            "I0407 14:27:34.767047 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223337\n",
            "INFO:tensorflow:examples/sec: 0.714678\n",
            "I0407 14:27:34.768547 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714678\n",
            "INFO:tensorflow:global_step/sec: 0.0225286\n",
            "I0407 14:28:19.155012 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225286\n",
            "INFO:tensorflow:examples/sec: 0.720915\n",
            "I0407 14:28:19.155498 139835423807360 tpu_estimator.py:2160] examples/sec: 0.720915\n",
            "INFO:tensorflow:global_step/sec: 0.0222093\n",
            "I0407 14:29:04.181138 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222093\n",
            "INFO:tensorflow:examples/sec: 0.710699\n",
            "I0407 14:29:04.181575 139835423807360 tpu_estimator.py:2160] examples/sec: 0.710699\n",
            "INFO:tensorflow:global_step/sec: 0.0225361\n",
            "I0407 14:29:48.554421 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225361\n",
            "INFO:tensorflow:examples/sec: 0.721155\n",
            "I0407 14:29:48.554692 139835423807360 tpu_estimator.py:2160] examples/sec: 0.721155\n",
            "INFO:tensorflow:global_step/sec: 0.0224022\n",
            "I0407 14:30:33.192786 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224022\n",
            "INFO:tensorflow:examples/sec: 0.716871\n",
            "I0407 14:30:33.193280 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716871\n",
            "INFO:tensorflow:global_step/sec: 0.0224772\n",
            "I0407 14:31:17.682385 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224772\n",
            "INFO:tensorflow:examples/sec: 0.71927\n",
            "I0407 14:31:17.682840 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71927\n",
            "INFO:tensorflow:global_step/sec: 0.0222649\n",
            "I0407 14:32:02.596265 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222649\n",
            "INFO:tensorflow:examples/sec: 0.712475\n",
            "I0407 14:32:02.597731 139835423807360 tpu_estimator.py:2160] examples/sec: 0.712475\n",
            "INFO:tensorflow:global_step/sec: 0.022219\n",
            "I0407 14:32:47.602714 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022219\n",
            "INFO:tensorflow:examples/sec: 0.711008\n",
            "I0407 14:32:47.603200 139835423807360 tpu_estimator.py:2160] examples/sec: 0.711008\n",
            "INFO:tensorflow:global_step/sec: 0.0222519\n",
            "I0407 14:33:32.542647 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222519\n",
            "INFO:tensorflow:examples/sec: 0.712062\n",
            "I0407 14:33:32.542928 139835423807360 tpu_estimator.py:2160] examples/sec: 0.712062\n",
            "INFO:tensorflow:global_step/sec: 0.0224588\n",
            "I0407 14:34:17.068462 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224588\n",
            "INFO:tensorflow:examples/sec: 0.718683\n",
            "I0407 14:34:17.068736 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718683\n",
            "INFO:tensorflow:global_step/sec: 0.0222383\n",
            "I0407 14:35:02.035846 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222383\n",
            "INFO:tensorflow:examples/sec: 0.711627\n",
            "I0407 14:35:02.036180 139835423807360 tpu_estimator.py:2160] examples/sec: 0.711627\n",
            "INFO:tensorflow:global_step/sec: 0.022397\n",
            "I0407 14:35:46.684675 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022397\n",
            "INFO:tensorflow:examples/sec: 0.716705\n",
            "I0407 14:35:46.685127 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716705\n",
            "INFO:tensorflow:global_step/sec: 0.0223813\n",
            "I0407 14:36:31.364832 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223813\n",
            "INFO:tensorflow:examples/sec: 0.716201\n",
            "I0407 14:36:31.365132 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716201\n",
            "INFO:tensorflow:global_step/sec: 0.0221477\n",
            "I0407 14:37:16.516225 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221477\n",
            "INFO:tensorflow:examples/sec: 0.708727\n",
            "I0407 14:37:16.516690 139835423807360 tpu_estimator.py:2160] examples/sec: 0.708727\n",
            "INFO:tensorflow:global_step/sec: 0.0222427\n",
            "I0407 14:38:01.474822 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222427\n",
            "INFO:tensorflow:examples/sec: 0.711765\n",
            "I0407 14:38:01.475290 139835423807360 tpu_estimator.py:2160] examples/sec: 0.711765\n",
            "INFO:tensorflow:global_step/sec: 0.0220823\n",
            "I0407 14:38:46.759930 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220823\n",
            "INFO:tensorflow:examples/sec: 0.706635\n",
            "I0407 14:38:46.761126 139835423807360 tpu_estimator.py:2160] examples/sec: 0.706635\n",
            "INFO:tensorflow:global_step/sec: 0.0222197\n",
            "I0407 14:39:31.765141 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222197\n",
            "INFO:tensorflow:examples/sec: 0.711031\n",
            "I0407 14:39:31.765485 139835423807360 tpu_estimator.py:2160] examples/sec: 0.711031\n",
            "INFO:tensorflow:global_step/sec: 0.0223569\n",
            "I0407 14:40:16.494113 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223569\n",
            "INFO:tensorflow:examples/sec: 0.715419\n",
            "I0407 14:40:16.494554 139835423807360 tpu_estimator.py:2160] examples/sec: 0.715419\n",
            "INFO:tensorflow:global_step/sec: 0.0221951\n",
            "I0407 14:41:01.548938 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221951\n",
            "INFO:tensorflow:examples/sec: 0.710244\n",
            "I0407 14:41:01.550395 139835423807360 tpu_estimator.py:2160] examples/sec: 0.710244\n",
            "INFO:tensorflow:global_step/sec: 0.0225035\n",
            "I0407 14:41:45.986628 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225035\n",
            "INFO:tensorflow:examples/sec: 0.720111\n",
            "I0407 14:41:45.987091 139835423807360 tpu_estimator.py:2160] examples/sec: 0.720111\n",
            "INFO:tensorflow:global_step/sec: 0.0225274\n",
            "I0407 14:42:30.376932 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225274\n",
            "INFO:tensorflow:examples/sec: 0.720877\n",
            "I0407 14:42:30.377403 139835423807360 tpu_estimator.py:2160] examples/sec: 0.720877\n",
            "INFO:tensorflow:global_step/sec: 0.0225815\n",
            "I0407 14:43:14.660976 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225815\n",
            "INFO:tensorflow:examples/sec: 0.722608\n",
            "I0407 14:43:14.662139 139835423807360 tpu_estimator.py:2160] examples/sec: 0.722608\n",
            "INFO:tensorflow:global_step/sec: 0.0224374\n",
            "I0407 14:43:59.229285 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224374\n",
            "INFO:tensorflow:examples/sec: 0.717998\n",
            "I0407 14:43:59.229707 139835423807360 tpu_estimator.py:2160] examples/sec: 0.717998\n",
            "INFO:tensorflow:global_step/sec: 0.0224888\n",
            "I0407 14:44:43.696022 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224888\n",
            "INFO:tensorflow:examples/sec: 0.71964\n",
            "I0407 14:44:43.696298 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71964\n",
            "INFO:tensorflow:global_step/sec: 0.0223196\n",
            "I0407 14:45:28.499691 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223196\n",
            "INFO:tensorflow:examples/sec: 0.714226\n",
            "I0407 14:45:28.500981 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714226\n",
            "INFO:tensorflow:global_step/sec: 0.022327\n",
            "I0407 14:46:13.288526 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022327\n",
            "INFO:tensorflow:examples/sec: 0.714464\n",
            "I0407 14:46:13.288976 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714464\n",
            "INFO:tensorflow:global_step/sec: 0.0222504\n",
            "I0407 14:46:58.231554 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222504\n",
            "INFO:tensorflow:examples/sec: 0.712013\n",
            "I0407 14:46:58.232002 139835423807360 tpu_estimator.py:2160] examples/sec: 0.712013\n",
            "INFO:tensorflow:global_step/sec: 0.0225516\n",
            "I0407 14:47:42.574236 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225516\n",
            "INFO:tensorflow:examples/sec: 0.721652\n",
            "I0407 14:47:42.574502 139835423807360 tpu_estimator.py:2160] examples/sec: 0.721652\n",
            "INFO:tensorflow:global_step/sec: 0.0222296\n",
            "I0407 14:48:27.559313 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222296\n",
            "INFO:tensorflow:examples/sec: 0.711348\n",
            "I0407 14:48:27.559749 139835423807360 tpu_estimator.py:2160] examples/sec: 0.711348\n",
            "INFO:tensorflow:global_step/sec: 0.0222434\n",
            "I0407 14:49:12.516555 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222434\n",
            "INFO:tensorflow:examples/sec: 0.711788\n",
            "I0407 14:49:12.517007 139835423807360 tpu_estimator.py:2160] examples/sec: 0.711788\n",
            "INFO:tensorflow:global_step/sec: 0.0225302\n",
            "I0407 14:49:56.901404 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225302\n",
            "INFO:tensorflow:examples/sec: 0.720965\n",
            "I0407 14:49:56.902535 139835423807360 tpu_estimator.py:2160] examples/sec: 0.720965\n",
            "INFO:tensorflow:global_step/sec: 0.0223337\n",
            "I0407 14:50:41.676731 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223337\n",
            "INFO:tensorflow:examples/sec: 0.714679\n",
            "I0407 14:50:41.677203 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714679\n",
            "INFO:tensorflow:global_step/sec: 0.0224975\n",
            "I0407 14:51:26.126142 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224975\n",
            "INFO:tensorflow:examples/sec: 0.719921\n",
            "I0407 14:51:26.126637 139835423807360 tpu_estimator.py:2160] examples/sec: 0.719921\n",
            "INFO:tensorflow:global_step/sec: 0.0223841\n",
            "I0407 14:52:10.800587 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223841\n",
            "INFO:tensorflow:examples/sec: 0.716291\n",
            "I0407 14:52:10.801989 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716291\n",
            "INFO:tensorflow:global_step/sec: 0.0223217\n",
            "I0407 14:52:55.600048 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223217\n",
            "INFO:tensorflow:examples/sec: 0.714295\n",
            "I0407 14:52:55.600535 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714295\n",
            "INFO:tensorflow:global_step/sec: 0.0224574\n",
            "I0407 14:53:40.128764 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224574\n",
            "INFO:tensorflow:examples/sec: 0.718637\n",
            "I0407 14:53:40.129313 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718637\n",
            "INFO:tensorflow:global_step/sec: 0.022382\n",
            "I0407 14:54:24.807424 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022382\n",
            "INFO:tensorflow:examples/sec: 0.716225\n",
            "I0407 14:54:24.808943 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716225\n",
            "INFO:tensorflow:global_step/sec: 0.0225195\n",
            "I0407 14:55:09.213452 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225195\n",
            "INFO:tensorflow:examples/sec: 0.720623\n",
            "I0407 14:55:09.213903 139835423807360 tpu_estimator.py:2160] examples/sec: 0.720623\n",
            "INFO:tensorflow:global_step/sec: 0.0223984\n",
            "I0407 14:55:53.859657 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223984\n",
            "INFO:tensorflow:examples/sec: 0.716748\n",
            "I0407 14:55:53.860155 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716748\n",
            "INFO:tensorflow:global_step/sec: 0.0223171\n",
            "I0407 14:56:38.668250 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223171\n",
            "INFO:tensorflow:examples/sec: 0.714147\n",
            "I0407 14:56:38.669485 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714147\n",
            "INFO:tensorflow:global_step/sec: 0.0223745\n",
            "I0407 14:57:23.362097 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223745\n",
            "INFO:tensorflow:examples/sec: 0.715985\n",
            "I0407 14:57:23.362533 139835423807360 tpu_estimator.py:2160] examples/sec: 0.715985\n",
            "INFO:tensorflow:global_step/sec: 0.0224928\n",
            "I0407 14:58:07.820678 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224928\n",
            "INFO:tensorflow:examples/sec: 0.719769\n",
            "I0407 14:58:07.821126 139835423807360 tpu_estimator.py:2160] examples/sec: 0.719769\n",
            "INFO:tensorflow:global_step/sec: 0.0222865\n",
            "I0407 14:58:52.691030 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222865\n",
            "INFO:tensorflow:examples/sec: 0.713167\n",
            "I0407 14:58:52.691314 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713167\n",
            "INFO:tensorflow:global_step/sec: 0.0225187\n",
            "I0407 14:59:37.098631 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225187\n",
            "INFO:tensorflow:examples/sec: 0.720597\n",
            "I0407 14:59:37.099341 139835423807360 tpu_estimator.py:2160] examples/sec: 0.720597\n",
            "INFO:tensorflow:global_step/sec: 0.0222911\n",
            "I0407 15:00:21.959677 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222911\n",
            "INFO:tensorflow:examples/sec: 0.713314\n",
            "I0407 15:00:21.960083 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713314\n",
            "INFO:tensorflow:global_step/sec: 0.0223287\n",
            "I0407 15:01:06.745203 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223287\n",
            "INFO:tensorflow:examples/sec: 0.714517\n",
            "I0407 15:01:06.746520 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714517\n",
            "INFO:tensorflow:global_step/sec: 0.022302\n",
            "I0407 15:01:51.584293 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022302\n",
            "INFO:tensorflow:examples/sec: 0.713662\n",
            "I0407 15:01:51.584605 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713662\n",
            "INFO:tensorflow:global_step/sec: 0.0221219\n",
            "I0407 15:02:36.788488 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221219\n",
            "INFO:tensorflow:examples/sec: 0.707901\n",
            "I0407 15:02:36.789104 139835423807360 tpu_estimator.py:2160] examples/sec: 0.707901\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 200 vs previous value: 200. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "W0407 15:02:36.789282 139835423807360 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 200 vs previous value: 200. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 0.0216686\n",
            "I0407 15:03:22.938121 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0216686\n",
            "INFO:tensorflow:examples/sec: 0.693395\n",
            "I0407 15:03:22.938450 139835423807360 tpu_estimator.py:2160] examples/sec: 0.693395\n",
            "INFO:tensorflow:global_step/sec: 0.02157\n",
            "I0407 15:04:09.298963 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.02157\n",
            "INFO:tensorflow:examples/sec: 0.690239\n",
            "I0407 15:04:09.299248 139835423807360 tpu_estimator.py:2160] examples/sec: 0.690239\n",
            "INFO:tensorflow:global_step/sec: 0.0216527\n",
            "I0407 15:04:55.482462 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0216527\n",
            "INFO:tensorflow:examples/sec: 0.692886\n",
            "I0407 15:04:55.482936 139835423807360 tpu_estimator.py:2160] examples/sec: 0.692886\n",
            "INFO:tensorflow:global_step/sec: 0.0212904\n",
            "I0407 15:05:42.452035 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0212904\n",
            "INFO:tensorflow:examples/sec: 0.681293\n",
            "I0407 15:05:42.453934 139835423807360 tpu_estimator.py:2160] examples/sec: 0.681293\n",
            "INFO:tensorflow:global_step/sec: 0.0215717\n",
            "I0407 15:06:28.809062 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0215717\n",
            "INFO:tensorflow:examples/sec: 0.690294\n",
            "I0407 15:06:28.809417 139835423807360 tpu_estimator.py:2160] examples/sec: 0.690294\n",
            "INFO:tensorflow:global_step/sec: 0.0212798\n",
            "I0407 15:07:15.802169 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0212798\n",
            "INFO:tensorflow:examples/sec: 0.680952\n",
            "I0407 15:07:15.802463 139835423807360 tpu_estimator.py:2160] examples/sec: 0.680952\n",
            "INFO:tensorflow:global_step/sec: 0.021353\n",
            "I0407 15:08:02.633997 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.021353\n",
            "INFO:tensorflow:examples/sec: 0.683295\n",
            "I0407 15:08:02.635111 139835423807360 tpu_estimator.py:2160] examples/sec: 0.683295\n",
            "INFO:tensorflow:global_step/sec: 0.0214232\n",
            "I0407 15:08:49.312484 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0214232\n",
            "INFO:tensorflow:examples/sec: 0.685541\n",
            "I0407 15:08:49.312998 139835423807360 tpu_estimator.py:2160] examples/sec: 0.685541\n",
            "INFO:tensorflow:global_step/sec: 0.0217249\n",
            "I0407 15:09:35.342573 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0217249\n",
            "INFO:tensorflow:examples/sec: 0.695198\n",
            "I0407 15:09:35.343106 139835423807360 tpu_estimator.py:2160] examples/sec: 0.695198\n",
            "INFO:tensorflow:global_step/sec: 0.0216461\n",
            "I0407 15:10:21.540229 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0216461\n",
            "INFO:tensorflow:examples/sec: 0.692676\n",
            "I0407 15:10:21.541463 139835423807360 tpu_estimator.py:2160] examples/sec: 0.692676\n",
            "INFO:tensorflow:global_step/sec: 0.0217344\n",
            "I0407 15:11:07.550115 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0217344\n",
            "INFO:tensorflow:examples/sec: 0.695502\n",
            "I0407 15:11:07.550587 139835423807360 tpu_estimator.py:2160] examples/sec: 0.695502\n",
            "INFO:tensorflow:global_step/sec: 0.021844\n",
            "I0407 15:11:53.329272 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.021844\n",
            "INFO:tensorflow:examples/sec: 0.699009\n",
            "I0407 15:11:53.329708 139835423807360 tpu_estimator.py:2160] examples/sec: 0.699009\n",
            "INFO:tensorflow:global_step/sec: 0.0213659\n",
            "I0407 15:12:40.132776 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0213659\n",
            "INFO:tensorflow:examples/sec: 0.683709\n",
            "I0407 15:12:40.134073 139835423807360 tpu_estimator.py:2160] examples/sec: 0.683709\n",
            "INFO:tensorflow:global_step/sec: 0.0216912\n",
            "I0407 15:13:26.234568 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0216912\n",
            "INFO:tensorflow:examples/sec: 0.694117\n",
            "I0407 15:13:26.235022 139835423807360 tpu_estimator.py:2160] examples/sec: 0.694117\n",
            "INFO:tensorflow:global_step/sec: 0.0218359\n",
            "I0407 15:14:12.030557 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218359\n",
            "INFO:tensorflow:examples/sec: 0.69875\n",
            "I0407 15:14:12.030837 139835423807360 tpu_estimator.py:2160] examples/sec: 0.69875\n",
            "INFO:tensorflow:global_step/sec: 0.021537\n",
            "I0407 15:14:58.462370 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.021537\n",
            "INFO:tensorflow:examples/sec: 0.689184\n",
            "I0407 15:14:58.463693 139835423807360 tpu_estimator.py:2160] examples/sec: 0.689184\n",
            "INFO:tensorflow:global_step/sec: 0.0218342\n",
            "I0407 15:15:44.262103 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218342\n",
            "INFO:tensorflow:examples/sec: 0.698693\n",
            "I0407 15:15:44.262710 139835423807360 tpu_estimator.py:2160] examples/sec: 0.698693\n",
            "INFO:tensorflow:global_step/sec: 0.0218171\n",
            "I0407 15:16:30.097718 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218171\n",
            "INFO:tensorflow:examples/sec: 0.698148\n",
            "I0407 15:16:30.098199 139835423807360 tpu_estimator.py:2160] examples/sec: 0.698148\n",
            "INFO:tensorflow:global_step/sec: 0.0216426\n",
            "I0407 15:17:16.302852 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0216426\n",
            "INFO:tensorflow:examples/sec: 0.692564\n",
            "I0407 15:17:16.304215 139835423807360 tpu_estimator.py:2160] examples/sec: 0.692564\n",
            "INFO:tensorflow:global_step/sec: 0.0217722\n",
            "I0407 15:18:02.233024 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0217722\n",
            "INFO:tensorflow:examples/sec: 0.696709\n",
            "I0407 15:18:02.233456 139835423807360 tpu_estimator.py:2160] examples/sec: 0.696709\n",
            "INFO:tensorflow:global_step/sec: 0.0217336\n",
            "I0407 15:18:48.244674 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0217336\n",
            "INFO:tensorflow:examples/sec: 0.695476\n",
            "I0407 15:18:48.245128 139835423807360 tpu_estimator.py:2160] examples/sec: 0.695476\n",
            "INFO:tensorflow:global_step/sec: 0.0220217\n",
            "I0407 15:19:33.654525 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220217\n",
            "INFO:tensorflow:examples/sec: 0.704694\n",
            "I0407 15:19:33.656058 139835423807360 tpu_estimator.py:2160] examples/sec: 0.704694\n",
            "INFO:tensorflow:global_step/sec: 0.0219397\n",
            "I0407 15:20:19.233920 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219397\n",
            "INFO:tensorflow:examples/sec: 0.702071\n",
            "I0407 15:20:19.234379 139835423807360 tpu_estimator.py:2160] examples/sec: 0.702071\n",
            "INFO:tensorflow:global_step/sec: 0.0218497\n",
            "I0407 15:21:05.001180 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218497\n",
            "INFO:tensorflow:examples/sec: 0.699189\n",
            "I0407 15:21:05.001698 139835423807360 tpu_estimator.py:2160] examples/sec: 0.699189\n",
            "INFO:tensorflow:global_step/sec: 0.0220849\n",
            "I0407 15:21:50.280999 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220849\n",
            "INFO:tensorflow:examples/sec: 0.706717\n",
            "I0407 15:21:50.282181 139835423807360 tpu_estimator.py:2160] examples/sec: 0.706717\n",
            "INFO:tensorflow:global_step/sec: 0.021817\n",
            "I0407 15:22:36.116811 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.021817\n",
            "INFO:tensorflow:examples/sec: 0.698143\n",
            "I0407 15:22:36.117327 139835423807360 tpu_estimator.py:2160] examples/sec: 0.698143\n",
            "INFO:tensorflow:global_step/sec: 0.0219739\n",
            "I0407 15:23:21.625288 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219739\n",
            "INFO:tensorflow:examples/sec: 0.703166\n",
            "I0407 15:23:21.625758 139835423807360 tpu_estimator.py:2160] examples/sec: 0.703166\n",
            "INFO:tensorflow:global_step/sec: 0.0219216\n",
            "I0407 15:24:07.242393 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219216\n",
            "INFO:tensorflow:examples/sec: 0.701492\n",
            "I0407 15:24:07.243627 139835423807360 tpu_estimator.py:2160] examples/sec: 0.701492\n",
            "INFO:tensorflow:global_step/sec: 0.0219968\n",
            "I0407 15:24:52.703618 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219968\n",
            "INFO:tensorflow:examples/sec: 0.703896\n",
            "I0407 15:24:52.704095 139835423807360 tpu_estimator.py:2160] examples/sec: 0.703896\n",
            "INFO:tensorflow:global_step/sec: 0.0223173\n",
            "I0407 15:25:37.511964 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223173\n",
            "INFO:tensorflow:examples/sec: 0.714153\n",
            "I0407 15:25:37.512471 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714153\n",
            "INFO:tensorflow:global_step/sec: 0.0221913\n",
            "I0407 15:26:22.574694 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221913\n",
            "INFO:tensorflow:examples/sec: 0.71012\n",
            "I0407 15:26:22.575932 139835423807360 tpu_estimator.py:2160] examples/sec: 0.71012\n",
            "INFO:tensorflow:global_step/sec: 0.0221295\n",
            "I0407 15:27:07.763194 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221295\n",
            "INFO:tensorflow:examples/sec: 0.708145\n",
            "I0407 15:27:07.763668 139835423807360 tpu_estimator.py:2160] examples/sec: 0.708145\n",
            "INFO:tensorflow:global_step/sec: 0.0222483\n",
            "I0407 15:27:52.710511 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222483\n",
            "INFO:tensorflow:examples/sec: 0.711945\n",
            "I0407 15:27:52.710969 139835423807360 tpu_estimator.py:2160] examples/sec: 0.711945\n",
            "INFO:tensorflow:global_step/sec: 0.0221509\n",
            "I0407 15:28:37.855426 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221509\n",
            "INFO:tensorflow:examples/sec: 0.708828\n",
            "I0407 15:28:37.856971 139835423807360 tpu_estimator.py:2160] examples/sec: 0.708828\n",
            "INFO:tensorflow:global_step/sec: 0.0222923\n",
            "I0407 15:29:22.714061 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222923\n",
            "INFO:tensorflow:examples/sec: 0.713353\n",
            "I0407 15:29:22.714531 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713353\n",
            "INFO:tensorflow:global_step/sec: 0.0221959\n",
            "I0407 15:30:07.767337 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221959\n",
            "INFO:tensorflow:examples/sec: 0.710269\n",
            "I0407 15:30:07.767770 139835423807360 tpu_estimator.py:2160] examples/sec: 0.710269\n",
            "INFO:tensorflow:global_step/sec: 0.0219285\n",
            "I0407 15:30:53.370180 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219285\n",
            "INFO:tensorflow:examples/sec: 0.701711\n",
            "I0407 15:30:53.371685 139835423807360 tpu_estimator.py:2160] examples/sec: 0.701711\n",
            "INFO:tensorflow:global_step/sec: 0.0220598\n",
            "I0407 15:31:38.701626 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220598\n",
            "INFO:tensorflow:examples/sec: 0.705913\n",
            "I0407 15:31:38.702166 139835423807360 tpu_estimator.py:2160] examples/sec: 0.705913\n",
            "INFO:tensorflow:global_step/sec: 0.0220982\n",
            "I0407 15:32:23.954235 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220982\n",
            "INFO:tensorflow:examples/sec: 0.707142\n",
            "I0407 15:32:23.954713 139835423807360 tpu_estimator.py:2160] examples/sec: 0.707142\n",
            "INFO:tensorflow:global_step/sec: 0.022218\n",
            "I0407 15:33:08.962876 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022218\n",
            "INFO:tensorflow:examples/sec: 0.710975\n",
            "I0407 15:33:08.964170 139835423807360 tpu_estimator.py:2160] examples/sec: 0.710975\n",
            "INFO:tensorflow:global_step/sec: 0.0218425\n",
            "I0407 15:33:54.745291 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218425\n",
            "INFO:tensorflow:examples/sec: 0.69896\n",
            "I0407 15:33:54.745610 139835423807360 tpu_estimator.py:2160] examples/sec: 0.69896\n",
            "INFO:tensorflow:global_step/sec: 0.0219247\n",
            "I0407 15:34:40.355772 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219247\n",
            "INFO:tensorflow:examples/sec: 0.70159\n",
            "I0407 15:34:40.356245 139835423807360 tpu_estimator.py:2160] examples/sec: 0.70159\n",
            "INFO:tensorflow:global_step/sec: 0.0219311\n",
            "I0407 15:35:25.953071 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219311\n",
            "INFO:tensorflow:examples/sec: 0.701796\n",
            "I0407 15:35:25.954223 139835423807360 tpu_estimator.py:2160] examples/sec: 0.701796\n",
            "INFO:tensorflow:global_step/sec: 0.0220262\n",
            "I0407 15:36:11.353525 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220262\n",
            "INFO:tensorflow:examples/sec: 0.70484\n",
            "I0407 15:36:11.353991 139835423807360 tpu_estimator.py:2160] examples/sec: 0.70484\n",
            "INFO:tensorflow:global_step/sec: 0.0219698\n",
            "I0407 15:36:56.870527 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219698\n",
            "INFO:tensorflow:examples/sec: 0.703033\n",
            "I0407 15:36:56.870997 139835423807360 tpu_estimator.py:2160] examples/sec: 0.703033\n",
            "INFO:tensorflow:global_step/sec: 0.0218381\n",
            "I0407 15:37:42.662007 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218381\n",
            "INFO:tensorflow:examples/sec: 0.69882\n",
            "I0407 15:37:42.663747 139835423807360 tpu_estimator.py:2160] examples/sec: 0.69882\n",
            "INFO:tensorflow:global_step/sec: 0.0217431\n",
            "I0407 15:38:28.653623 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0217431\n",
            "INFO:tensorflow:examples/sec: 0.695779\n",
            "I0407 15:38:28.654098 139835423807360 tpu_estimator.py:2160] examples/sec: 0.695779\n",
            "INFO:tensorflow:global_step/sec: 0.0217269\n",
            "I0407 15:39:14.679643 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0217269\n",
            "INFO:tensorflow:examples/sec: 0.69526\n",
            "I0407 15:39:14.680104 139835423807360 tpu_estimator.py:2160] examples/sec: 0.69526\n",
            "INFO:tensorflow:global_step/sec: 0.0219102\n",
            "I0407 15:40:00.320398 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219102\n",
            "INFO:tensorflow:examples/sec: 0.701126\n",
            "I0407 15:40:00.321659 139835423807360 tpu_estimator.py:2160] examples/sec: 0.701126\n",
            "INFO:tensorflow:global_step/sec: 0.0217695\n",
            "I0407 15:40:46.256243 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0217695\n",
            "INFO:tensorflow:examples/sec: 0.696624\n",
            "I0407 15:40:46.256585 139835423807360 tpu_estimator.py:2160] examples/sec: 0.696624\n",
            "INFO:tensorflow:global_step/sec: 0.0218534\n",
            "I0407 15:41:32.015717 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218534\n",
            "INFO:tensorflow:examples/sec: 0.699309\n",
            "I0407 15:41:32.016202 139835423807360 tpu_estimator.py:2160] examples/sec: 0.699309\n",
            "INFO:tensorflow:global_step/sec: 0.0218619\n",
            "I0407 15:42:17.757326 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218619\n",
            "INFO:tensorflow:examples/sec: 0.699582\n",
            "I0407 15:42:17.758901 139835423807360 tpu_estimator.py:2160] examples/sec: 0.699582\n",
            "INFO:tensorflow:global_step/sec: 0.0218832\n",
            "I0407 15:43:03.454654 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218832\n",
            "INFO:tensorflow:examples/sec: 0.700261\n",
            "I0407 15:43:03.455139 139835423807360 tpu_estimator.py:2160] examples/sec: 0.700261\n",
            "INFO:tensorflow:global_step/sec: 0.0221191\n",
            "I0407 15:43:48.664352 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221191\n",
            "INFO:tensorflow:examples/sec: 0.707811\n",
            "I0407 15:43:48.664642 139835423807360 tpu_estimator.py:2160] examples/sec: 0.707811\n",
            "INFO:tensorflow:global_step/sec: 0.0221339\n",
            "I0407 15:44:33.844096 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221339\n",
            "INFO:tensorflow:examples/sec: 0.708285\n",
            "I0407 15:44:33.845538 139835423807360 tpu_estimator.py:2160] examples/sec: 0.708285\n",
            "INFO:tensorflow:global_step/sec: 0.0217746\n",
            "I0407 15:45:19.768987 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0217746\n",
            "INFO:tensorflow:examples/sec: 0.696788\n",
            "I0407 15:45:19.769450 139835423807360 tpu_estimator.py:2160] examples/sec: 0.696788\n",
            "INFO:tensorflow:global_step/sec: 0.0217779\n",
            "I0407 15:46:05.687186 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0217779\n",
            "INFO:tensorflow:examples/sec: 0.696893\n",
            "I0407 15:46:05.687659 139835423807360 tpu_estimator.py:2160] examples/sec: 0.696893\n",
            "INFO:tensorflow:global_step/sec: 0.0218623\n",
            "I0407 15:46:51.427975 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218623\n",
            "INFO:tensorflow:examples/sec: 0.699594\n",
            "I0407 15:46:51.429524 139835423807360 tpu_estimator.py:2160] examples/sec: 0.699594\n",
            "INFO:tensorflow:global_step/sec: 0.0220072\n",
            "I0407 15:47:36.867527 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220072\n",
            "INFO:tensorflow:examples/sec: 0.70423\n",
            "I0407 15:47:36.867972 139835423807360 tpu_estimator.py:2160] examples/sec: 0.70423\n",
            "INFO:tensorflow:global_step/sec: 0.0220493\n",
            "I0407 15:48:22.220517 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220493\n",
            "INFO:tensorflow:examples/sec: 0.705577\n",
            "I0407 15:48:22.220782 139835423807360 tpu_estimator.py:2160] examples/sec: 0.705577\n",
            "INFO:tensorflow:global_step/sec: 0.0217415\n",
            "I0407 15:49:08.215636 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0217415\n",
            "INFO:tensorflow:examples/sec: 0.695727\n",
            "I0407 15:49:08.217157 139835423807360 tpu_estimator.py:2160] examples/sec: 0.695727\n",
            "INFO:tensorflow:global_step/sec: 0.0216886\n",
            "I0407 15:49:54.322911 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0216886\n",
            "INFO:tensorflow:examples/sec: 0.694035\n",
            "I0407 15:49:54.323385 139835423807360 tpu_estimator.py:2160] examples/sec: 0.694035\n",
            "INFO:tensorflow:global_step/sec: 0.021777\n",
            "I0407 15:50:40.242837 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.021777\n",
            "INFO:tensorflow:examples/sec: 0.696863\n",
            "I0407 15:50:40.243287 139835423807360 tpu_estimator.py:2160] examples/sec: 0.696863\n",
            "INFO:tensorflow:global_step/sec: 0.0220139\n",
            "I0407 15:51:25.668785 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220139\n",
            "INFO:tensorflow:examples/sec: 0.704444\n",
            "I0407 15:51:25.669997 139835423807360 tpu_estimator.py:2160] examples/sec: 0.704444\n",
            "INFO:tensorflow:global_step/sec: 0.0218312\n",
            "I0407 15:52:11.474769 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218312\n",
            "INFO:tensorflow:examples/sec: 0.698598\n",
            "I0407 15:52:11.475222 139835423807360 tpu_estimator.py:2160] examples/sec: 0.698598\n",
            "INFO:tensorflow:global_step/sec: 0.0221057\n",
            "I0407 15:52:56.712097 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221057\n",
            "INFO:tensorflow:examples/sec: 0.707383\n",
            "I0407 15:52:56.712625 139835423807360 tpu_estimator.py:2160] examples/sec: 0.707383\n",
            "INFO:tensorflow:global_step/sec: 0.0221125\n",
            "I0407 15:53:41.935172 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221125\n",
            "INFO:tensorflow:examples/sec: 0.707601\n",
            "I0407 15:53:41.937122 139835423807360 tpu_estimator.py:2160] examples/sec: 0.707601\n",
            "INFO:tensorflow:global_step/sec: 0.0220597\n",
            "I0407 15:54:27.266611 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220597\n",
            "INFO:tensorflow:examples/sec: 0.70591\n",
            "I0407 15:54:27.266903 139835423807360 tpu_estimator.py:2160] examples/sec: 0.70591\n",
            "INFO:tensorflow:global_step/sec: 0.0220142\n",
            "I0407 15:55:12.691938 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220142\n",
            "INFO:tensorflow:examples/sec: 0.704456\n",
            "I0407 15:55:12.692214 139835423807360 tpu_estimator.py:2160] examples/sec: 0.704456\n",
            "INFO:tensorflow:global_step/sec: 0.0220586\n",
            "I0407 15:55:58.025645 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220586\n",
            "INFO:tensorflow:examples/sec: 0.705874\n",
            "I0407 15:55:58.027173 139835423807360 tpu_estimator.py:2160] examples/sec: 0.705874\n",
            "INFO:tensorflow:global_step/sec: 0.0219542\n",
            "I0407 15:56:43.575012 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219542\n",
            "INFO:tensorflow:examples/sec: 0.702535\n",
            "I0407 15:56:43.575445 139835423807360 tpu_estimator.py:2160] examples/sec: 0.702535\n",
            "INFO:tensorflow:global_step/sec: 0.0223184\n",
            "I0407 15:57:28.381201 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223184\n",
            "INFO:tensorflow:examples/sec: 0.714188\n",
            "I0407 15:57:28.381646 139835423807360 tpu_estimator.py:2160] examples/sec: 0.714188\n",
            "INFO:tensorflow:global_step/sec: 0.0222543\n",
            "I0407 15:58:13.316199 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222543\n",
            "INFO:tensorflow:examples/sec: 0.712139\n",
            "I0407 15:58:13.317848 139835423807360 tpu_estimator.py:2160] examples/sec: 0.712139\n",
            "INFO:tensorflow:global_step/sec: 0.0222067\n",
            "I0407 15:58:58.347756 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222067\n",
            "INFO:tensorflow:examples/sec: 0.710614\n",
            "I0407 15:58:58.348043 139835423807360 tpu_estimator.py:2160] examples/sec: 0.710614\n",
            "INFO:tensorflow:global_step/sec: 0.0223098\n",
            "I0407 15:59:43.171051 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223098\n",
            "INFO:tensorflow:examples/sec: 0.713913\n",
            "I0407 15:59:43.171453 139835423807360 tpu_estimator.py:2160] examples/sec: 0.713913\n",
            "INFO:tensorflow:global_step/sec: 0.0223505\n",
            "I0407 16:00:27.912842 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223505\n",
            "INFO:tensorflow:examples/sec: 0.715215\n",
            "I0407 16:00:27.914391 139835423807360 tpu_estimator.py:2160] examples/sec: 0.715215\n",
            "INFO:tensorflow:global_step/sec: 0.0224242\n",
            "I0407 16:01:12.507763 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224242\n",
            "INFO:tensorflow:examples/sec: 0.717573\n",
            "I0407 16:01:12.508192 139835423807360 tpu_estimator.py:2160] examples/sec: 0.717573\n",
            "INFO:tensorflow:global_step/sec: 0.0222421\n",
            "I0407 16:01:57.467399 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222421\n",
            "INFO:tensorflow:examples/sec: 0.711747\n",
            "I0407 16:01:57.467932 139835423807360 tpu_estimator.py:2160] examples/sec: 0.711747\n",
            "INFO:tensorflow:global_step/sec: 0.0220311\n",
            "I0407 16:02:42.857705 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220311\n",
            "INFO:tensorflow:examples/sec: 0.704996\n",
            "I0407 16:02:42.858904 139835423807360 tpu_estimator.py:2160] examples/sec: 0.704996\n",
            "INFO:tensorflow:global_step/sec: 0.0220154\n",
            "I0407 16:03:28.280529 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220154\n",
            "INFO:tensorflow:examples/sec: 0.704492\n",
            "I0407 16:03:28.280953 139835423807360 tpu_estimator.py:2160] examples/sec: 0.704492\n",
            "INFO:tensorflow:global_step/sec: 0.0220225\n",
            "I0407 16:04:13.688677 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220225\n",
            "INFO:tensorflow:examples/sec: 0.704719\n",
            "I0407 16:04:13.689113 139835423807360 tpu_estimator.py:2160] examples/sec: 0.704719\n",
            "INFO:tensorflow:global_step/sec: 0.0218182\n",
            "I0407 16:04:59.522131 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218182\n",
            "INFO:tensorflow:examples/sec: 0.698181\n",
            "I0407 16:04:59.523408 139835423807360 tpu_estimator.py:2160] examples/sec: 0.698181\n",
            "INFO:tensorflow:global_step/sec: 0.0219282\n",
            "I0407 16:05:45.125421 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219282\n",
            "INFO:tensorflow:examples/sec: 0.701703\n",
            "I0407 16:05:45.125983 139835423807360 tpu_estimator.py:2160] examples/sec: 0.701703\n",
            "INFO:tensorflow:global_step/sec: 0.0220007\n",
            "I0407 16:06:30.578489 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220007\n",
            "INFO:tensorflow:examples/sec: 0.704023\n",
            "I0407 16:06:30.578944 139835423807360 tpu_estimator.py:2160] examples/sec: 0.704023\n",
            "INFO:tensorflow:global_step/sec: 0.0219318\n",
            "I0407 16:07:16.174386 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219318\n",
            "INFO:tensorflow:examples/sec: 0.701818\n",
            "I0407 16:07:16.175585 139835423807360 tpu_estimator.py:2160] examples/sec: 0.701818\n",
            "INFO:tensorflow:global_step/sec: 0.0220518\n",
            "I0407 16:08:01.522127 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220518\n",
            "INFO:tensorflow:examples/sec: 0.705658\n",
            "I0407 16:08:01.522412 139835423807360 tpu_estimator.py:2160] examples/sec: 0.705658\n",
            "INFO:tensorflow:global_step/sec: 0.0215578\n",
            "I0407 16:08:47.908951 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0215578\n",
            "INFO:tensorflow:examples/sec: 0.68985\n",
            "I0407 16:08:47.909416 139835423807360 tpu_estimator.py:2160] examples/sec: 0.68985\n",
            "INFO:tensorflow:global_step/sec: 0.0219252\n",
            "I0407 16:09:33.518483 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219252\n",
            "INFO:tensorflow:examples/sec: 0.701607\n",
            "I0407 16:09:33.519669 139835423807360 tpu_estimator.py:2160] examples/sec: 0.701607\n",
            "INFO:tensorflow:global_step/sec: 0.0221772\n",
            "I0407 16:10:18.609787 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221772\n",
            "INFO:tensorflow:examples/sec: 0.709671\n",
            "I0407 16:10:18.610167 139835423807360 tpu_estimator.py:2160] examples/sec: 0.709671\n",
            "INFO:tensorflow:global_step/sec: 0.02201\n",
            "I0407 16:11:04.043705 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.02201\n",
            "INFO:tensorflow:examples/sec: 0.70432\n",
            "I0407 16:11:04.044221 139835423807360 tpu_estimator.py:2160] examples/sec: 0.70432\n",
            "INFO:tensorflow:global_step/sec: 0.0221712\n",
            "I0407 16:11:49.147295 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221712\n",
            "INFO:tensorflow:examples/sec: 0.709478\n",
            "I0407 16:11:49.148526 139835423807360 tpu_estimator.py:2160] examples/sec: 0.709478\n",
            "INFO:tensorflow:global_step/sec: 0.0220986\n",
            "I0407 16:12:34.398963 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220986\n",
            "INFO:tensorflow:examples/sec: 0.707156\n",
            "I0407 16:12:34.399396 139835423807360 tpu_estimator.py:2160] examples/sec: 0.707156\n",
            "INFO:tensorflow:global_step/sec: 0.0220683\n",
            "I0407 16:13:19.712720 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220683\n",
            "INFO:tensorflow:examples/sec: 0.706187\n",
            "I0407 16:13:19.713181 139835423807360 tpu_estimator.py:2160] examples/sec: 0.706187\n",
            "INFO:tensorflow:global_step/sec: 0.0218458\n",
            "I0407 16:14:05.488093 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218458\n",
            "INFO:tensorflow:examples/sec: 0.699066\n",
            "I0407 16:14:05.489709 139835423807360 tpu_estimator.py:2160] examples/sec: 0.699066\n",
            "INFO:tensorflow:global_step/sec: 0.0218118\n",
            "I0407 16:14:51.334939 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0218118\n",
            "INFO:tensorflow:examples/sec: 0.697976\n",
            "I0407 16:14:51.335415 139835423807360 tpu_estimator.py:2160] examples/sec: 0.697976\n",
            "INFO:tensorflow:global_step/sec: 0.0221168\n",
            "I0407 16:15:36.549367 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221168\n",
            "INFO:tensorflow:examples/sec: 0.707739\n",
            "I0407 16:15:36.549780 139835423807360 tpu_estimator.py:2160] examples/sec: 0.707739\n",
            "INFO:tensorflow:global_step/sec: 0.0222675\n",
            "I0407 16:16:21.457943 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222675\n",
            "INFO:tensorflow:examples/sec: 0.712559\n",
            "I0407 16:16:21.459051 139835423807360 tpu_estimator.py:2160] examples/sec: 0.712559\n",
            "INFO:tensorflow:global_step/sec: 0.0221294\n",
            "I0407 16:17:06.646668 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221294\n",
            "INFO:tensorflow:examples/sec: 0.708141\n",
            "I0407 16:17:06.647121 139835423807360 tpu_estimator.py:2160] examples/sec: 0.708141\n",
            "INFO:tensorflow:global_step/sec: 0.0220082\n",
            "I0407 16:17:52.084245 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0220082\n",
            "INFO:tensorflow:examples/sec: 0.704262\n",
            "I0407 16:17:52.084680 139835423807360 tpu_estimator.py:2160] examples/sec: 0.704262\n",
            "INFO:tensorflow:global_step/sec: 0.0219842\n",
            "I0407 16:18:37.571528 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0219842\n",
            "INFO:tensorflow:examples/sec: 0.703493\n",
            "I0407 16:18:37.571810 139835423807360 tpu_estimator.py:2160] examples/sec: 0.703493\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 300 vs previous value: 300. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "W0407 16:18:37.571991 139835423807360 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 300 vs previous value: 300. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 0.0222339\n",
            "I0407 16:19:22.547929 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222339\n",
            "INFO:tensorflow:examples/sec: 0.711484\n",
            "I0407 16:19:22.548371 139835423807360 tpu_estimator.py:2160] examples/sec: 0.711484\n",
            "INFO:tensorflow:global_step/sec: 0.022212\n",
            "I0407 16:20:07.568636 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022212\n",
            "INFO:tensorflow:examples/sec: 0.710784\n",
            "I0407 16:20:07.569087 139835423807360 tpu_estimator.py:2160] examples/sec: 0.710784\n",
            "INFO:tensorflow:global_step/sec: 0.0221407\n",
            "I0407 16:20:52.734368 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221407\n",
            "INFO:tensorflow:examples/sec: 0.708501\n",
            "I0407 16:20:52.735509 139835423807360 tpu_estimator.py:2160] examples/sec: 0.708501\n",
            "INFO:tensorflow:global_step/sec: 0.0224643\n",
            "I0407 16:21:37.249461 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224643\n",
            "INFO:tensorflow:examples/sec: 0.718858\n",
            "I0407 16:21:37.249890 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718858\n",
            "INFO:tensorflow:global_step/sec: 0.0223993\n",
            "I0407 16:22:21.893620 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223993\n",
            "INFO:tensorflow:examples/sec: 0.716779\n",
            "I0407 16:22:21.894078 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716779\n",
            "INFO:tensorflow:global_step/sec: 0.0222647\n",
            "I0407 16:23:06.807637 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0222647\n",
            "INFO:tensorflow:examples/sec: 0.712472\n",
            "I0407 16:23:06.809298 139835423807360 tpu_estimator.py:2160] examples/sec: 0.712472\n",
            "INFO:tensorflow:global_step/sec: 0.022407\n",
            "I0407 16:23:51.436650 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.022407\n",
            "INFO:tensorflow:examples/sec: 0.717024\n",
            "I0407 16:23:51.437118 139835423807360 tpu_estimator.py:2160] examples/sec: 0.717024\n",
            "INFO:tensorflow:global_step/sec: 0.0223949\n",
            "I0407 16:24:36.089497 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0223949\n",
            "INFO:tensorflow:examples/sec: 0.716638\n",
            "I0407 16:24:36.089947 139835423807360 tpu_estimator.py:2160] examples/sec: 0.716638\n",
            "INFO:tensorflow:global_step/sec: 0.0221896\n",
            "I0407 16:25:21.155681 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0221896\n",
            "INFO:tensorflow:examples/sec: 0.710067\n",
            "I0407 16:25:21.155972 139835423807360 tpu_estimator.py:2160] examples/sec: 0.710067\n",
            "INFO:tensorflow:global_step/sec: 0.0225075\n",
            "I0407 16:26:05.585384 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0225075\n",
            "INFO:tensorflow:examples/sec: 0.72024\n",
            "I0407 16:26:05.585795 139835423807360 tpu_estimator.py:2160] examples/sec: 0.72024\n",
            "INFO:tensorflow:global_step/sec: 0.0224676\n",
            "I0407 16:26:50.093792 139835423807360 tpu_estimator.py:2159] global_step/sec: 0.0224676\n",
            "INFO:tensorflow:examples/sec: 0.718964\n",
            "I0407 16:26:50.094282 139835423807360 tpu_estimator.py:2160] examples/sec: 0.718964\n",
            "INFO:tensorflow:Saving checkpoints for 312 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output/pre_training/model.ckpt.\n",
            "I0407 16:26:50.094831 139835423807360 basic_session_run_hooks.py:606] Saving checkpoints for 312 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output/pre_training/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.36949295.\n",
            "I0407 16:26:58.332224 139835423807360 estimator.py:368] Loss for final step: 0.36949295.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "I0407 16:26:58.333215 139835423807360 error_handling.py:96] training_loop marked as finished\n",
            "INFO:tensorflow:Writing example 0 of 3148\n",
            "I0407 16:26:58.929750 139835423807360 run_classifier.py:499] Writing example 0 of 3148\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 16:26:58.930485 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: dev-0\n",
            "I0407 16:26:58.930655 139835423807360 run_classifier.py:475] guid: dev-0\n",
            "INFO:tensorflow:tokens: [CLS] 왜 위 ##젯 ##을 안 ##만 ##드는 ##지 [UNK] 티월드 위 ##젯 ##처 ##럼 [UNK] [SEP]\n",
            "I0407 16:26:58.930781 139835423807360 run_classifier.py:477] tokens: [CLS] 왜 위 ##젯 ##을 안 ##만 ##드는 ##지 [UNK] 티월드 위 ##젯 ##처 ##럼 [UNK] [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1407 277 15532 9506 273 2582 15417 1161 100 45399 277 15532 4504 10731 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.930963 139835423807360 run_classifier.py:478] input_ids: 101 1407 277 15532 9506 273 2582 15417 1161 100 45399 277 15532 4504 10731 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.931123 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.931266 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 16:26:58.931357 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 16:26:58.932576 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: dev-1\n",
            "I0407 16:26:58.932751 139835423807360 run_classifier.py:475] guid: dev-1\n",
            "INFO:tensorflow:tokens: [CLS] 홈 ##화면 위 ##젯 ##가 ##능 추가 ##해 ##주 ##세 ##뇨 ##. ##. ##. [SEP]\n",
            "I0407 16:26:58.932894 139835423807360 run_classifier.py:477] tokens: [CLS] 홈 ##화면 위 ##젯 ##가 ##능 추가 ##해 ##주 ##세 ##뇨 ##. ##. ##. [SEP]\n",
            "INFO:tensorflow:input_ids: 101 869 30439 277 15532 1952 18444 551 3074 1510 2960 37488 37606 37606 37606 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.933058 139835423807360 run_classifier.py:478] input_ids: 101 869 30439 277 15532 1952 18444 551 3074 1510 2960 37488 37606 37606 37606 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.933211 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.933356 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 16:26:58.933447 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 16:26:58.934313 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: dev-2\n",
            "I0407 16:26:58.934464 139835423807360 run_classifier.py:475] guid: dev-2\n",
            "INFO:tensorflow:tokens: [CLS] 근데 [UNK] 더욱 편리 ##할 ##거 ##같 ##아 ##요 ##. ##. [UNK] [SEP]\n",
            "I0407 16:26:58.934579 139835423807360 run_classifier.py:477] tokens: [CLS] 근데 [UNK] 더욱 편리 ##할 ##거 ##같 ##아 ##요 ##. ##. [UNK] [SEP]\n",
            "INFO:tensorflow:input_ids: 101 10867 100 751 3459 6914 5820 31305 2532 5721 37606 37606 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.934724 139835423807360 run_classifier.py:478] input_ids: 101 10867 100 751 3459 6914 5820 31305 2532 5721 37606 37606 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.934880 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.935033 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 16:26:58.935141 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 16:26:58.935688 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: dev-3\n",
            "I0407 16:26:58.935826 139835423807360 run_classifier.py:475] guid: dev-3\n",
            "INFO:tensorflow:tokens: [CLS] 위 ##젯 ##으로 만들 ##기 ##가 그렇 ##게 힘든 ##가 ##? [SEP]\n",
            "I0407 16:26:58.935954 139835423807360 run_classifier.py:477] tokens: [CLS] 위 ##젯 ##으로 만들 ##기 ##가 그렇 ##게 힘든 ##가 ##? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 277 15532 44942 414 1261 1952 1051 7228 3280 1952 20689 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.936121 139835423807360 run_classifier.py:478] input_ids: 101 277 15532 44942 414 1261 1952 1051 7228 3280 1952 20689 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.936278 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.936436 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 16:26:58.936555 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 16:26:58.938082 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: dev-4\n",
            "I0407 16:26:58.938235 139835423807360 run_classifier.py:475] guid: dev-4\n",
            "INFO:tensorflow:tokens: [CLS] 엄마 ##가 사용량 [UNK] 그래서 봐 ##줄 ##려 ##고 하 ##는 데 돼지 ##도 ##안 ##네 ##. ##. ##위 ##젯 ##은 바라 ##지도 않 ##아 ##요 ##. ##되 ##는 ##것 ##좀 안 ##들 ##어 ##봐 ##요 누가 [UNK] [SEP]\n",
            "I0407 16:26:58.938372 139835423807360 run_classifier.py:477] tokens: [CLS] 엄마 ##가 사용량 [UNK] 그래서 봐 ##줄 ##려 ##고 하 ##는 데 돼지 ##도 ##안 ##네 ##. ##. ##위 ##젯 ##은 바라 ##지도 않 ##아 ##요 ##. ##되 ##는 ##것 ##좀 안 ##들 ##어 ##봐 ##요 누가 [UNK] [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1801 1952 7253 100 1869 1356 6896 4250 1590 116 12333 331 12057 1701 2838 5428 37606 37606 3046 15532 4155 3325 44631 167 2532 5721 37606 32143 12333 14676 46337 273 4496 2479 16862 5721 2846 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.938536 139835423807360 run_classifier.py:478] input_ids: 101 1801 1952 7253 100 1869 1356 6896 4250 1590 116 12333 331 12057 1701 2838 5428 37606 37606 3046 15532 4155 3325 44631 167 2532 5721 37606 32143 12333 14676 46337 273 4496 2479 16862 5721 2846 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.938686 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:26:58.938832 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 16:26:58.938944 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:***** Running evaluation *****\n",
            "I0407 16:27:00.099725 139835423807360 run_classifier.py:885] ***** Running evaluation *****\n",
            "INFO:tensorflow:  Num examples = 3148\n",
            "I0407 16:27:00.100335 139835423807360 run_classifier.py:886]   Num examples = 3148\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I0407 16:27:00.100446 139835423807360 run_classifier.py:887]   Batch size = 8\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0407 16:27:00.153318 139835423807360 estimator.py:1145] Calling model_fn.\n",
            "INFO:tensorflow:Running eval on CPU\n",
            "I0407 16:27:00.153709 139835423807360 tpu_estimator.py:2965] Running eval on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0407 16:27:00.154141 139835423807360 run_classifier.py:635] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "I0407 16:27:00.154333 139835423807360 run_classifier.py:637]   name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "I0407 16:27:00.154476 139835423807360 run_classifier.py:637]   name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "I0407 16:27:00.154600 139835423807360 run_classifier.py:637]   name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "I0407 16:27:00.154730 139835423807360 run_classifier.py:637]   name = segment_ids, shape = (?, 128)\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b467d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b467d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:00.377378 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b467d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b467d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b52410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b52410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:00.476750 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b52410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b52410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b52410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b52410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:00.577758 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b52410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b52410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:00.708383 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:00.834352 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:00.940705 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e3c650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e3c650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:01.073637 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e3c650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e3c650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2ded7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2ded7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:01.177842 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2ded7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2ded7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2ded7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2ded7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:01.279733 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2ded7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2ded7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b464d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b464d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:01.409277 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b464d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b464d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:01.527933 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:01.632120 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e26750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e26750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:01.776070 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e26750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e26750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e26750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e26750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:01.882510 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e26750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e26750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e26750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e26750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:01.984003 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e26750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e26750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2d33e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2d33e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:02.121569 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2d33e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2d33e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:02.251397 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:02.372650 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b63d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b63d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:02.502289 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b63d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b63d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2db3b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2db3b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:02.602371 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2db3b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2db3b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2cdb490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2cdb490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:02.710490 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2cdb490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2cdb490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c68790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c68790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:02.853790 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c68790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c68790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:02.980822 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:03.088222 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:03.223449 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:03.332774 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:03.431184 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c68790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c68790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:03.553670 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c68790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4c68790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:03.682545 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:03.795735 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db274f410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db274f410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:03.928769 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db274f410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db274f410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2749dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2749dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:04.041007 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2749dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2749dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8a09dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8a09dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:04.145944 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8a09dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8a09dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7af10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7af10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:04.273762 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7af10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7af10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:04.396312 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4b57dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4b57dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:04.501259 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4b57dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4b57dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8988910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8988910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:04.633929 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8988910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8988910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2adffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2adffd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:04.738979 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2adffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2adffd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2adffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2adffd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:04.848402 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2adffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2adffd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7a690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7a690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:04.979857 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7a690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7a690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e0c790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e0c790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:05.099517 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e0c790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e0c790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:05.209293 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:05.343882 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:05.445461 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:05.546382 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7a690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7a690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:05.679170 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7a690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7a690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db28d39d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db28d39d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:06.360787 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db28d39d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db28d39d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:06.468942 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da85e9090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da85e9090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:06.598954 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da85e9090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da85e9090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db283f6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db283f6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:06.704787 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db283f6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db283f6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da89f4fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da89f4fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:06.810702 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da89f4fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da89f4fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7af10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7af10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:06.963181 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7af10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2b7af10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:07.082696 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da88f8990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da88f8990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:07.204813 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da88f8990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da88f8990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5199290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5199290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:07.326293 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5199290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5199290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e5ab50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e5ab50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:07.425976 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e5ab50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e5ab50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e5ab50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e5ab50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:07.536518 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e5ab50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e5ab50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e5b150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e5b150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:07.659738 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e5b150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2e5b150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2918b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2918b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:07.778343 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2918b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2918b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2dfd3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2dfd3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:07.910772 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2dfd3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db2dfd3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8514d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8514d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:08.042338 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8514d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8514d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8514d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8514d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:08.148767 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8514d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8514d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8514d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8514d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:08.255631 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8514d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8514d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6d94a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6d94a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:08.377856 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6d94a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6d94a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df6931490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df6931490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:08.495887 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df6931490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df6931490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:08.606605 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8837990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db69ec990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db69ec990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:08.727859 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db69ec990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db69ec990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6889ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6889ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:08.834810 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6889ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6889ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6889ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6889ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:08.944368 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6889ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6889ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a14650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a14650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:09.086342 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a14650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a14650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da89f1510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da89f1510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:09.217250 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da89f1510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da89f1510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a53d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a53d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:09.333199 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a53d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2df69a53d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b9f990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b9f990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:27:09.517132 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b9f990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b9f990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0407 16:27:10.313544 139835423807360 run_classifier.py:666] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (49541, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.313782 139835423807360 run_classifier.py:672]   name = bert/embeddings/word_embeddings:0, shape = (49541, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.313957 139835423807360 run_classifier.py:672]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.314064 139835423807360 run_classifier.py:672]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.314150 139835423807360 run_classifier.py:672]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.314228 139835423807360 run_classifier.py:672]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.314304 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.314384 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.314457 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.314535 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.314619 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.314697 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.314770 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.314847 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.314980 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.315098 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.315218 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.315344 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.315462 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.315591 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.315707 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.315827 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.315960 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.316087 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.316209 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.316332 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.316448 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.316578 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.316697 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.316819 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.316960 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.317079 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.317197 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.317321 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.317440 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.317564 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.317684 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.317801 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.317939 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.318068 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.318187 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.318318 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.318436 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.318561 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.318690 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.318820 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.318954 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.319076 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.319197 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.319324 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.319441 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.319576 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.319697 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.319815 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.319953 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.320081 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.320201 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.320324 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.320446 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.320578 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.320697 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.320823 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.320958 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.321076 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.321196 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.321322 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.402832 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.403197 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.403388 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.403571 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.403734 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.403915 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.404079 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.404268 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.404428 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.404596 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.404761 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.404954 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.405132 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.405299 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.405460 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.405640 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.405801 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.405981 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.406145 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.406300 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.406452 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.406614 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.406769 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.406950 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.407267 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.407554 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.407748 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.408040 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.408235 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.408410 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.408581 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.408762 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.408957 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.409137 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.409299 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.409462 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.409626 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.409795 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.409997 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.410176 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.410341 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.410520 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.410686 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.410855 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.411071 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.411228 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.411385 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.411554 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.411714 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.411892 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.412071 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.412230 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.412380 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.412517 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.412643 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.412771 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.412924 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.413058 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.413375 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.413545 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.413736 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.413895 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.414021 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.414158 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.414301 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.414441 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.414575 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.414711 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.414840 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.414988 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.415119 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.415249 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.415371 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.415501 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.415626 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.415764 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.415904 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.416037 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.416159 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.416311 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.416437 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.416569 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.416698 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.416821 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.416962 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.417090 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.417212 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.417342 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.417465 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.417594 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.417721 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.417853 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.417991 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.418113 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.418237 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.418373 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.418491 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.418616 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.418745 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.418880 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.419010 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.419147 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.419268 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.419396 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.419517 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.419645 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.419772 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.511234 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.511590 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.511792 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.512006 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.512209 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.512390 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.512569 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.512740 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.512925 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.513102 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.513280 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.513422 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.513575 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.513726 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.513906 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.514067 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.514248 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.514408 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.514564 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.514719 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.514902 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.515063 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.515242 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.515410 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.515597 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.515774 139835423807360 run_classifier.py:672]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:27:10.515967 139835423807360 run_classifier.py:672]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (3, 768)\n",
            "I0407 16:27:10.516196 139835423807360 run_classifier.py:672]   name = output_weights:0, shape = (3, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (3,)\n",
            "I0407 16:27:10.516409 139835423807360 run_classifier.py:672]   name = output_bias:0, shape = (3,)\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:689: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "W0407 16:27:10.519629 139835423807360 deprecation_wrapper.py:119] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:689: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:690: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "W0407 16:27:10.535037 139835423807360 deprecation_wrapper.py:119] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:690: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0407 16:27:10.549179 139835423807360 estimator.py:1147] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-04-07T16:27:10Z\n",
            "I0407 16:27:10.569347 139835423807360 evaluation.py:255] Starting evaluation at 2021-04-07T16:27:10Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0407 16:27:11.097816 139835423807360 monitored_session.py:240] Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0407 16:27:11.099210 139835423807360 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output/pre_training/model.ckpt-312\n",
            "I0407 16:27:11.102220 139835423807360 saver.py:1280] Restoring parameters from drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output/pre_training/model.ckpt-312\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0407 16:27:12.383671 139835423807360 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0407 16:27:12.440446 139835423807360 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2021-04-07-16:57:26\n",
            "I0407 16:57:26.282040 139835423807360 evaluation.py:275] Finished evaluation at 2021-04-07-16:57:26\n",
            "INFO:tensorflow:Saving dict for global step 312: eval_accuracy = 0.8405337, eval_loss = 0.43671906, global_step = 312, loss = 0.43658826\n",
            "I0407 16:57:26.282440 139835423807360 estimator.py:2039] Saving dict for global step 312: eval_accuracy = 0.8405337, eval_loss = 0.43671906, global_step = 312, loss = 0.43658826\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 312: drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output/pre_training/model.ckpt-312\n",
            "I0407 16:57:26.929767 139835423807360 estimator.py:2099] Saving 'checkpoint_path' summary for global step 312: drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output/pre_training/model.ckpt-312\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n",
            "I0407 16:57:26.930817 139835423807360 error_handling.py:96] evaluation_loop marked as finished\n",
            "INFO:tensorflow:***** Eval results *****\n",
            "I0407 16:57:26.931100 139835423807360 run_classifier.py:909] ***** Eval results *****\n",
            "INFO:tensorflow:  eval_accuracy = 0.8405337\n",
            "I0407 16:57:26.931192 139835423807360 run_classifier.py:911]   eval_accuracy = 0.8405337\n",
            "INFO:tensorflow:  eval_loss = 0.43671906\n",
            "I0407 16:57:26.936291 139835423807360 run_classifier.py:911]   eval_loss = 0.43671906\n",
            "INFO:tensorflow:  global_step = 312\n",
            "I0407 16:57:26.936500 139835423807360 run_classifier.py:911]   global_step = 312\n",
            "INFO:tensorflow:  loss = 0.43658826\n",
            "I0407 16:57:26.936598 139835423807360 run_classifier.py:911]   loss = 0.43658826\n",
            "INFO:tensorflow:Writing example 0 of 1147\n",
            "I0407 16:57:26.951472 139835423807360 run_classifier.py:499] Writing example 0 of 1147\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 16:57:26.952337 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: test-1\n",
            "I0407 16:57:26.952461 139835423807360 run_classifier.py:475] guid: test-1\n",
            "INFO:tensorflow:tokens: [CLS] 지금 ##까 ##지도 ##돌 ##폰 ##으로 ##했 ##는 ##데이 ##걸 ##발 ##견 ##하 ##고 ##는 ##바로 ##이 ##걸 ##로 ##바 ##꿨 ##어 ##요 ##. ##간 ##편 ##도 ##하 ##고 ##요 ##. [SEP]\n",
            "I0407 16:57:26.952542 139835423807360 run_classifier.py:477] tokens: [CLS] 지금 ##까 ##지도 ##돌 ##폰 ##으로 ##했 ##는 ##데이 ##걸 ##발 ##견 ##하 ##고 ##는 ##바로 ##이 ##걸 ##로 ##바 ##꿨 ##어 ##요 ##. ##간 ##편 ##도 ##하 ##고 ##요 ##. [SEP]\n",
            "INFO:tensorflow:input_ids: 101 519 22970 44631 7263 6919 44942 8051 12333 9847 5429 4715 8022 2283 1590 12333 30411 1291 5429 1834 3202 46244 2479 5721 37606 3303 5920 1701 2283 1590 5721 37606 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.952654 139835423807360 run_classifier.py:478] input_ids: 101 519 22970 44631 7263 6919 44942 8051 12333 9847 5429 4715 8022 2283 1590 12333 30411 1291 5429 1834 3202 46244 2479 5721 37606 3303 5920 1701 2283 1590 5721 37606 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.952747 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.952837 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 16:57:26.952935 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 16:57:26.953535 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: test-2\n",
            "I0407 16:57:26.953669 139835423807360 run_classifier.py:475] guid: test-2\n",
            "INFO:tensorflow:tokens: [CLS] 위 ##젯 ##을 원해 ##요 ##. . 요즘 ##시대 ##에 ##. . ##참 [SEP]\n",
            "I0407 16:57:26.953741 139835423807360 run_classifier.py:477] tokens: [CLS] 위 ##젯 ##을 원해 ##요 ##. . 요즘 ##시대 ##에 ##. . ##참 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 277 15532 9506 17764 5721 37606 106 2502 44598 4498 37606 106 15693 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.953834 139835423807360 run_classifier.py:478] input_ids: 101 277 15532 9506 17764 5721 37606 106 2502 44598 4498 37606 106 15693 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.953966 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.954103 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 16:57:26.954197 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 16:57:26.954696 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: test-3\n",
            "I0407 16:57:26.954825 139835423807360 run_classifier.py:475] guid: test-3\n",
            "INFO:tensorflow:tokens: [CLS] 3 ##월 ##달 ##게 미납 ##으로 [UNK] 돈 ##은 [UNK] [SEP]\n",
            "I0407 16:57:26.954955 139835423807360 run_classifier.py:477] tokens: [CLS] 3 ##월 ##달 ##게 미납 ##으로 [UNK] 돈 ##은 [UNK] [SEP]\n",
            "INFO:tensorflow:input_ids: 101 148 7036 5339 7228 8315 44942 100 825 4155 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.955114 139835423807360 run_classifier.py:478] input_ids: 101 148 7036 5339 7228 8315 44942 100 825 4155 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.955258 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.955399 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 16:57:26.955487 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 16:57:26.955954 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: test-4\n",
            "I0407 16:57:26.956079 139835423807360 run_classifier.py:475] guid: test-4\n",
            "INFO:tensorflow:tokens: [CLS] 다른 ##거 필요 ##없 ##고 위 ##젯 ##좀 만 ##듭 ##시 ##다 ##! ##! [SEP]\n",
            "I0407 16:57:26.956192 139835423807360 run_classifier.py:477] tokens: [CLS] 다른 ##거 필요 ##없 ##고 위 ##젯 ##좀 만 ##듭 ##시 ##다 ##! ##! [SEP]\n",
            "INFO:tensorflow:input_ids: 101 368 5820 356 8466 1590 277 15532 46337 144 45561 1468 3305 36977 36977 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.956333 139835423807360 run_classifier.py:478] input_ids: 101 368 5820 356 8466 1590 277 15532 46337 144 45561 1468 3305 36977 36977 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.956474 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.956618 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 16:57:26.956712 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0407 16:57:26.957137 139835423807360 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: test-5\n",
            "I0407 16:57:26.957258 139835423807360 run_classifier.py:475] guid: test-5\n",
            "INFO:tensorflow:tokens: [CLS] 왜 ##업 ##데이트 ##안 ##되 ##요 [SEP]\n",
            "I0407 16:57:26.957363 139835423807360 run_classifier.py:477] tokens: [CLS] 왜 ##업 ##데이트 ##안 ##되 ##요 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1407 2670 40773 2838 32143 5721 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.957509 139835423807360 run_classifier.py:478] input_ids: 101 1407 2670 40773 2838 32143 5721 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.957652 139835423807360 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0407 16:57:26.957787 139835423807360 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0407 16:57:26.957889 139835423807360 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:***** Running prediction*****\n",
            "I0407 16:57:27.358365 139835423807360 run_classifier.py:921] ***** Running prediction*****\n",
            "INFO:tensorflow:  Num examples = 1147\n",
            "I0407 16:57:27.358999 139835423807360 run_classifier.py:922]   Num examples = 1147\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I0407 16:57:27.359159 139835423807360 run_classifier.py:923]   Batch size = 8\n",
            "INFO:tensorflow:***** Predict results *****\n",
            "I0407 16:57:27.359360 139835423807360 run_classifier.py:941] ***** Predict results *****\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0407 16:57:27.398096 139835423807360 estimator.py:1145] Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "I0407 16:57:27.398416 139835423807360 tpu_estimator.py:2965] Running infer on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0407 16:57:27.398777 139835423807360 run_classifier.py:635] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "I0407 16:57:27.398966 139835423807360 run_classifier.py:637]   name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "I0407 16:57:27.399117 139835423807360 run_classifier.py:637]   name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "I0407 16:57:27.399241 139835423807360 run_classifier.py:637]   name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "I0407 16:57:27.399368 139835423807360 run_classifier.py:637]   name = segment_ids, shape = (?, 128)\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:27.598165 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:27.707295 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:27.820679 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55911d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55911d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:27.943648 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55911d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55911d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:28.071181 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:28.178413 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5289bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5289bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:28.303779 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5289bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5289bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db553f0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db553f0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:28.413720 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db553f0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db553f0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4f67ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4f67ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:28.775232 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4f67ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4f67ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:28.904263 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5591150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55858d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55858d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:29.047521 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55858d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55858d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:29.153465 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5557450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5557450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:29.282029 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5557450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5557450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5557450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5557450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:29.391311 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5557450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5557450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5557450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5557450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:29.490464 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5557450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5557450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db58f2a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db58f2a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:29.626370 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db58f2a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db58f2a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55858d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55858d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:29.750066 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55858d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55858d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:29.865761 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6938d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6938d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:30.004518 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6938d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6938d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5421750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5421750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:30.113964 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5421750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5421750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db69be0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db69be0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:30.215710 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db69be0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db69be0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db681c150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db681c150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:30.345376 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db681c150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db681c150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:30.464095 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55859d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55859d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:30.578340 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55859d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55859d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6980790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6980790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:30.711161 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6980790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6980790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52007d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52007d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:30.812334 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52007d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52007d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52007d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52007d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:30.926086 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52007d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52007d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:31.073146 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b46f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:31.195988 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5585d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6837ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6837ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:31.316943 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6837ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6837ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a14910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a14910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:31.437921 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a14910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a14910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a14910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a14910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:31.544052 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a14910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a14910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67fc390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67fc390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:31.643431 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67fc390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67fc390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db539c7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db539c7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:31.767728 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db539c7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db539c7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67be710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67be710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:31.904368 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67be710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67be710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a8b590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a8b590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:32.013857 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a8b590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a8b590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db041f290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db041f290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:32.145259 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db041f290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db041f290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b134d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b134d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:32.248790 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b134d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b134d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b134d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b134d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:32.352239 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b134d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6b134d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8596910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8596910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:32.618234 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8596910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8596910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b1bb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b1bb50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:32.737623 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b1bb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b1bb50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8bb3350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8bb3350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:32.851693 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8bb3350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8bb3350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db1f3ac50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db1f3ac50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:32.984121 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db1f3ac50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db1f3ac50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db041f0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db041f0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:33.083886 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db041f0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db041f0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db041f0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db041f0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:33.193458 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db041f0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db041f0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db539c7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db539c7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:33.316129 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db539c7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db539c7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8508090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8508090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:33.434237 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8508090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8508090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6879bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6879bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:33.555152 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6879bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6879bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6ac1090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6ac1090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:33.684589 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6ac1090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6ac1090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db1f3aed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db1f3aed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:33.792212 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db1f3aed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db1f3aed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db1f3aed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db1f3aed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:33.903810 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db1f3aed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db1f3aed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a8b590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a8b590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:34.037045 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a8b590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6a8b590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8508090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8508090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:34.168369 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8508090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8508090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:34.283338 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b41c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52e7dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52e7dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:34.411959 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52e7dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db52e7dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db47fcdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db47fcdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:34.521258 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db47fcdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db47fcdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db069acd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db069acd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:34.620752 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db069acd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db069acd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8c24690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8c24690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:34.744593 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8c24690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8c24690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b1bb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b1bb50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:34.874897 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b1bb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b1bb50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5813e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5813e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:34.996883 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5813e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5813e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2dac7642d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2dac7642d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:35.143759 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2dac7642d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2dac7642d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da84a1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da84a1dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:35.245209 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da84a1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da84a1dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da84a1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da84a1dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:35.344137 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da84a1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da84a1dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67c1310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67c1310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:35.479367 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67c1310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db67c1310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da920c910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da920c910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:35.596401 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da920c910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da920c910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6d73d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6d73d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:35.717527 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6d73d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db6d73d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a0b5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a0b5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:35.850793 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a0b5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a0b5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a0b5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a0b5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:35.964607 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a0b5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a0b5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a0b5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a0b5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:36.081014 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a0b5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db4a0b5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da84d2090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da84d2090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:36.211594 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da84d2090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da84d2090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b1bb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b1bb50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:36.335787 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b1bb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2da8b1bb50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5147d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5147d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:36.441256 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5147d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db5147d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55fabd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55fabd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0407 16:57:36.635741 139835423807360 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55fabd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2db55fabd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0407 16:57:37.462687 139835423807360 run_classifier.py:666] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (49541, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.463069 139835423807360 run_classifier.py:672]   name = bert/embeddings/word_embeddings:0, shape = (49541, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.463276 139835423807360 run_classifier.py:672]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.463423 139835423807360 run_classifier.py:672]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.463562 139835423807360 run_classifier.py:672]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.463731 139835423807360 run_classifier.py:672]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.463895 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.464042 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.464163 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.464288 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.464430 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.464586 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.464705 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.464832 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.464975 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.465134 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.465267 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.465394 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.465518 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.465739 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.465920 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.466054 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.466176 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.466304 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.466427 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.466564 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.466685 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.466811 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.466948 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.467078 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.467198 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.467321 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.467438 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.467570 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.467693 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.467820 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.467952 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.468072 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.468188 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.468311 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.468427 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.468560 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.468677 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.468799 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.468934 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.469060 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.469178 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.469295 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.469415 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.469558 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.469700 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.469842 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.469994 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.470126 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.470259 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.470407 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.470552 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.470695 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.470830 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.470978 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.471107 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.471249 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.471389 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.471553 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.471705 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.471877 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.561453 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.561712 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.561903 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.562137 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.562299 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.562468 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.562630 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.562799 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.562990 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.563161 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.563347 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.563549 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.563715 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.563894 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.564093 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.564270 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.564428 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.564596 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.564752 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.564928 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.565093 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.565261 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.565420 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.565589 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.565747 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.565934 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.566103 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.566277 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.566443 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.566606 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.566761 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.566953 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.567113 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.567283 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.567442 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.567600 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.567759 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.567960 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.568129 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.568298 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.568458 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.568625 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.568786 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.568989 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.569155 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.569314 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.569473 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.569642 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.569798 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.569993 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.570151 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.570306 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.570461 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.570629 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.570787 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.570980 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.571143 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.571312 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.571472 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.571645 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.571806 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.571995 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.572159 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.572330 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.572491 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.572653 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.572809 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.572990 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.573154 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.573333 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.573492 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.573660 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.573820 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.574019 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.574187 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.574359 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.574521 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.574679 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.574840 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.575033 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.575221 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.575395 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.575553 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.575710 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.575875 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.576059 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.576215 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.576383 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.576542 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.576713 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.576889 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.577076 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.577241 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.577402 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.577558 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.577720 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.577891 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.578070 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.578231 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.578386 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.578542 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.578706 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.578876 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.579066 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.579227 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.579401 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.579565 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.579736 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.579922 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.580091 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.580253 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.580428 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.580593 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.580764 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.580943 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.581101 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.581254 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.581416 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.581576 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.581740 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.581907 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.582092 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.582245 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.582413 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.582576 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.582736 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.582908 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.583168 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.583337 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.583534 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.583695 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.583855 139835423807360 run_classifier.py:672]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.584047 139835423807360 run_classifier.py:672]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0407 16:57:37.584220 139835423807360 run_classifier.py:672]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (3, 768)\n",
            "I0407 16:57:37.584439 139835423807360 run_classifier.py:672]   name = output_weights:0, shape = (3, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (3,)\n",
            "I0407 16:57:37.584655 139835423807360 run_classifier.py:672]   name = output_bias:0, shape = (3,)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0407 16:57:37.585331 139835423807360 estimator.py:1147] Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0407 16:57:38.109599 139835423807360 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output/pre_training/model.ckpt-312\n",
            "I0407 16:57:38.113099 139835423807360 saver.py:1280] Restoring parameters from drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output/pre_training/model.ckpt-312\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0407 16:57:39.453555 139835423807360 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0407 16:57:39.501705 139835423807360 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0407 17:08:41.108951 139835423807360 error_handling.py:96] prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0407 17:08:41.109238 139835423807360 error_handling.py:96] prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZOfHliO5MGL"
      },
      "source": [
        "## Mobile TV app 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQGZYPnh5L2R",
        "outputId": "2596918e-9027-482d-d71f-8b99456428d8"
      },
      "source": [
        "!python drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py \\\n",
        "--task_name=nsmc \\\n",
        "--do_train=true \\\n",
        "--do_predict=true \\\n",
        "--do_eval=true \\\n",
        "--data_dir=drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/nsmc/mobile_TV \\\n",
        "--vocab_file=drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/T_conf/vocab.txt \\\n",
        "--bert_config_file=drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/T_conf/bert_config.json \\\n",
        "--init_checkpoint=drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_2/2home/model.ckpt-160 \\\n",
        "--save_checkpoints_steps=50 \\\n",
        "--iterations_per_loop=50 \\\n",
        "--max_seq_length=128 \\\n",
        "--train_batch_size=32 \\\n",
        "--num_train_epochs=3.0 \\\n",
        "--learning_rate=3e-5 \\\n",
        "--do_lower_case=false \\\n",
        "--output_dir=drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "INFO:tensorflow:global_step/sec: 0.022545\n",
            "I0410 08:50:53.051354 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022545\n",
            "INFO:tensorflow:examples/sec: 0.721439\n",
            "I0410 08:50:53.052879 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721439\n",
            "INFO:tensorflow:global_step/sec: 0.0223535\n",
            "I0410 08:51:37.787103 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223535\n",
            "INFO:tensorflow:examples/sec: 0.715311\n",
            "I0410 08:51:37.787527 140202582333312 tpu_estimator.py:2160] examples/sec: 0.715311\n",
            "INFO:tensorflow:Saving checkpoints for 340 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 08:52:22.331380 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 340 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0192544\n",
            "I0410 08:52:29.723344 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0192544\n",
            "INFO:tensorflow:examples/sec: 0.61614\n",
            "I0410 08:52:29.723687 140202582333312 tpu_estimator.py:2160] examples/sec: 0.61614\n",
            "INFO:tensorflow:global_step/sec: 0.0218126\n",
            "I0410 08:53:15.568465 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218126\n",
            "INFO:tensorflow:examples/sec: 0.698002\n",
            "I0410 08:53:15.569610 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698002\n",
            "INFO:tensorflow:global_step/sec: 0.0222236\n",
            "I0410 08:54:00.565747 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222236\n",
            "INFO:tensorflow:examples/sec: 0.711154\n",
            "I0410 08:54:00.566088 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711154\n",
            "INFO:tensorflow:global_step/sec: 0.0225849\n",
            "I0410 08:54:44.843167 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225849\n",
            "INFO:tensorflow:examples/sec: 0.722718\n",
            "I0410 08:54:44.843528 140202582333312 tpu_estimator.py:2160] examples/sec: 0.722718\n",
            "INFO:tensorflow:global_step/sec: 0.0225089\n",
            "I0410 08:55:29.269977 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225089\n",
            "INFO:tensorflow:examples/sec: 0.720285\n",
            "I0410 08:55:29.270988 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720285\n",
            "INFO:tensorflow:global_step/sec: 0.0225287\n",
            "I0410 08:56:13.657737 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225287\n",
            "INFO:tensorflow:examples/sec: 0.720919\n",
            "I0410 08:56:13.658071 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720919\n",
            "INFO:tensorflow:global_step/sec: 0.0223926\n",
            "I0410 08:56:58.315306 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223926\n",
            "INFO:tensorflow:examples/sec: 0.716564\n",
            "I0410 08:56:58.315639 140202582333312 tpu_estimator.py:2160] examples/sec: 0.716564\n",
            "INFO:tensorflow:global_step/sec: 0.0223761\n",
            "I0410 08:57:43.005815 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223761\n",
            "INFO:tensorflow:examples/sec: 0.716036\n",
            "I0410 08:57:43.006966 140202582333312 tpu_estimator.py:2160] examples/sec: 0.716036\n",
            "INFO:tensorflow:global_step/sec: 0.0225343\n",
            "I0410 08:58:27.382731 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225343\n",
            "INFO:tensorflow:examples/sec: 0.721096\n",
            "I0410 08:58:27.383009 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721096\n",
            "INFO:tensorflow:global_step/sec: 0.0223595\n",
            "I0410 08:59:12.106453 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223595\n",
            "INFO:tensorflow:examples/sec: 0.715503\n",
            "I0410 08:59:12.106858 140202582333312 tpu_estimator.py:2160] examples/sec: 0.715503\n",
            "INFO:tensorflow:global_step/sec: 0.0225344\n",
            "I0410 08:59:56.483027 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225344\n",
            "INFO:tensorflow:examples/sec: 0.721101\n",
            "I0410 08:59:56.484432 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721101\n",
            "INFO:tensorflow:global_step/sec: 0.0225665\n",
            "I0410 09:00:40.796504 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225665\n",
            "INFO:tensorflow:examples/sec: 0.722127\n",
            "I0410 09:00:40.796787 140202582333312 tpu_estimator.py:2160] examples/sec: 0.722127\n",
            "INFO:tensorflow:global_step/sec: 0.0222636\n",
            "I0410 09:01:25.712815 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222636\n",
            "INFO:tensorflow:examples/sec: 0.712437\n",
            "I0410 09:01:25.713284 140202582333312 tpu_estimator.py:2160] examples/sec: 0.712437\n",
            "INFO:tensorflow:global_step/sec: 0.0223073\n",
            "I0410 09:02:10.541265 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223073\n",
            "INFO:tensorflow:examples/sec: 0.713833\n",
            "I0410 09:02:10.542697 140202582333312 tpu_estimator.py:2160] examples/sec: 0.713833\n",
            "INFO:tensorflow:global_step/sec: 0.0225546\n",
            "I0410 09:02:54.878148 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225546\n",
            "INFO:tensorflow:examples/sec: 0.721747\n",
            "I0410 09:02:54.878570 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721747\n",
            "INFO:tensorflow:global_step/sec: 0.0226014\n",
            "I0410 09:03:39.123201 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0226014\n",
            "INFO:tensorflow:examples/sec: 0.723244\n",
            "I0410 09:03:39.123623 140202582333312 tpu_estimator.py:2160] examples/sec: 0.723244\n",
            "INFO:tensorflow:global_step/sec: 0.0225141\n",
            "I0410 09:04:23.539897 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225141\n",
            "INFO:tensorflow:examples/sec: 0.72045\n",
            "I0410 09:04:23.540924 140202582333312 tpu_estimator.py:2160] examples/sec: 0.72045\n",
            "INFO:tensorflow:global_step/sec: 0.0224554\n",
            "I0410 09:05:08.072698 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224554\n",
            "INFO:tensorflow:examples/sec: 0.718571\n",
            "I0410 09:05:08.072999 140202582333312 tpu_estimator.py:2160] examples/sec: 0.718571\n",
            "INFO:tensorflow:global_step/sec: 0.0221219\n",
            "I0410 09:05:53.276726 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221219\n",
            "INFO:tensorflow:examples/sec: 0.707901\n",
            "I0410 09:05:53.277127 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707901\n",
            "INFO:tensorflow:global_step/sec: 0.0225324\n",
            "I0410 09:06:37.657346 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225324\n",
            "INFO:tensorflow:examples/sec: 0.721036\n",
            "I0410 09:06:37.658925 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721036\n",
            "INFO:tensorflow:Saving checkpoints for 360 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 09:07:22.202863 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 360 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0194503\n",
            "I0410 09:07:29.070434 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0194503\n",
            "INFO:tensorflow:examples/sec: 0.62241\n",
            "I0410 09:07:29.070862 140202582333312 tpu_estimator.py:2160] examples/sec: 0.62241\n",
            "INFO:tensorflow:global_step/sec: 0.0216947\n",
            "I0410 09:08:15.164450 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216947\n",
            "INFO:tensorflow:examples/sec: 0.694232\n",
            "I0410 09:08:15.164805 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694232\n",
            "INFO:tensorflow:global_step/sec: 0.0225993\n",
            "I0410 09:08:59.413569 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225993\n",
            "INFO:tensorflow:examples/sec: 0.723178\n",
            "I0410 09:08:59.414929 140202582333312 tpu_estimator.py:2160] examples/sec: 0.723178\n",
            "INFO:tensorflow:global_step/sec: 0.0225514\n",
            "I0410 09:09:43.756631 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225514\n",
            "INFO:tensorflow:examples/sec: 0.721646\n",
            "I0410 09:09:43.757010 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721646\n",
            "INFO:tensorflow:global_step/sec: 0.0222616\n",
            "I0410 09:10:28.676949 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222616\n",
            "INFO:tensorflow:examples/sec: 0.712372\n",
            "I0410 09:10:28.677340 140202582333312 tpu_estimator.py:2160] examples/sec: 0.712372\n",
            "INFO:tensorflow:global_step/sec: 0.0222552\n",
            "I0410 09:11:13.610210 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222552\n",
            "INFO:tensorflow:examples/sec: 0.712168\n",
            "I0410 09:11:13.610483 140202582333312 tpu_estimator.py:2160] examples/sec: 0.712168\n",
            "INFO:tensorflow:global_step/sec: 0.0225005\n",
            "I0410 09:11:58.053714 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225005\n",
            "INFO:tensorflow:examples/sec: 0.720016\n",
            "I0410 09:11:58.054191 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720016\n",
            "INFO:tensorflow:global_step/sec: 0.0225597\n",
            "I0410 09:12:42.380828 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225597\n",
            "INFO:tensorflow:examples/sec: 0.72191\n",
            "I0410 09:12:42.381300 140202582333312 tpu_estimator.py:2160] examples/sec: 0.72191\n",
            "INFO:tensorflow:global_step/sec: 0.0223933\n",
            "I0410 09:13:27.036747 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223933\n",
            "INFO:tensorflow:examples/sec: 0.716585\n",
            "I0410 09:13:27.038083 140202582333312 tpu_estimator.py:2160] examples/sec: 0.716585\n",
            "INFO:tensorflow:global_step/sec: 0.0225877\n",
            "I0410 09:14:11.308694 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225877\n",
            "INFO:tensorflow:examples/sec: 0.722808\n",
            "I0410 09:14:11.309126 140202582333312 tpu_estimator.py:2160] examples/sec: 0.722808\n",
            "INFO:tensorflow:global_step/sec: 0.022241\n",
            "I0410 09:14:56.270565 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022241\n",
            "INFO:tensorflow:examples/sec: 0.711712\n",
            "I0410 09:14:56.270987 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711712\n",
            "INFO:tensorflow:global_step/sec: 0.0223436\n",
            "I0410 09:15:41.026060 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223436\n",
            "INFO:tensorflow:examples/sec: 0.714996\n",
            "I0410 09:15:41.026375 140202582333312 tpu_estimator.py:2160] examples/sec: 0.714996\n",
            "INFO:tensorflow:global_step/sec: 0.0225019\n",
            "I0410 09:16:25.466713 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225019\n",
            "INFO:tensorflow:examples/sec: 0.720062\n",
            "I0410 09:16:25.467156 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720062\n",
            "INFO:tensorflow:global_step/sec: 0.0222371\n",
            "I0410 09:17:10.436557 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222371\n",
            "INFO:tensorflow:examples/sec: 0.711588\n",
            "I0410 09:17:10.436963 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711588\n",
            "INFO:tensorflow:global_step/sec: 0.0224858\n",
            "I0410 09:17:54.909006 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224858\n",
            "INFO:tensorflow:examples/sec: 0.719547\n",
            "I0410 09:17:54.910626 140202582333312 tpu_estimator.py:2160] examples/sec: 0.719547\n",
            "INFO:tensorflow:global_step/sec: 0.0223998\n",
            "I0410 09:18:39.552280 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223998\n",
            "INFO:tensorflow:examples/sec: 0.716793\n",
            "I0410 09:18:39.552688 140202582333312 tpu_estimator.py:2160] examples/sec: 0.716793\n",
            "INFO:tensorflow:global_step/sec: 0.0224948\n",
            "I0410 09:19:24.007034 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224948\n",
            "INFO:tensorflow:examples/sec: 0.719834\n",
            "I0410 09:19:24.007467 140202582333312 tpu_estimator.py:2160] examples/sec: 0.719834\n",
            "INFO:tensorflow:global_step/sec: 0.022283\n",
            "I0410 09:20:08.884382 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022283\n",
            "INFO:tensorflow:examples/sec: 0.713056\n",
            "I0410 09:20:08.886032 140202582333312 tpu_estimator.py:2160] examples/sec: 0.713056\n",
            "INFO:tensorflow:global_step/sec: 0.022526\n",
            "I0410 09:20:53.277506 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022526\n",
            "INFO:tensorflow:examples/sec: 0.720832\n",
            "I0410 09:20:53.277919 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720832\n",
            "INFO:tensorflow:global_step/sec: 0.0221921\n",
            "I0410 09:21:38.338481 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221921\n",
            "INFO:tensorflow:examples/sec: 0.710147\n",
            "I0410 09:21:38.339006 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710147\n",
            "INFO:tensorflow:Saving checkpoints for 380 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 09:22:22.613581 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 380 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0194265\n",
            "I0410 09:22:29.814500 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0194265\n",
            "INFO:tensorflow:examples/sec: 0.621649\n",
            "I0410 09:22:29.814819 140202582333312 tpu_estimator.py:2160] examples/sec: 0.621649\n",
            "INFO:tensorflow:global_step/sec: 0.0220952\n",
            "I0410 09:23:15.073171 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220952\n",
            "INFO:tensorflow:examples/sec: 0.707047\n",
            "I0410 09:23:15.073681 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707047\n",
            "INFO:tensorflow:global_step/sec: 0.0226919\n",
            "I0410 09:23:59.141824 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0226919\n",
            "INFO:tensorflow:examples/sec: 0.72614\n",
            "I0410 09:23:59.142282 140202582333312 tpu_estimator.py:2160] examples/sec: 0.72614\n",
            "INFO:tensorflow:global_step/sec: 0.0222849\n",
            "I0410 09:24:44.015283 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222849\n",
            "INFO:tensorflow:examples/sec: 0.713116\n",
            "I0410 09:24:44.016665 140202582333312 tpu_estimator.py:2160] examples/sec: 0.713116\n",
            "INFO:tensorflow:global_step/sec: 0.0225039\n",
            "I0410 09:25:28.452037 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225039\n",
            "INFO:tensorflow:examples/sec: 0.720124\n",
            "I0410 09:25:28.452463 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720124\n",
            "INFO:tensorflow:global_step/sec: 0.0226002\n",
            "I0410 09:26:12.699444 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0226002\n",
            "INFO:tensorflow:examples/sec: 0.723206\n",
            "I0410 09:26:12.699729 140202582333312 tpu_estimator.py:2160] examples/sec: 0.723206\n",
            "INFO:tensorflow:global_step/sec: 0.0223988\n",
            "I0410 09:26:57.344678 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223988\n",
            "INFO:tensorflow:examples/sec: 0.716762\n",
            "I0410 09:26:57.344946 140202582333312 tpu_estimator.py:2160] examples/sec: 0.716762\n",
            "INFO:tensorflow:global_step/sec: 0.0224096\n",
            "I0410 09:27:41.968419 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224096\n",
            "INFO:tensorflow:examples/sec: 0.717107\n",
            "I0410 09:27:41.968860 140202582333312 tpu_estimator.py:2160] examples/sec: 0.717107\n",
            "INFO:tensorflow:global_step/sec: 0.0226118\n",
            "I0410 09:28:26.193272 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0226118\n",
            "INFO:tensorflow:examples/sec: 0.723576\n",
            "I0410 09:28:26.193694 140202582333312 tpu_estimator.py:2160] examples/sec: 0.723576\n",
            "INFO:tensorflow:global_step/sec: 0.0224606\n",
            "I0410 09:29:10.715568 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224606\n",
            "INFO:tensorflow:examples/sec: 0.71874\n",
            "I0410 09:29:10.715859 140202582333312 tpu_estimator.py:2160] examples/sec: 0.71874\n",
            "INFO:tensorflow:global_step/sec: 0.0223686\n",
            "I0410 09:29:55.421095 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223686\n",
            "INFO:tensorflow:examples/sec: 0.715795\n",
            "I0410 09:29:55.421407 140202582333312 tpu_estimator.py:2160] examples/sec: 0.715795\n",
            "INFO:tensorflow:global_step/sec: 0.0225459\n",
            "I0410 09:30:39.775182 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225459\n",
            "INFO:tensorflow:examples/sec: 0.721467\n",
            "I0410 09:30:39.775475 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721467\n",
            "INFO:tensorflow:global_step/sec: 0.0223788\n",
            "I0410 09:31:24.460347 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223788\n",
            "INFO:tensorflow:examples/sec: 0.716122\n",
            "I0410 09:31:24.461763 140202582333312 tpu_estimator.py:2160] examples/sec: 0.716122\n",
            "INFO:tensorflow:global_step/sec: 0.0225768\n",
            "I0410 09:32:08.753642 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225768\n",
            "INFO:tensorflow:examples/sec: 0.722457\n",
            "I0410 09:32:08.754059 140202582333312 tpu_estimator.py:2160] examples/sec: 0.722457\n",
            "INFO:tensorflow:global_step/sec: 0.0224599\n",
            "I0410 09:32:53.277467 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224599\n",
            "INFO:tensorflow:examples/sec: 0.718716\n",
            "I0410 09:32:53.277877 140202582333312 tpu_estimator.py:2160] examples/sec: 0.718716\n",
            "INFO:tensorflow:global_step/sec: 0.0225153\n",
            "I0410 09:33:37.691663 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225153\n",
            "INFO:tensorflow:examples/sec: 0.720489\n",
            "I0410 09:33:37.693128 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720489\n",
            "INFO:tensorflow:global_step/sec: 0.0226052\n",
            "I0410 09:34:21.929365 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0226052\n",
            "INFO:tensorflow:examples/sec: 0.723366\n",
            "I0410 09:34:21.929778 140202582333312 tpu_estimator.py:2160] examples/sec: 0.723366\n",
            "INFO:tensorflow:global_step/sec: 0.0223996\n",
            "I0410 09:35:06.573072 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223996\n",
            "INFO:tensorflow:examples/sec: 0.716786\n",
            "I0410 09:35:06.573396 140202582333312 tpu_estimator.py:2160] examples/sec: 0.716786\n",
            "INFO:tensorflow:global_step/sec: 0.0225527\n",
            "I0410 09:35:50.913628 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225527\n",
            "INFO:tensorflow:examples/sec: 0.721686\n",
            "I0410 09:35:50.914088 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721686\n",
            "INFO:tensorflow:global_step/sec: 0.0224709\n",
            "I0410 09:36:35.415736 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224709\n",
            "INFO:tensorflow:examples/sec: 0.719068\n",
            "I0410 09:36:35.416211 140202582333312 tpu_estimator.py:2160] examples/sec: 0.719068\n",
            "INFO:tensorflow:Saving checkpoints for 400 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 09:37:19.734813 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 400 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.019515\n",
            "I0410 09:37:26.658457 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.019515\n",
            "INFO:tensorflow:examples/sec: 0.62448\n",
            "I0410 09:37:26.658844 140202582333312 tpu_estimator.py:2160] examples/sec: 0.62448\n",
            "INFO:tensorflow:global_step/sec: 0.0216909\n",
            "I0410 09:38:12.760836 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216909\n",
            "INFO:tensorflow:examples/sec: 0.694108\n",
            "I0410 09:38:12.762209 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694108\n",
            "INFO:tensorflow:global_step/sec: 0.0225404\n",
            "I0410 09:38:57.125433 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225404\n",
            "INFO:tensorflow:examples/sec: 0.721294\n",
            "I0410 09:38:57.125849 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721294\n",
            "INFO:tensorflow:global_step/sec: 0.0225586\n",
            "I0410 09:39:41.454453 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225586\n",
            "INFO:tensorflow:examples/sec: 0.721874\n",
            "I0410 09:39:41.454878 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721874\n",
            "INFO:tensorflow:global_step/sec: 0.0222178\n",
            "I0410 09:40:26.463377 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222178\n",
            "INFO:tensorflow:examples/sec: 0.710971\n",
            "I0410 09:40:26.464836 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710971\n",
            "INFO:tensorflow:global_step/sec: 0.0223527\n",
            "I0410 09:41:11.200770 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223527\n",
            "INFO:tensorflow:examples/sec: 0.715285\n",
            "I0410 09:41:11.201192 140202582333312 tpu_estimator.py:2160] examples/sec: 0.715285\n",
            "INFO:tensorflow:global_step/sec: 0.0221268\n",
            "I0410 09:41:56.394918 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221268\n",
            "INFO:tensorflow:examples/sec: 0.708056\n",
            "I0410 09:41:56.395376 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708056\n",
            "INFO:tensorflow:global_step/sec: 0.0223912\n",
            "I0410 09:42:41.055416 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223912\n",
            "INFO:tensorflow:examples/sec: 0.716518\n",
            "I0410 09:42:41.057217 140202582333312 tpu_estimator.py:2160] examples/sec: 0.716518\n",
            "INFO:tensorflow:global_step/sec: 0.0222074\n",
            "I0410 09:43:26.085479 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222074\n",
            "INFO:tensorflow:examples/sec: 0.710636\n",
            "I0410 09:43:26.085801 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710636\n",
            "INFO:tensorflow:global_step/sec: 0.022396\n",
            "I0410 09:44:10.736159 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022396\n",
            "INFO:tensorflow:examples/sec: 0.716673\n",
            "I0410 09:44:10.736622 140202582333312 tpu_estimator.py:2160] examples/sec: 0.716673\n",
            "INFO:tensorflow:global_step/sec: 0.0223081\n",
            "I0410 09:44:55.562895 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223081\n",
            "INFO:tensorflow:examples/sec: 0.71386\n",
            "I0410 09:44:55.564300 140202582333312 tpu_estimator.py:2160] examples/sec: 0.71386\n",
            "INFO:tensorflow:global_step/sec: 0.0224036\n",
            "I0410 09:45:40.198623 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224036\n",
            "INFO:tensorflow:examples/sec: 0.716914\n",
            "I0410 09:45:40.199057 140202582333312 tpu_estimator.py:2160] examples/sec: 0.716914\n",
            "INFO:tensorflow:global_step/sec: 0.0224182\n",
            "I0410 09:46:24.805259 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224182\n",
            "INFO:tensorflow:examples/sec: 0.717382\n",
            "I0410 09:46:24.805712 140202582333312 tpu_estimator.py:2160] examples/sec: 0.717382\n",
            "INFO:tensorflow:global_step/sec: 0.0225667\n",
            "I0410 09:47:09.118356 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225667\n",
            "INFO:tensorflow:examples/sec: 0.722134\n",
            "I0410 09:47:09.119833 140202582333312 tpu_estimator.py:2160] examples/sec: 0.722134\n",
            "INFO:tensorflow:global_step/sec: 0.0220906\n",
            "I0410 09:47:54.386474 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220906\n",
            "INFO:tensorflow:examples/sec: 0.706901\n",
            "I0410 09:47:54.386902 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706901\n",
            "INFO:tensorflow:global_step/sec: 0.0224977\n",
            "I0410 09:48:38.835371 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224977\n",
            "INFO:tensorflow:examples/sec: 0.719927\n",
            "I0410 09:48:38.835812 140202582333312 tpu_estimator.py:2160] examples/sec: 0.719927\n",
            "INFO:tensorflow:global_step/sec: 0.0225036\n",
            "I0410 09:49:23.272791 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225036\n",
            "INFO:tensorflow:examples/sec: 0.720115\n",
            "I0410 09:49:23.274230 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720115\n",
            "INFO:tensorflow:global_step/sec: 0.0225596\n",
            "I0410 09:50:07.599851 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225596\n",
            "INFO:tensorflow:examples/sec: 0.721906\n",
            "I0410 09:50:07.600288 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721906\n",
            "INFO:tensorflow:global_step/sec: 0.0224521\n",
            "I0410 09:50:52.138998 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224521\n",
            "INFO:tensorflow:examples/sec: 0.718468\n",
            "I0410 09:50:52.139511 140202582333312 tpu_estimator.py:2160] examples/sec: 0.718468\n",
            "INFO:tensorflow:global_step/sec: 0.0224944\n",
            "I0410 09:51:36.594563 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224944\n",
            "INFO:tensorflow:examples/sec: 0.71982\n",
            "I0410 09:51:36.595659 140202582333312 tpu_estimator.py:2160] examples/sec: 0.71982\n",
            "INFO:tensorflow:Saving checkpoints for 420 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 09:52:21.613011 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 420 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0193125\n",
            "I0410 09:52:28.374353 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0193125\n",
            "INFO:tensorflow:examples/sec: 0.618001\n",
            "I0410 09:52:28.374734 140202582333312 tpu_estimator.py:2160] examples/sec: 0.618001\n",
            "INFO:tensorflow:global_step/sec: 0.0219798\n",
            "I0410 09:53:13.871121 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219798\n",
            "INFO:tensorflow:examples/sec: 0.703353\n",
            "I0410 09:53:13.871468 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703353\n",
            "INFO:tensorflow:global_step/sec: 0.0224877\n",
            "I0410 09:53:58.339462 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224877\n",
            "INFO:tensorflow:examples/sec: 0.719608\n",
            "I0410 09:53:58.340861 140202582333312 tpu_estimator.py:2160] examples/sec: 0.719608\n",
            "INFO:tensorflow:global_step/sec: 0.0223045\n",
            "I0410 09:54:43.173520 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223045\n",
            "INFO:tensorflow:examples/sec: 0.713743\n",
            "I0410 09:54:43.174071 140202582333312 tpu_estimator.py:2160] examples/sec: 0.713743\n",
            "INFO:tensorflow:global_step/sec: 0.0221987\n",
            "I0410 09:55:28.221223 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221987\n",
            "INFO:tensorflow:examples/sec: 0.710359\n",
            "I0410 09:55:28.221694 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710359\n",
            "INFO:tensorflow:global_step/sec: 0.0224444\n",
            "I0410 09:56:12.775707 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224444\n",
            "INFO:tensorflow:examples/sec: 0.718222\n",
            "I0410 09:56:12.777174 140202582333312 tpu_estimator.py:2160] examples/sec: 0.718222\n",
            "INFO:tensorflow:global_step/sec: 0.0225131\n",
            "I0410 09:56:57.194272 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225131\n",
            "INFO:tensorflow:examples/sec: 0.720419\n",
            "I0410 09:56:57.194746 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720419\n",
            "INFO:tensorflow:global_step/sec: 0.0225865\n",
            "I0410 09:57:41.468532 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225865\n",
            "INFO:tensorflow:examples/sec: 0.722768\n",
            "I0410 09:57:41.469050 140202582333312 tpu_estimator.py:2160] examples/sec: 0.722768\n",
            "INFO:tensorflow:global_step/sec: 0.0225195\n",
            "I0410 09:58:25.874413 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225195\n",
            "INFO:tensorflow:examples/sec: 0.720626\n",
            "I0410 09:58:25.875667 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720626\n",
            "INFO:tensorflow:global_step/sec: 0.0225337\n",
            "I0410 09:59:10.252359 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225337\n",
            "INFO:tensorflow:examples/sec: 0.721079\n",
            "I0410 09:59:10.252873 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721079\n",
            "INFO:tensorflow:global_step/sec: 0.0222938\n",
            "I0410 09:59:55.107902 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222938\n",
            "INFO:tensorflow:examples/sec: 0.713401\n",
            "I0410 09:59:55.108406 140202582333312 tpu_estimator.py:2160] examples/sec: 0.713401\n",
            "INFO:tensorflow:global_step/sec: 0.022502\n",
            "I0410 10:00:39.548372 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022502\n",
            "INFO:tensorflow:examples/sec: 0.720064\n",
            "I0410 10:00:39.548657 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720064\n",
            "INFO:tensorflow:global_step/sec: 0.0222924\n",
            "I0410 10:01:24.406800 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222924\n",
            "INFO:tensorflow:examples/sec: 0.713355\n",
            "I0410 10:01:24.407076 140202582333312 tpu_estimator.py:2160] examples/sec: 0.713355\n",
            "INFO:tensorflow:global_step/sec: 0.0222442\n",
            "I0410 10:02:09.362375 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222442\n",
            "INFO:tensorflow:examples/sec: 0.711814\n",
            "I0410 10:02:09.363063 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711814\n",
            "INFO:tensorflow:global_step/sec: 0.022262\n",
            "I0410 10:02:54.281847 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022262\n",
            "INFO:tensorflow:examples/sec: 0.712386\n",
            "I0410 10:02:54.283199 140202582333312 tpu_estimator.py:2160] examples/sec: 0.712386\n",
            "INFO:tensorflow:global_step/sec: 0.022432\n",
            "I0410 10:03:38.861300 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022432\n",
            "INFO:tensorflow:examples/sec: 0.717823\n",
            "I0410 10:03:38.861867 140202582333312 tpu_estimator.py:2160] examples/sec: 0.717823\n",
            "INFO:tensorflow:global_step/sec: 0.0223756\n",
            "I0410 10:04:23.552640 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223756\n",
            "INFO:tensorflow:examples/sec: 0.716019\n",
            "I0410 10:04:23.553115 140202582333312 tpu_estimator.py:2160] examples/sec: 0.716019\n",
            "INFO:tensorflow:global_step/sec: 0.022551\n",
            "I0410 10:05:07.896701 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022551\n",
            "INFO:tensorflow:examples/sec: 0.721633\n",
            "I0410 10:05:07.897066 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721633\n",
            "INFO:tensorflow:global_step/sec: 0.0225208\n",
            "I0410 10:05:52.299923 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225208\n",
            "INFO:tensorflow:examples/sec: 0.720665\n",
            "I0410 10:05:52.300419 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720665\n",
            "INFO:tensorflow:global_step/sec: 0.0224298\n",
            "I0410 10:06:36.883453 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224298\n",
            "INFO:tensorflow:examples/sec: 0.717754\n",
            "I0410 10:06:36.883960 140202582333312 tpu_estimator.py:2160] examples/sec: 0.717754\n",
            "INFO:tensorflow:Saving checkpoints for 440 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 10:07:21.290725 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 440 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0192487\n",
            "I0410 10:07:28.834940 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0192487\n",
            "INFO:tensorflow:examples/sec: 0.615959\n",
            "I0410 10:07:28.835243 140202582333312 tpu_estimator.py:2160] examples/sec: 0.615959\n",
            "INFO:tensorflow:global_step/sec: 0.0218839\n",
            "I0410 10:08:14.530745 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218839\n",
            "INFO:tensorflow:examples/sec: 0.700283\n",
            "I0410 10:08:14.531040 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700283\n",
            "INFO:tensorflow:global_step/sec: 0.0222758\n",
            "I0410 10:08:59.422596 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222758\n",
            "INFO:tensorflow:examples/sec: 0.712824\n",
            "I0410 10:08:59.423063 140202582333312 tpu_estimator.py:2160] examples/sec: 0.712824\n",
            "INFO:tensorflow:global_step/sec: 0.0221385\n",
            "I0410 10:09:44.592705 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221385\n",
            "INFO:tensorflow:examples/sec: 0.708433\n",
            "I0410 10:09:44.592996 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708433\n",
            "INFO:tensorflow:global_step/sec: 0.0224428\n",
            "I0410 10:10:29.150525 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224428\n",
            "INFO:tensorflow:examples/sec: 0.718168\n",
            "I0410 10:10:29.150975 140202582333312 tpu_estimator.py:2160] examples/sec: 0.718168\n",
            "INFO:tensorflow:global_step/sec: 0.0225245\n",
            "I0410 10:11:13.546604 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225245\n",
            "INFO:tensorflow:examples/sec: 0.720785\n",
            "I0410 10:11:13.547032 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720785\n",
            "INFO:tensorflow:global_step/sec: 0.0224247\n",
            "I0410 10:11:58.140332 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224247\n",
            "INFO:tensorflow:examples/sec: 0.717589\n",
            "I0410 10:11:58.141785 140202582333312 tpu_estimator.py:2160] examples/sec: 0.717589\n",
            "INFO:tensorflow:global_step/sec: 0.0224662\n",
            "I0410 10:12:42.651589 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224662\n",
            "INFO:tensorflow:examples/sec: 0.718919\n",
            "I0410 10:12:42.652000 140202582333312 tpu_estimator.py:2160] examples/sec: 0.718919\n",
            "INFO:tensorflow:global_step/sec: 0.0224353\n",
            "I0410 10:13:27.224173 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224353\n",
            "INFO:tensorflow:examples/sec: 0.717931\n",
            "I0410 10:13:27.224643 140202582333312 tpu_estimator.py:2160] examples/sec: 0.717931\n",
            "INFO:tensorflow:global_step/sec: 0.0223315\n",
            "I0410 10:14:12.003999 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223315\n",
            "INFO:tensorflow:examples/sec: 0.714608\n",
            "I0410 10:14:12.005338 140202582333312 tpu_estimator.py:2160] examples/sec: 0.714608\n",
            "INFO:tensorflow:global_step/sec: 0.0223481\n",
            "I0410 10:14:56.750402 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223481\n",
            "INFO:tensorflow:examples/sec: 0.71514\n",
            "I0410 10:14:56.750821 140202582333312 tpu_estimator.py:2160] examples/sec: 0.71514\n",
            "INFO:tensorflow:global_step/sec: 0.0223231\n",
            "I0410 10:15:41.546955 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223231\n",
            "INFO:tensorflow:examples/sec: 0.714341\n",
            "I0410 10:15:41.547406 140202582333312 tpu_estimator.py:2160] examples/sec: 0.714341\n",
            "INFO:tensorflow:global_step/sec: 0.0224704\n",
            "I0410 10:16:26.050057 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224704\n",
            "INFO:tensorflow:examples/sec: 0.719053\n",
            "I0410 10:16:26.051650 140202582333312 tpu_estimator.py:2160] examples/sec: 0.719053\n",
            "INFO:tensorflow:global_step/sec: 0.0223165\n",
            "I0410 10:17:10.859927 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223165\n",
            "INFO:tensorflow:examples/sec: 0.714128\n",
            "I0410 10:17:10.860293 140202582333312 tpu_estimator.py:2160] examples/sec: 0.714128\n",
            "INFO:tensorflow:global_step/sec: 0.0222459\n",
            "I0410 10:17:55.811919 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222459\n",
            "INFO:tensorflow:examples/sec: 0.71187\n",
            "I0410 10:17:55.812206 140202582333312 tpu_estimator.py:2160] examples/sec: 0.71187\n",
            "INFO:tensorflow:global_step/sec: 0.0225309\n",
            "I0410 10:18:40.195472 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225309\n",
            "INFO:tensorflow:examples/sec: 0.720988\n",
            "I0410 10:18:40.195784 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720988\n",
            "INFO:tensorflow:global_step/sec: 0.0223226\n",
            "I0410 10:19:24.993183 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223226\n",
            "INFO:tensorflow:examples/sec: 0.714323\n",
            "I0410 10:19:24.993449 140202582333312 tpu_estimator.py:2160] examples/sec: 0.714323\n",
            "INFO:tensorflow:global_step/sec: 0.0224788\n",
            "I0410 10:20:09.479539 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224788\n",
            "INFO:tensorflow:examples/sec: 0.719321\n",
            "I0410 10:20:09.480004 140202582333312 tpu_estimator.py:2160] examples/sec: 0.719321\n",
            "INFO:tensorflow:global_step/sec: 0.0225889\n",
            "I0410 10:20:53.749075 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225889\n",
            "INFO:tensorflow:examples/sec: 0.722844\n",
            "I0410 10:20:53.749370 140202582333312 tpu_estimator.py:2160] examples/sec: 0.722844\n",
            "INFO:tensorflow:global_step/sec: 0.0225996\n",
            "I0410 10:21:37.997676 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225996\n",
            "INFO:tensorflow:examples/sec: 0.723188\n",
            "I0410 10:21:37.998105 140202582333312 tpu_estimator.py:2160] examples/sec: 0.723188\n",
            "INFO:tensorflow:Saving checkpoints for 460 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 10:22:22.358013 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 460 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0196131\n",
            "I0410 10:22:28.983979 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0196131\n",
            "INFO:tensorflow:examples/sec: 0.627619\n",
            "I0410 10:22:28.984330 140202582333312 tpu_estimator.py:2160] examples/sec: 0.627619\n",
            "INFO:tensorflow:global_step/sec: 0.0220619\n",
            "I0410 10:23:14.310986 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220619\n",
            "INFO:tensorflow:examples/sec: 0.705981\n",
            "I0410 10:23:14.311290 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705981\n",
            "INFO:tensorflow:global_step/sec: 0.022401\n",
            "I0410 10:23:58.951955 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022401\n",
            "INFO:tensorflow:examples/sec: 0.716831\n",
            "I0410 10:23:58.952248 140202582333312 tpu_estimator.py:2160] examples/sec: 0.716831\n",
            "INFO:tensorflow:global_step/sec: 0.0224416\n",
            "I0410 10:24:43.512157 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224416\n",
            "INFO:tensorflow:examples/sec: 0.71813\n",
            "I0410 10:24:43.512433 140202582333312 tpu_estimator.py:2160] examples/sec: 0.71813\n",
            "INFO:tensorflow:global_step/sec: 0.0225313\n",
            "I0410 10:25:27.894905 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225313\n",
            "INFO:tensorflow:examples/sec: 0.721001\n",
            "I0410 10:25:27.896059 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721001\n",
            "INFO:tensorflow:global_step/sec: 0.022533\n",
            "I0410 10:26:12.274248 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022533\n",
            "INFO:tensorflow:examples/sec: 0.721057\n",
            "I0410 10:26:12.274663 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721057\n",
            "INFO:tensorflow:global_step/sec: 0.0224583\n",
            "I0410 10:26:56.801225 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224583\n",
            "INFO:tensorflow:examples/sec: 0.718666\n",
            "I0410 10:26:56.801634 140202582333312 tpu_estimator.py:2160] examples/sec: 0.718666\n",
            "INFO:tensorflow:global_step/sec: 0.0225376\n",
            "I0410 10:27:41.171540 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225376\n",
            "INFO:tensorflow:examples/sec: 0.721202\n",
            "I0410 10:27:41.172698 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721202\n",
            "INFO:tensorflow:global_step/sec: 0.0225464\n",
            "I0410 10:28:25.524470 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225464\n",
            "INFO:tensorflow:examples/sec: 0.721485\n",
            "I0410 10:28:25.524902 140202582333312 tpu_estimator.py:2160] examples/sec: 0.721485\n",
            "INFO:tensorflow:global_step/sec: 0.0224624\n",
            "I0410 10:29:10.043518 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224624\n",
            "INFO:tensorflow:examples/sec: 0.718795\n",
            "I0410 10:29:10.044054 140202582333312 tpu_estimator.py:2160] examples/sec: 0.718795\n",
            "INFO:tensorflow:global_step/sec: 0.0224291\n",
            "I0410 10:29:54.628326 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224291\n",
            "INFO:tensorflow:examples/sec: 0.717732\n",
            "I0410 10:29:54.629492 140202582333312 tpu_estimator.py:2160] examples/sec: 0.717732\n",
            "INFO:tensorflow:global_step/sec: 0.0225104\n",
            "I0410 10:30:39.052180 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225104\n",
            "INFO:tensorflow:examples/sec: 0.720334\n",
            "I0410 10:30:39.052509 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720334\n",
            "INFO:tensorflow:global_step/sec: 0.0224277\n",
            "I0410 10:31:23.640042 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224277\n",
            "INFO:tensorflow:examples/sec: 0.717688\n",
            "I0410 10:31:23.640473 140202582333312 tpu_estimator.py:2160] examples/sec: 0.717688\n",
            "INFO:tensorflow:global_step/sec: 0.0224598\n",
            "I0410 10:32:08.163993 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224598\n",
            "INFO:tensorflow:examples/sec: 0.718713\n",
            "I0410 10:32:08.165382 140202582333312 tpu_estimator.py:2160] examples/sec: 0.718713\n",
            "INFO:tensorflow:global_step/sec: 0.0226333\n",
            "I0410 10:32:52.346573 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0226333\n",
            "INFO:tensorflow:examples/sec: 0.724264\n",
            "I0410 10:32:52.346977 140202582333312 tpu_estimator.py:2160] examples/sec: 0.724264\n",
            "INFO:tensorflow:global_step/sec: 0.0225697\n",
            "I0410 10:33:36.653822 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225697\n",
            "INFO:tensorflow:examples/sec: 0.722229\n",
            "I0410 10:33:36.654246 140202582333312 tpu_estimator.py:2160] examples/sec: 0.722229\n",
            "INFO:tensorflow:global_step/sec: 0.0222755\n",
            "I0410 10:34:21.546103 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222755\n",
            "INFO:tensorflow:examples/sec: 0.712818\n",
            "I0410 10:34:21.547536 140202582333312 tpu_estimator.py:2160] examples/sec: 0.712818\n",
            "INFO:tensorflow:global_step/sec: 0.0223669\n",
            "I0410 10:35:06.255063 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223669\n",
            "INFO:tensorflow:examples/sec: 0.71574\n",
            "I0410 10:35:06.255533 140202582333312 tpu_estimator.py:2160] examples/sec: 0.71574\n",
            "INFO:tensorflow:global_step/sec: 0.0224527\n",
            "I0410 10:35:50.793230 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0224527\n",
            "INFO:tensorflow:examples/sec: 0.718486\n",
            "I0410 10:35:50.793528 140202582333312 tpu_estimator.py:2160] examples/sec: 0.718486\n",
            "INFO:tensorflow:global_step/sec: 0.022634\n",
            "I0410 10:36:34.974547 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022634\n",
            "INFO:tensorflow:examples/sec: 0.724287\n",
            "I0410 10:36:34.974819 140202582333312 tpu_estimator.py:2160] examples/sec: 0.724287\n",
            "INFO:tensorflow:Saving checkpoints for 480 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 10:37:20.110444 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 480 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0193487\n",
            "I0410 10:37:26.657724 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0193487\n",
            "INFO:tensorflow:examples/sec: 0.619157\n",
            "I0410 10:37:26.658121 140202582333312 tpu_estimator.py:2160] examples/sec: 0.619157\n",
            "INFO:tensorflow:global_step/sec: 0.0216216\n",
            "I0410 10:38:12.907757 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216216\n",
            "INFO:tensorflow:examples/sec: 0.691892\n",
            "I0410 10:38:12.908055 140202582333312 tpu_estimator.py:2160] examples/sec: 0.691892\n",
            "INFO:tensorflow:global_step/sec: 0.0223544\n",
            "I0410 10:38:57.641591 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223544\n",
            "INFO:tensorflow:examples/sec: 0.715342\n",
            "I0410 10:38:57.641879 140202582333312 tpu_estimator.py:2160] examples/sec: 0.715342\n",
            "INFO:tensorflow:global_step/sec: 0.0225202\n",
            "I0410 10:39:42.046273 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0225202\n",
            "INFO:tensorflow:examples/sec: 0.720645\n",
            "I0410 10:39:42.046692 140202582333312 tpu_estimator.py:2160] examples/sec: 0.720645\n",
            "INFO:tensorflow:global_step/sec: 0.0223789\n",
            "I0410 10:40:26.731286 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223789\n",
            "INFO:tensorflow:examples/sec: 0.716123\n",
            "I0410 10:40:26.731563 140202582333312 tpu_estimator.py:2160] examples/sec: 0.716123\n",
            "INFO:tensorflow:global_step/sec: 0.0221771\n",
            "I0410 10:41:11.823060 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221771\n",
            "INFO:tensorflow:examples/sec: 0.709666\n",
            "I0410 10:41:11.824211 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709666\n",
            "INFO:tensorflow:global_step/sec: 0.0222726\n",
            "I0410 10:41:56.721022 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222726\n",
            "INFO:tensorflow:examples/sec: 0.712725\n",
            "I0410 10:41:56.721446 140202582333312 tpu_estimator.py:2160] examples/sec: 0.712725\n",
            "INFO:tensorflow:global_step/sec: 0.022365\n",
            "I0410 10:42:41.433707 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022365\n",
            "INFO:tensorflow:examples/sec: 0.715681\n",
            "I0410 10:42:41.434115 140202582333312 tpu_estimator.py:2160] examples/sec: 0.715681\n",
            "INFO:tensorflow:global_step/sec: 0.0222252\n",
            "I0410 10:43:26.427737 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222252\n",
            "INFO:tensorflow:examples/sec: 0.711206\n",
            "I0410 10:43:26.429128 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711206\n",
            "INFO:tensorflow:global_step/sec: 0.0222167\n",
            "I0410 10:44:11.438795 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222167\n",
            "INFO:tensorflow:examples/sec: 0.710936\n",
            "I0410 10:44:11.439312 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710936\n",
            "INFO:tensorflow:global_step/sec: 0.0220577\n",
            "I0410 10:44:56.774358 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220577\n",
            "INFO:tensorflow:examples/sec: 0.705847\n",
            "I0410 10:44:56.774783 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705847\n",
            "INFO:tensorflow:global_step/sec: 0.0219412\n",
            "I0410 10:45:42.350791 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219412\n",
            "INFO:tensorflow:examples/sec: 0.702117\n",
            "I0410 10:45:42.351961 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702117\n",
            "INFO:tensorflow:global_step/sec: 0.0220111\n",
            "I0410 10:46:27.782397 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220111\n",
            "INFO:tensorflow:examples/sec: 0.704355\n",
            "I0410 10:46:27.782855 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704355\n",
            "INFO:tensorflow:global_step/sec: 0.0221825\n",
            "I0410 10:47:12.863067 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221825\n",
            "INFO:tensorflow:examples/sec: 0.709838\n",
            "I0410 10:47:12.863506 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709838\n",
            "INFO:tensorflow:global_step/sec: 0.022255\n",
            "I0410 10:47:57.796859 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022255\n",
            "INFO:tensorflow:examples/sec: 0.712159\n",
            "I0410 10:47:57.798317 140202582333312 tpu_estimator.py:2160] examples/sec: 0.712159\n",
            "INFO:tensorflow:global_step/sec: 0.0222823\n",
            "I0410 10:48:42.675498 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222823\n",
            "INFO:tensorflow:examples/sec: 0.713034\n",
            "I0410 10:48:42.675914 140202582333312 tpu_estimator.py:2160] examples/sec: 0.713034\n",
            "INFO:tensorflow:global_step/sec: 0.0220188\n",
            "I0410 10:49:28.091435 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220188\n",
            "INFO:tensorflow:examples/sec: 0.704602\n",
            "I0410 10:49:28.091935 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704602\n",
            "INFO:tensorflow:global_step/sec: 0.0221695\n",
            "I0410 10:50:13.198251 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221695\n",
            "INFO:tensorflow:examples/sec: 0.709423\n",
            "I0410 10:50:13.198569 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709423\n",
            "INFO:tensorflow:global_step/sec: 0.0218936\n",
            "I0410 10:50:58.873690 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218936\n",
            "INFO:tensorflow:examples/sec: 0.700596\n",
            "I0410 10:50:58.873965 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700596\n",
            "INFO:tensorflow:global_step/sec: 0.022181\n",
            "I0410 10:51:43.957365 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022181\n",
            "INFO:tensorflow:examples/sec: 0.709792\n",
            "I0410 10:51:43.957782 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709792\n",
            "INFO:tensorflow:Saving checkpoints for 500 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 10:52:29.487237 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 500 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.019136\n",
            "I0410 10:52:36.214710 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.019136\n",
            "INFO:tensorflow:examples/sec: 0.612353\n",
            "I0410 10:52:36.214978 140202582333312 tpu_estimator.py:2160] examples/sec: 0.612353\n",
            "INFO:tensorflow:global_step/sec: 0.0217962\n",
            "I0410 10:53:22.094403 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217962\n",
            "INFO:tensorflow:examples/sec: 0.697478\n",
            "I0410 10:53:22.094790 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697478\n",
            "INFO:tensorflow:global_step/sec: 0.0220538\n",
            "I0410 10:54:07.438040 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220538\n",
            "INFO:tensorflow:examples/sec: 0.705721\n",
            "I0410 10:54:07.438508 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705721\n",
            "INFO:tensorflow:global_step/sec: 0.0220712\n",
            "I0410 10:54:52.745945 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220712\n",
            "INFO:tensorflow:examples/sec: 0.706278\n",
            "I0410 10:54:52.747175 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706278\n",
            "INFO:tensorflow:global_step/sec: 0.0220726\n",
            "I0410 10:55:38.051107 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220726\n",
            "INFO:tensorflow:examples/sec: 0.706322\n",
            "I0410 10:55:38.051486 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706322\n",
            "INFO:tensorflow:global_step/sec: 0.0222068\n",
            "I0410 10:56:23.082365 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222068\n",
            "INFO:tensorflow:examples/sec: 0.710618\n",
            "I0410 10:56:23.082654 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710618\n",
            "INFO:tensorflow:global_step/sec: 0.0217852\n",
            "I0410 10:57:08.985190 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217852\n",
            "INFO:tensorflow:examples/sec: 0.697125\n",
            "I0410 10:57:08.986677 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697125\n",
            "INFO:tensorflow:global_step/sec: 0.0222489\n",
            "I0410 10:57:53.931196 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222489\n",
            "INFO:tensorflow:examples/sec: 0.711966\n",
            "I0410 10:57:53.931710 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711966\n",
            "INFO:tensorflow:global_step/sec: 0.0218255\n",
            "I0410 10:58:39.749229 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218255\n",
            "INFO:tensorflow:examples/sec: 0.698417\n",
            "I0410 10:58:39.749645 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698417\n",
            "INFO:tensorflow:global_step/sec: 0.0218254\n",
            "I0410 10:59:25.567357 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218254\n",
            "INFO:tensorflow:examples/sec: 0.698413\n",
            "I0410 10:59:25.568531 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698413\n",
            "INFO:tensorflow:global_step/sec: 0.0220059\n",
            "I0410 11:00:11.009569 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220059\n",
            "INFO:tensorflow:examples/sec: 0.704188\n",
            "I0410 11:00:11.009871 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704188\n",
            "INFO:tensorflow:global_step/sec: 0.0221214\n",
            "I0410 11:00:56.214684 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221214\n",
            "INFO:tensorflow:examples/sec: 0.707885\n",
            "I0410 11:00:56.215094 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707885\n",
            "INFO:tensorflow:global_step/sec: 0.0220985\n",
            "I0410 11:01:41.466600 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220985\n",
            "INFO:tensorflow:examples/sec: 0.707152\n",
            "I0410 11:01:41.467775 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707152\n",
            "INFO:tensorflow:global_step/sec: 0.022215\n",
            "I0410 11:02:26.481285 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022215\n",
            "INFO:tensorflow:examples/sec: 0.71088\n",
            "I0410 11:02:26.481756 140202582333312 tpu_estimator.py:2160] examples/sec: 0.71088\n",
            "INFO:tensorflow:global_step/sec: 0.0221171\n",
            "I0410 11:03:11.695172 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221171\n",
            "INFO:tensorflow:examples/sec: 0.707747\n",
            "I0410 11:03:11.695607 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707747\n",
            "INFO:tensorflow:global_step/sec: 0.022004\n",
            "I0410 11:03:57.141544 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022004\n",
            "INFO:tensorflow:examples/sec: 0.704127\n",
            "I0410 11:03:57.142730 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704127\n",
            "INFO:tensorflow:global_step/sec: 0.0220269\n",
            "I0410 11:04:42.540595 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220269\n",
            "INFO:tensorflow:examples/sec: 0.70486\n",
            "I0410 11:04:42.540998 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70486\n",
            "INFO:tensorflow:global_step/sec: 0.022167\n",
            "I0410 11:05:27.652763 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022167\n",
            "INFO:tensorflow:examples/sec: 0.709344\n",
            "I0410 11:05:27.653206 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709344\n",
            "INFO:tensorflow:global_step/sec: 0.0218974\n",
            "I0410 11:06:13.320357 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218974\n",
            "INFO:tensorflow:examples/sec: 0.700717\n",
            "I0410 11:06:13.321507 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700717\n",
            "INFO:tensorflow:global_step/sec: 0.0219413\n",
            "I0410 11:06:58.896497 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219413\n",
            "INFO:tensorflow:examples/sec: 0.702122\n",
            "I0410 11:06:58.896943 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702122\n",
            "INFO:tensorflow:Saving checkpoints for 520 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 11:07:44.201122 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 520 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0189504\n",
            "I0410 11:07:51.665534 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0189504\n",
            "INFO:tensorflow:examples/sec: 0.606414\n",
            "I0410 11:07:51.665889 140202582333312 tpu_estimator.py:2160] examples/sec: 0.606414\n",
            "INFO:tensorflow:global_step/sec: 0.0215915\n",
            "I0410 11:08:37.980291 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215915\n",
            "INFO:tensorflow:examples/sec: 0.690927\n",
            "I0410 11:08:37.980599 140202582333312 tpu_estimator.py:2160] examples/sec: 0.690927\n",
            "INFO:tensorflow:global_step/sec: 0.0220859\n",
            "I0410 11:09:23.257850 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220859\n",
            "INFO:tensorflow:examples/sec: 0.70675\n",
            "I0410 11:09:23.258150 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70675\n",
            "INFO:tensorflow:global_step/sec: 0.021939\n",
            "I0410 11:10:08.838838 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021939\n",
            "INFO:tensorflow:examples/sec: 0.702047\n",
            "I0410 11:10:08.839314 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702047\n",
            "INFO:tensorflow:global_step/sec: 0.0221363\n",
            "I0410 11:10:54.013491 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221363\n",
            "INFO:tensorflow:examples/sec: 0.708361\n",
            "I0410 11:10:54.014965 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708361\n",
            "INFO:tensorflow:global_step/sec: 0.0220511\n",
            "I0410 11:11:39.362723 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220511\n",
            "INFO:tensorflow:examples/sec: 0.705635\n",
            "I0410 11:11:39.363261 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705635\n",
            "INFO:tensorflow:global_step/sec: 0.0221467\n",
            "I0410 11:12:24.516193 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221467\n",
            "INFO:tensorflow:examples/sec: 0.708694\n",
            "I0410 11:12:24.516639 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708694\n",
            "INFO:tensorflow:global_step/sec: 0.0221166\n",
            "I0410 11:13:09.731066 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221166\n",
            "INFO:tensorflow:examples/sec: 0.707732\n",
            "I0410 11:13:09.732704 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707732\n",
            "INFO:tensorflow:global_step/sec: 0.0221773\n",
            "I0410 11:13:54.822305 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221773\n",
            "INFO:tensorflow:examples/sec: 0.709672\n",
            "I0410 11:13:54.822771 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709672\n",
            "INFO:tensorflow:global_step/sec: 0.0219927\n",
            "I0410 11:14:40.291902 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219927\n",
            "INFO:tensorflow:examples/sec: 0.703767\n",
            "I0410 11:14:40.292329 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703767\n",
            "INFO:tensorflow:global_step/sec: 0.0219687\n",
            "I0410 11:15:25.811333 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219687\n",
            "INFO:tensorflow:examples/sec: 0.702997\n",
            "I0410 11:15:25.812446 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702997\n",
            "INFO:tensorflow:global_step/sec: 0.0221227\n",
            "I0410 11:16:11.013818 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221227\n",
            "INFO:tensorflow:examples/sec: 0.707926\n",
            "I0410 11:16:11.014280 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707926\n",
            "INFO:tensorflow:global_step/sec: 0.0221083\n",
            "I0410 11:16:56.245558 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221083\n",
            "INFO:tensorflow:examples/sec: 0.707467\n",
            "I0410 11:16:56.245999 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707467\n",
            "INFO:tensorflow:global_step/sec: 0.0218007\n",
            "I0410 11:17:42.115690 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218007\n",
            "INFO:tensorflow:examples/sec: 0.697623\n",
            "I0410 11:17:42.117212 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697623\n",
            "INFO:tensorflow:global_step/sec: 0.0219474\n",
            "I0410 11:18:27.679121 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219474\n",
            "INFO:tensorflow:examples/sec: 0.702318\n",
            "I0410 11:18:27.679590 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702318\n",
            "INFO:tensorflow:global_step/sec: 0.0222111\n",
            "I0410 11:19:12.701621 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222111\n",
            "INFO:tensorflow:examples/sec: 0.710755\n",
            "I0410 11:19:12.701897 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710755\n",
            "INFO:tensorflow:global_step/sec: 0.0220269\n",
            "I0410 11:19:58.100579 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220269\n",
            "INFO:tensorflow:examples/sec: 0.704862\n",
            "I0410 11:19:58.102086 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704862\n",
            "INFO:tensorflow:global_step/sec: 0.0220799\n",
            "I0410 11:20:43.390664 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220799\n",
            "INFO:tensorflow:examples/sec: 0.706556\n",
            "I0410 11:20:43.391096 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706556\n",
            "INFO:tensorflow:global_step/sec: 0.0220365\n",
            "I0410 11:21:28.769988 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220365\n",
            "INFO:tensorflow:examples/sec: 0.705167\n",
            "I0410 11:21:28.770443 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705167\n",
            "INFO:tensorflow:global_step/sec: 0.0221511\n",
            "I0410 11:22:13.914419 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221511\n",
            "INFO:tensorflow:examples/sec: 0.708836\n",
            "I0410 11:22:13.914704 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708836\n",
            "INFO:tensorflow:Saving checkpoints for 540 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 11:22:59.121765 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 540 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0190711\n",
            "I0410 11:23:06.349834 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0190711\n",
            "INFO:tensorflow:examples/sec: 0.610274\n",
            "I0410 11:23:06.350341 140202582333312 tpu_estimator.py:2160] examples/sec: 0.610274\n",
            "INFO:tensorflow:global_step/sec: 0.0218459\n",
            "I0410 11:23:52.125174 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218459\n",
            "INFO:tensorflow:examples/sec: 0.699068\n",
            "I0410 11:23:52.125628 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699068\n",
            "INFO:tensorflow:global_step/sec: 0.0219316\n",
            "I0410 11:24:37.721501 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219316\n",
            "INFO:tensorflow:examples/sec: 0.701811\n",
            "I0410 11:24:37.721787 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701811\n",
            "INFO:tensorflow:global_step/sec: 0.0222311\n",
            "I0410 11:25:22.703482 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222311\n",
            "INFO:tensorflow:examples/sec: 0.711395\n",
            "I0410 11:25:22.703760 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711395\n",
            "INFO:tensorflow:global_step/sec: 0.0221138\n",
            "I0410 11:26:07.924279 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221138\n",
            "INFO:tensorflow:examples/sec: 0.70764\n",
            "I0410 11:26:07.924596 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70764\n",
            "INFO:tensorflow:global_step/sec: 0.0221293\n",
            "I0410 11:26:53.113198 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221293\n",
            "INFO:tensorflow:examples/sec: 0.708138\n",
            "I0410 11:26:53.114757 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708138\n",
            "INFO:tensorflow:global_step/sec: 0.0220557\n",
            "I0410 11:27:38.453265 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220557\n",
            "INFO:tensorflow:examples/sec: 0.705781\n",
            "I0410 11:27:38.453712 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705781\n",
            "INFO:tensorflow:global_step/sec: 0.022095\n",
            "I0410 11:28:23.712307 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022095\n",
            "INFO:tensorflow:examples/sec: 0.707039\n",
            "I0410 11:28:23.712749 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707039\n",
            "INFO:tensorflow:global_step/sec: 0.0220488\n",
            "I0410 11:29:09.066218 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220488\n",
            "INFO:tensorflow:examples/sec: 0.70556\n",
            "I0410 11:29:09.067737 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70556\n",
            "INFO:tensorflow:global_step/sec: 0.0222683\n",
            "I0410 11:29:53.973147 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222683\n",
            "INFO:tensorflow:examples/sec: 0.712585\n",
            "I0410 11:29:53.973578 140202582333312 tpu_estimator.py:2160] examples/sec: 0.712585\n",
            "INFO:tensorflow:global_step/sec: 0.0216965\n",
            "I0410 11:30:40.063477 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216965\n",
            "INFO:tensorflow:examples/sec: 0.694289\n",
            "I0410 11:30:40.063909 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694289\n",
            "INFO:tensorflow:global_step/sec: 0.0220857\n",
            "I0410 11:31:25.341561 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220857\n",
            "INFO:tensorflow:examples/sec: 0.706744\n",
            "I0410 11:31:25.342704 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706744\n",
            "INFO:tensorflow:global_step/sec: 0.0219736\n",
            "I0410 11:32:10.850791 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219736\n",
            "INFO:tensorflow:examples/sec: 0.703154\n",
            "I0410 11:32:10.851252 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703154\n",
            "INFO:tensorflow:global_step/sec: 0.0218968\n",
            "I0410 11:32:56.519517 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218968\n",
            "INFO:tensorflow:examples/sec: 0.700698\n",
            "I0410 11:32:56.520101 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700698\n",
            "INFO:tensorflow:global_step/sec: 0.0218922\n",
            "I0410 11:33:42.197861 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218922\n",
            "INFO:tensorflow:examples/sec: 0.700552\n",
            "I0410 11:33:42.199007 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700552\n",
            "INFO:tensorflow:global_step/sec: 0.0220289\n",
            "I0410 11:34:27.592839 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220289\n",
            "INFO:tensorflow:examples/sec: 0.704924\n",
            "I0410 11:34:27.593365 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704924\n",
            "INFO:tensorflow:global_step/sec: 0.021959\n",
            "I0410 11:35:13.132261 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021959\n",
            "INFO:tensorflow:examples/sec: 0.702687\n",
            "I0410 11:35:13.132672 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702687\n",
            "INFO:tensorflow:global_step/sec: 0.0222248\n",
            "I0410 11:35:58.127067 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222248\n",
            "INFO:tensorflow:examples/sec: 0.711193\n",
            "I0410 11:35:58.127369 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711193\n",
            "INFO:tensorflow:global_step/sec: 0.0223269\n",
            "I0410 11:36:42.915985 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0223269\n",
            "INFO:tensorflow:examples/sec: 0.714462\n",
            "I0410 11:36:42.916392 140202582333312 tpu_estimator.py:2160] examples/sec: 0.714462\n",
            "INFO:tensorflow:global_step/sec: 0.0220953\n",
            "I0410 11:37:28.174602 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220953\n",
            "INFO:tensorflow:examples/sec: 0.707049\n",
            "I0410 11:37:28.175026 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707049\n",
            "INFO:tensorflow:Saving checkpoints for 560 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 11:38:13.322661 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 560 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0188904\n",
            "I0410 11:38:21.111412 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0188904\n",
            "INFO:tensorflow:examples/sec: 0.604493\n",
            "I0410 11:38:21.111789 140202582333312 tpu_estimator.py:2160] examples/sec: 0.604493\n",
            "INFO:tensorflow:global_step/sec: 0.0217433\n",
            "I0410 11:39:07.102557 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217433\n",
            "INFO:tensorflow:examples/sec: 0.695787\n",
            "I0410 11:39:07.102862 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695787\n",
            "INFO:tensorflow:global_step/sec: 0.0221942\n",
            "I0410 11:39:52.159309 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221942\n",
            "INFO:tensorflow:examples/sec: 0.710216\n",
            "I0410 11:39:52.159590 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710216\n",
            "INFO:tensorflow:global_step/sec: 0.0221308\n",
            "I0410 11:40:37.345231 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221308\n",
            "INFO:tensorflow:examples/sec: 0.708185\n",
            "I0410 11:40:37.345509 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708185\n",
            "INFO:tensorflow:global_step/sec: 0.0221813\n",
            "I0410 11:41:22.428205 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221813\n",
            "INFO:tensorflow:examples/sec: 0.709802\n",
            "I0410 11:41:22.428686 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709802\n",
            "INFO:tensorflow:global_step/sec: 0.0221809\n",
            "I0410 11:42:07.512017 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221809\n",
            "INFO:tensorflow:examples/sec: 0.709789\n",
            "I0410 11:42:07.512573 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709789\n",
            "INFO:tensorflow:global_step/sec: 0.0221055\n",
            "I0410 11:42:52.749637 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221055\n",
            "INFO:tensorflow:examples/sec: 0.707376\n",
            "I0410 11:42:52.750769 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707376\n",
            "INFO:tensorflow:global_step/sec: 0.0222628\n",
            "I0410 11:43:37.667644 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222628\n",
            "INFO:tensorflow:examples/sec: 0.712409\n",
            "I0410 11:43:37.668101 140202582333312 tpu_estimator.py:2160] examples/sec: 0.712409\n",
            "INFO:tensorflow:global_step/sec: 0.0219485\n",
            "I0410 11:44:23.228865 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219485\n",
            "INFO:tensorflow:examples/sec: 0.702352\n",
            "I0410 11:44:23.229324 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702352\n",
            "INFO:tensorflow:global_step/sec: 0.0221534\n",
            "I0410 11:45:08.368589 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221534\n",
            "INFO:tensorflow:examples/sec: 0.70891\n",
            "I0410 11:45:08.370097 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70891\n",
            "INFO:tensorflow:global_step/sec: 0.0217692\n",
            "I0410 11:45:54.304947 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217692\n",
            "INFO:tensorflow:examples/sec: 0.696616\n",
            "I0410 11:45:54.305410 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696616\n",
            "INFO:tensorflow:global_step/sec: 0.0222683\n",
            "I0410 11:46:39.211901 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222683\n",
            "INFO:tensorflow:examples/sec: 0.712584\n",
            "I0410 11:46:39.212396 140202582333312 tpu_estimator.py:2160] examples/sec: 0.712584\n",
            "INFO:tensorflow:global_step/sec: 0.0221472\n",
            "I0410 11:47:24.364323 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221472\n",
            "INFO:tensorflow:examples/sec: 0.708711\n",
            "I0410 11:47:24.365480 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708711\n",
            "INFO:tensorflow:global_step/sec: 0.0219443\n",
            "I0410 11:48:09.934287 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219443\n",
            "INFO:tensorflow:examples/sec: 0.702219\n",
            "I0410 11:48:09.934571 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702219\n",
            "INFO:tensorflow:global_step/sec: 0.0221857\n",
            "I0410 11:48:55.008334 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221857\n",
            "INFO:tensorflow:examples/sec: 0.709942\n",
            "I0410 11:48:55.008836 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709942\n",
            "INFO:tensorflow:global_step/sec: 0.0222313\n",
            "I0410 11:49:39.989893 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222313\n",
            "INFO:tensorflow:examples/sec: 0.711402\n",
            "I0410 11:49:39.991060 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711402\n",
            "INFO:tensorflow:global_step/sec: 0.0218554\n",
            "I0410 11:50:25.745234 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218554\n",
            "INFO:tensorflow:examples/sec: 0.699372\n",
            "I0410 11:50:25.745508 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699372\n",
            "INFO:tensorflow:global_step/sec: 0.0221253\n",
            "I0410 11:51:10.942348 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221253\n",
            "INFO:tensorflow:examples/sec: 0.70801\n",
            "I0410 11:51:10.942622 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70801\n",
            "INFO:tensorflow:global_step/sec: 0.0219181\n",
            "I0410 11:51:56.566748 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219181\n",
            "INFO:tensorflow:examples/sec: 0.701378\n",
            "I0410 11:51:56.567865 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701378\n",
            "INFO:tensorflow:global_step/sec: 0.022019\n",
            "I0410 11:52:41.981961 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022019\n",
            "INFO:tensorflow:examples/sec: 0.704609\n",
            "I0410 11:52:41.982412 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704609\n",
            "INFO:tensorflow:Saving checkpoints for 580 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 11:53:27.382546 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 580 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0191252\n",
            "I0410 11:53:34.268868 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0191252\n",
            "INFO:tensorflow:examples/sec: 0.612007\n",
            "I0410 11:53:34.269212 140202582333312 tpu_estimator.py:2160] examples/sec: 0.612007\n",
            "INFO:tensorflow:global_step/sec: 0.0216282\n",
            "I0410 11:54:20.504781 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216282\n",
            "INFO:tensorflow:examples/sec: 0.692104\n",
            "I0410 11:54:20.505128 140202582333312 tpu_estimator.py:2160] examples/sec: 0.692104\n",
            "INFO:tensorflow:global_step/sec: 0.0218716\n",
            "I0410 11:55:06.226072 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218716\n",
            "INFO:tensorflow:examples/sec: 0.699892\n",
            "I0410 11:55:06.226550 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699892\n",
            "INFO:tensorflow:global_step/sec: 0.0220361\n",
            "I0410 11:55:51.606178 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220361\n",
            "INFO:tensorflow:examples/sec: 0.705155\n",
            "I0410 11:55:51.606637 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705155\n",
            "INFO:tensorflow:global_step/sec: 0.0222237\n",
            "I0410 11:56:36.603473 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222237\n",
            "INFO:tensorflow:examples/sec: 0.71116\n",
            "I0410 11:56:36.604794 140202582333312 tpu_estimator.py:2160] examples/sec: 0.71116\n",
            "INFO:tensorflow:global_step/sec: 0.0218864\n",
            "I0410 11:57:22.293745 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218864\n",
            "INFO:tensorflow:examples/sec: 0.700364\n",
            "I0410 11:57:22.294080 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700364\n",
            "INFO:tensorflow:global_step/sec: 0.0220617\n",
            "I0410 11:58:07.621064 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220617\n",
            "INFO:tensorflow:examples/sec: 0.705974\n",
            "I0410 11:58:07.621379 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705974\n",
            "INFO:tensorflow:global_step/sec: 0.0217239\n",
            "I0410 11:58:53.653371 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217239\n",
            "INFO:tensorflow:examples/sec: 0.695164\n",
            "I0410 11:58:53.654863 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695164\n",
            "INFO:tensorflow:global_step/sec: 0.0221639\n",
            "I0410 11:59:38.771836 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221639\n",
            "INFO:tensorflow:examples/sec: 0.709244\n",
            "I0410 11:59:38.772259 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709244\n",
            "INFO:tensorflow:global_step/sec: 0.0220797\n",
            "I0410 12:00:24.062311 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220797\n",
            "INFO:tensorflow:examples/sec: 0.706551\n",
            "I0410 12:00:24.062728 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706551\n",
            "INFO:tensorflow:global_step/sec: 0.0221317\n",
            "I0410 12:01:09.246461 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221317\n",
            "INFO:tensorflow:examples/sec: 0.708214\n",
            "I0410 12:01:09.247772 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708214\n",
            "INFO:tensorflow:global_step/sec: 0.0221696\n",
            "I0410 12:01:54.353125 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221696\n",
            "INFO:tensorflow:examples/sec: 0.709428\n",
            "I0410 12:01:54.353576 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709428\n",
            "INFO:tensorflow:global_step/sec: 0.0222296\n",
            "I0410 12:02:39.338380 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222296\n",
            "INFO:tensorflow:examples/sec: 0.711346\n",
            "I0410 12:02:39.338824 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711346\n",
            "INFO:tensorflow:global_step/sec: 0.0222003\n",
            "I0410 12:03:24.382740 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222003\n",
            "INFO:tensorflow:examples/sec: 0.710409\n",
            "I0410 12:03:24.383906 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710409\n",
            "INFO:tensorflow:global_step/sec: 0.0217171\n",
            "I0410 12:04:10.429496 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217171\n",
            "INFO:tensorflow:examples/sec: 0.694946\n",
            "I0410 12:04:10.429993 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694946\n",
            "INFO:tensorflow:global_step/sec: 0.0222131\n",
            "I0410 12:04:55.447979 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222131\n",
            "INFO:tensorflow:examples/sec: 0.71082\n",
            "I0410 12:04:55.448493 140202582333312 tpu_estimator.py:2160] examples/sec: 0.71082\n",
            "INFO:tensorflow:global_step/sec: 0.0221318\n",
            "I0410 12:05:40.631709 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221318\n",
            "INFO:tensorflow:examples/sec: 0.708218\n",
            "I0410 12:05:40.631985 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708218\n",
            "INFO:tensorflow:global_step/sec: 0.0221573\n",
            "I0410 12:06:25.763684 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221573\n",
            "INFO:tensorflow:examples/sec: 0.709033\n",
            "I0410 12:06:25.763953 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709033\n",
            "INFO:tensorflow:global_step/sec: 0.0221785\n",
            "I0410 12:07:10.852347 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221785\n",
            "INFO:tensorflow:examples/sec: 0.709713\n",
            "I0410 12:07:10.852799 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709713\n",
            "INFO:tensorflow:global_step/sec: 0.0218856\n",
            "I0410 12:07:56.544514 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218856\n",
            "INFO:tensorflow:examples/sec: 0.700339\n",
            "I0410 12:07:56.545840 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700339\n",
            "INFO:tensorflow:Saving checkpoints for 600 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 12:08:42.112813 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 600 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0187982\n",
            "I0410 12:08:49.740938 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0187982\n",
            "INFO:tensorflow:examples/sec: 0.601543\n",
            "I0410 12:08:49.741430 140202582333312 tpu_estimator.py:2160] examples/sec: 0.601543\n",
            "INFO:tensorflow:global_step/sec: 0.0213154\n",
            "I0410 12:09:36.655426 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0213154\n",
            "INFO:tensorflow:examples/sec: 0.682093\n",
            "I0410 12:09:36.655749 140202582333312 tpu_estimator.py:2160] examples/sec: 0.682093\n",
            "INFO:tensorflow:global_step/sec: 0.0220904\n",
            "I0410 12:10:21.923887 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220904\n",
            "INFO:tensorflow:examples/sec: 0.706894\n",
            "I0410 12:10:21.925324 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706894\n",
            "INFO:tensorflow:global_step/sec: 0.0220677\n",
            "I0410 12:11:07.238981 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220677\n",
            "INFO:tensorflow:examples/sec: 0.706166\n",
            "I0410 12:11:07.239425 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706166\n",
            "INFO:tensorflow:global_step/sec: 0.0221068\n",
            "I0410 12:11:52.474019 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221068\n",
            "INFO:tensorflow:examples/sec: 0.707417\n",
            "I0410 12:11:52.474459 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707417\n",
            "INFO:tensorflow:global_step/sec: 0.0221335\n",
            "I0410 12:12:37.654406 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221335\n",
            "INFO:tensorflow:examples/sec: 0.708273\n",
            "I0410 12:12:37.655831 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708273\n",
            "INFO:tensorflow:global_step/sec: 0.0220246\n",
            "I0410 12:13:23.058166 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220246\n",
            "INFO:tensorflow:examples/sec: 0.704787\n",
            "I0410 12:13:23.058578 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704787\n",
            "INFO:tensorflow:global_step/sec: 0.0217374\n",
            "I0410 12:14:09.061810 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217374\n",
            "INFO:tensorflow:examples/sec: 0.695597\n",
            "I0410 12:14:09.062256 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695597\n",
            "INFO:tensorflow:global_step/sec: 0.0221475\n",
            "I0410 12:14:54.213654 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221475\n",
            "INFO:tensorflow:examples/sec: 0.708719\n",
            "I0410 12:14:54.215060 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708719\n",
            "INFO:tensorflow:global_step/sec: 0.0221857\n",
            "I0410 12:15:39.287650 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221857\n",
            "INFO:tensorflow:examples/sec: 0.709944\n",
            "I0410 12:15:39.288064 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709944\n",
            "INFO:tensorflow:global_step/sec: 0.0221174\n",
            "I0410 12:16:24.501031 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221174\n",
            "INFO:tensorflow:examples/sec: 0.707755\n",
            "I0410 12:16:24.501506 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707755\n",
            "INFO:tensorflow:global_step/sec: 0.0220826\n",
            "I0410 12:17:09.785467 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220826\n",
            "INFO:tensorflow:examples/sec: 0.706644\n",
            "I0410 12:17:09.786604 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706644\n",
            "INFO:tensorflow:global_step/sec: 0.0221446\n",
            "I0410 12:17:54.943207 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221446\n",
            "INFO:tensorflow:examples/sec: 0.708628\n",
            "I0410 12:17:54.943636 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708628\n",
            "INFO:tensorflow:global_step/sec: 0.0219111\n",
            "I0410 12:18:40.582223 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219111\n",
            "INFO:tensorflow:examples/sec: 0.701154\n",
            "I0410 12:18:40.582681 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701154\n",
            "INFO:tensorflow:global_step/sec: 0.0221938\n",
            "I0410 12:19:25.639912 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221938\n",
            "INFO:tensorflow:examples/sec: 0.710201\n",
            "I0410 12:19:25.641209 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710201\n",
            "INFO:tensorflow:global_step/sec: 0.0221828\n",
            "I0410 12:20:10.719843 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221828\n",
            "INFO:tensorflow:examples/sec: 0.709851\n",
            "I0410 12:20:10.720453 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709851\n",
            "INFO:tensorflow:global_step/sec: 0.0219562\n",
            "I0410 12:20:56.265127 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219562\n",
            "INFO:tensorflow:examples/sec: 0.702597\n",
            "I0410 12:20:56.265575 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702597\n",
            "INFO:tensorflow:global_step/sec: 0.0221483\n",
            "I0410 12:21:41.415252 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221483\n",
            "INFO:tensorflow:examples/sec: 0.708747\n",
            "I0410 12:21:41.416402 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708747\n",
            "INFO:tensorflow:global_step/sec: 0.0220875\n",
            "I0410 12:22:26.689831 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220875\n",
            "INFO:tensorflow:examples/sec: 0.706799\n",
            "I0410 12:22:26.690293 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706799\n",
            "INFO:tensorflow:global_step/sec: 0.022197\n",
            "I0410 12:23:11.740924 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022197\n",
            "INFO:tensorflow:examples/sec: 0.710305\n",
            "I0410 12:23:11.741539 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710305\n",
            "INFO:tensorflow:Saving checkpoints for 620 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 12:23:57.222248 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 620 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0190921\n",
            "I0410 12:24:04.118468 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0190921\n",
            "INFO:tensorflow:examples/sec: 0.610948\n",
            "I0410 12:24:04.119000 140202582333312 tpu_estimator.py:2160] examples/sec: 0.610948\n",
            "INFO:tensorflow:global_step/sec: 0.0215014\n",
            "I0410 12:24:50.627105 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215014\n",
            "INFO:tensorflow:examples/sec: 0.688044\n",
            "I0410 12:24:50.627579 140202582333312 tpu_estimator.py:2160] examples/sec: 0.688044\n",
            "INFO:tensorflow:global_step/sec: 0.0220018\n",
            "I0410 12:25:36.077995 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220018\n",
            "INFO:tensorflow:examples/sec: 0.704057\n",
            "I0410 12:25:36.078493 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704057\n",
            "INFO:tensorflow:global_step/sec: 0.0221403\n",
            "I0410 12:26:21.244638 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221403\n",
            "INFO:tensorflow:examples/sec: 0.708491\n",
            "I0410 12:26:21.246104 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708491\n",
            "INFO:tensorflow:global_step/sec: 0.0219665\n",
            "I0410 12:27:06.768459 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219665\n",
            "INFO:tensorflow:examples/sec: 0.702928\n",
            "I0410 12:27:06.768885 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702928\n",
            "INFO:tensorflow:global_step/sec: 0.0220908\n",
            "I0410 12:27:52.036036 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220908\n",
            "INFO:tensorflow:examples/sec: 0.706905\n",
            "I0410 12:27:52.036486 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706905\n",
            "INFO:tensorflow:global_step/sec: 0.02179\n",
            "I0410 12:28:37.928594 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.02179\n",
            "INFO:tensorflow:examples/sec: 0.697281\n",
            "I0410 12:28:37.929758 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697281\n",
            "INFO:tensorflow:global_step/sec: 0.0219114\n",
            "I0410 12:29:23.567150 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219114\n",
            "INFO:tensorflow:examples/sec: 0.701165\n",
            "I0410 12:29:23.567592 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701165\n",
            "INFO:tensorflow:global_step/sec: 0.0221038\n",
            "I0410 12:30:08.808086 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221038\n",
            "INFO:tensorflow:examples/sec: 0.707322\n",
            "I0410 12:30:08.808548 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707322\n",
            "INFO:tensorflow:global_step/sec: 0.022045\n",
            "I0410 12:30:54.169795 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022045\n",
            "INFO:tensorflow:examples/sec: 0.70544\n",
            "I0410 12:30:54.171224 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70544\n",
            "INFO:tensorflow:global_step/sec: 0.0220805\n",
            "I0410 12:31:39.458556 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220805\n",
            "INFO:tensorflow:examples/sec: 0.706577\n",
            "I0410 12:31:39.458982 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706577\n",
            "INFO:tensorflow:global_step/sec: 0.0221451\n",
            "I0410 12:32:24.615382 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221451\n",
            "INFO:tensorflow:examples/sec: 0.708644\n",
            "I0410 12:32:24.615828 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708644\n",
            "INFO:tensorflow:global_step/sec: 0.0218887\n",
            "I0410 12:33:10.300941 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218887\n",
            "INFO:tensorflow:examples/sec: 0.700437\n",
            "I0410 12:33:10.302113 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700437\n",
            "INFO:tensorflow:global_step/sec: 0.0220235\n",
            "I0410 12:33:55.706961 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220235\n",
            "INFO:tensorflow:examples/sec: 0.704753\n",
            "I0410 12:33:55.707294 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704753\n",
            "INFO:tensorflow:global_step/sec: 0.0219376\n",
            "I0410 12:34:41.290920 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219376\n",
            "INFO:tensorflow:examples/sec: 0.702002\n",
            "I0410 12:34:41.291401 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702002\n",
            "INFO:tensorflow:global_step/sec: 0.0219405\n",
            "I0410 12:35:26.868729 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219405\n",
            "INFO:tensorflow:examples/sec: 0.702095\n",
            "I0410 12:35:26.869014 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702095\n",
            "INFO:tensorflow:global_step/sec: 0.0217451\n",
            "I0410 12:36:12.856033 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217451\n",
            "INFO:tensorflow:examples/sec: 0.695844\n",
            "I0410 12:36:12.856522 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695844\n",
            "INFO:tensorflow:global_step/sec: 0.0221398\n",
            "I0410 12:36:58.023627 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221398\n",
            "INFO:tensorflow:examples/sec: 0.708473\n",
            "I0410 12:36:58.024268 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708473\n",
            "INFO:tensorflow:global_step/sec: 0.0221453\n",
            "I0410 12:37:43.179975 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221453\n",
            "INFO:tensorflow:examples/sec: 0.708649\n",
            "I0410 12:37:43.180305 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708649\n",
            "INFO:tensorflow:global_step/sec: 0.0222247\n",
            "I0410 12:38:28.174974 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222247\n",
            "INFO:tensorflow:examples/sec: 0.71119\n",
            "I0410 12:38:28.175416 140202582333312 tpu_estimator.py:2160] examples/sec: 0.71119\n",
            "INFO:tensorflow:Saving checkpoints for 640 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 12:39:13.370941 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 640 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0192061\n",
            "I0410 12:39:20.241673 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0192061\n",
            "INFO:tensorflow:examples/sec: 0.614596\n",
            "I0410 12:39:20.242055 140202582333312 tpu_estimator.py:2160] examples/sec: 0.614596\n",
            "INFO:tensorflow:global_step/sec: 0.0215305\n",
            "I0410 12:40:06.687440 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215305\n",
            "INFO:tensorflow:examples/sec: 0.688977\n",
            "I0410 12:40:06.689033 140202582333312 tpu_estimator.py:2160] examples/sec: 0.688977\n",
            "INFO:tensorflow:global_step/sec: 0.0216397\n",
            "I0410 12:40:52.898794 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216397\n",
            "INFO:tensorflow:examples/sec: 0.692469\n",
            "I0410 12:40:52.899269 140202582333312 tpu_estimator.py:2160] examples/sec: 0.692469\n",
            "INFO:tensorflow:global_step/sec: 0.0222245\n",
            "I0410 12:41:37.894194 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222245\n",
            "INFO:tensorflow:examples/sec: 0.711185\n",
            "I0410 12:41:37.894622 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711185\n",
            "INFO:tensorflow:global_step/sec: 0.0218491\n",
            "I0410 12:42:23.662666 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218491\n",
            "INFO:tensorflow:examples/sec: 0.699171\n",
            "I0410 12:42:23.664172 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699171\n",
            "INFO:tensorflow:global_step/sec: 0.0220805\n",
            "I0410 12:43:08.951546 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220805\n",
            "INFO:tensorflow:examples/sec: 0.706575\n",
            "I0410 12:43:08.951965 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706575\n",
            "INFO:tensorflow:global_step/sec: 0.0221435\n",
            "I0410 12:43:54.111616 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221435\n",
            "INFO:tensorflow:examples/sec: 0.708591\n",
            "I0410 12:43:54.112034 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708591\n",
            "INFO:tensorflow:global_step/sec: 0.0220568\n",
            "I0410 12:44:39.448981 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220568\n",
            "INFO:tensorflow:examples/sec: 0.705819\n",
            "I0410 12:44:39.450428 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705819\n",
            "INFO:tensorflow:global_step/sec: 0.021982\n",
            "I0410 12:45:24.940825 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021982\n",
            "INFO:tensorflow:examples/sec: 0.703424\n",
            "I0410 12:45:24.941275 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703424\n",
            "INFO:tensorflow:global_step/sec: 0.0220172\n",
            "I0410 12:46:10.359797 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220172\n",
            "INFO:tensorflow:examples/sec: 0.704551\n",
            "I0410 12:46:10.360262 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704551\n",
            "INFO:tensorflow:global_step/sec: 0.0218999\n",
            "I0410 12:46:56.022324 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218999\n",
            "INFO:tensorflow:examples/sec: 0.700796\n",
            "I0410 12:46:56.023598 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700796\n",
            "INFO:tensorflow:global_step/sec: 0.0218914\n",
            "I0410 12:47:41.702115 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218914\n",
            "INFO:tensorflow:examples/sec: 0.700526\n",
            "I0410 12:47:41.702598 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700526\n",
            "INFO:tensorflow:global_step/sec: 0.0218929\n",
            "I0410 12:48:27.379003 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218929\n",
            "INFO:tensorflow:examples/sec: 0.700573\n",
            "I0410 12:48:27.379438 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700573\n",
            "INFO:tensorflow:global_step/sec: 0.0221016\n",
            "I0410 12:49:12.624561 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221016\n",
            "INFO:tensorflow:examples/sec: 0.707252\n",
            "I0410 12:49:12.625962 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707252\n",
            "INFO:tensorflow:global_step/sec: 0.0218568\n",
            "I0410 12:49:58.376881 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218568\n",
            "INFO:tensorflow:examples/sec: 0.699418\n",
            "I0410 12:49:58.377363 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699418\n",
            "INFO:tensorflow:global_step/sec: 0.0220551\n",
            "I0410 12:50:43.717827 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220551\n",
            "INFO:tensorflow:examples/sec: 0.705764\n",
            "I0410 12:50:43.718286 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705764\n",
            "INFO:tensorflow:global_step/sec: 0.0220039\n",
            "I0410 12:51:29.164313 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220039\n",
            "INFO:tensorflow:examples/sec: 0.704125\n",
            "I0410 12:51:29.165723 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704125\n",
            "INFO:tensorflow:global_step/sec: 0.0220362\n",
            "I0410 12:52:14.544339 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220362\n",
            "INFO:tensorflow:examples/sec: 0.705158\n",
            "I0410 12:52:14.544916 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705158\n",
            "INFO:tensorflow:global_step/sec: 0.0221215\n",
            "I0410 12:52:59.749179 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221215\n",
            "INFO:tensorflow:examples/sec: 0.707887\n",
            "I0410 12:52:59.749682 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707887\n",
            "INFO:tensorflow:global_step/sec: 0.0219122\n",
            "I0410 12:53:45.385759 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219122\n",
            "INFO:tensorflow:examples/sec: 0.701192\n",
            "I0410 12:53:45.386042 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701192\n",
            "INFO:tensorflow:Saving checkpoints for 660 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 12:54:30.971202 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 660 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0190933\n",
            "I0410 12:54:37.760113 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0190933\n",
            "INFO:tensorflow:examples/sec: 0.610986\n",
            "I0410 12:54:37.760468 140202582333312 tpu_estimator.py:2160] examples/sec: 0.610986\n",
            "INFO:tensorflow:global_step/sec: 0.0216381\n",
            "I0410 12:55:23.974976 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216381\n",
            "INFO:tensorflow:examples/sec: 0.69242\n",
            "I0410 12:55:23.975337 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69242\n",
            "INFO:tensorflow:global_step/sec: 0.0218277\n",
            "I0410 12:56:09.788503 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218277\n",
            "INFO:tensorflow:examples/sec: 0.698485\n",
            "I0410 12:56:09.789979 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698485\n",
            "INFO:tensorflow:global_step/sec: 0.022114\n",
            "I0410 12:56:55.008572 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022114\n",
            "INFO:tensorflow:examples/sec: 0.707649\n",
            "I0410 12:56:55.008909 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707649\n",
            "INFO:tensorflow:global_step/sec: 0.0221335\n",
            "I0410 12:57:40.188816 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221335\n",
            "INFO:tensorflow:examples/sec: 0.708272\n",
            "I0410 12:57:40.189164 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708272\n",
            "INFO:tensorflow:global_step/sec: 0.0220454\n",
            "I0410 12:58:25.549724 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220454\n",
            "INFO:tensorflow:examples/sec: 0.705453\n",
            "I0410 12:58:25.550746 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705453\n",
            "INFO:tensorflow:global_step/sec: 0.0221265\n",
            "I0410 12:59:10.744446 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221265\n",
            "INFO:tensorflow:examples/sec: 0.708047\n",
            "I0410 12:59:10.744775 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708047\n",
            "INFO:tensorflow:global_step/sec: 0.0219298\n",
            "I0410 12:59:56.344496 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219298\n",
            "INFO:tensorflow:examples/sec: 0.701754\n",
            "I0410 12:59:56.344860 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701754\n",
            "INFO:tensorflow:global_step/sec: 0.0219172\n",
            "I0410 13:00:41.970741 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219172\n",
            "INFO:tensorflow:examples/sec: 0.701351\n",
            "I0410 13:00:41.972169 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701351\n",
            "INFO:tensorflow:global_step/sec: 0.021995\n",
            "I0410 13:01:27.435592 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021995\n",
            "INFO:tensorflow:examples/sec: 0.703841\n",
            "I0410 13:01:27.436079 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703841\n",
            "INFO:tensorflow:global_step/sec: 0.0218353\n",
            "I0410 13:02:13.233107 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218353\n",
            "INFO:tensorflow:examples/sec: 0.69873\n",
            "I0410 13:02:13.233578 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69873\n",
            "INFO:tensorflow:global_step/sec: 0.0218684\n",
            "I0410 13:02:58.961017 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218684\n",
            "INFO:tensorflow:examples/sec: 0.69979\n",
            "I0410 13:02:58.962205 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69979\n",
            "INFO:tensorflow:global_step/sec: 0.0220333\n",
            "I0410 13:03:44.346817 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220333\n",
            "INFO:tensorflow:examples/sec: 0.705067\n",
            "I0410 13:03:44.347282 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705067\n",
            "INFO:tensorflow:global_step/sec: 0.0220083\n",
            "I0410 13:04:29.784019 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220083\n",
            "INFO:tensorflow:examples/sec: 0.704267\n",
            "I0410 13:04:29.784438 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704267\n",
            "INFO:tensorflow:global_step/sec: 0.0218887\n",
            "I0410 13:05:15.469794 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218887\n",
            "INFO:tensorflow:examples/sec: 0.700437\n",
            "I0410 13:05:15.471233 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700437\n",
            "INFO:tensorflow:global_step/sec: 0.0221873\n",
            "I0410 13:06:00.540511 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221873\n",
            "INFO:tensorflow:examples/sec: 0.709995\n",
            "I0410 13:06:00.540811 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709995\n",
            "INFO:tensorflow:global_step/sec: 0.0219736\n",
            "I0410 13:06:46.049611 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219736\n",
            "INFO:tensorflow:examples/sec: 0.703156\n",
            "I0410 13:06:46.050017 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703156\n",
            "INFO:tensorflow:global_step/sec: 0.0221906\n",
            "I0410 13:07:31.113663 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221906\n",
            "INFO:tensorflow:examples/sec: 0.7101\n",
            "I0410 13:07:31.114745 140202582333312 tpu_estimator.py:2160] examples/sec: 0.7101\n",
            "INFO:tensorflow:global_step/sec: 0.0219002\n",
            "I0410 13:08:16.775457 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219002\n",
            "INFO:tensorflow:examples/sec: 0.700805\n",
            "I0410 13:08:16.775749 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700805\n",
            "INFO:tensorflow:global_step/sec: 0.0221316\n",
            "I0410 13:09:01.959792 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221316\n",
            "INFO:tensorflow:examples/sec: 0.70821\n",
            "I0410 13:09:01.960064 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70821\n",
            "INFO:tensorflow:Saving checkpoints for 680 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 13:09:48.051423 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 680 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.018576\n",
            "I0410 13:09:55.792717 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.018576\n",
            "INFO:tensorflow:examples/sec: 0.594432\n",
            "I0410 13:09:55.793099 140202582333312 tpu_estimator.py:2160] examples/sec: 0.594432\n",
            "INFO:tensorflow:global_step/sec: 0.0215879\n",
            "I0410 13:10:42.114909 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215879\n",
            "INFO:tensorflow:examples/sec: 0.690814\n",
            "I0410 13:10:42.115217 140202582333312 tpu_estimator.py:2160] examples/sec: 0.690814\n",
            "INFO:tensorflow:global_step/sec: 0.0218769\n",
            "I0410 13:11:27.825333 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218769\n",
            "INFO:tensorflow:examples/sec: 0.70006\n",
            "I0410 13:11:27.825797 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70006\n",
            "INFO:tensorflow:global_step/sec: 0.0220941\n",
            "I0410 13:12:13.086204 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220941\n",
            "INFO:tensorflow:examples/sec: 0.707012\n",
            "I0410 13:12:13.087321 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707012\n",
            "INFO:tensorflow:global_step/sec: 0.0218562\n",
            "I0410 13:12:58.839746 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218562\n",
            "INFO:tensorflow:examples/sec: 0.699399\n",
            "I0410 13:12:58.840312 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699399\n",
            "INFO:tensorflow:global_step/sec: 0.0218026\n",
            "I0410 13:13:44.705760 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218026\n",
            "INFO:tensorflow:examples/sec: 0.697684\n",
            "I0410 13:13:44.706205 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697684\n",
            "INFO:tensorflow:global_step/sec: 0.0221604\n",
            "I0410 13:14:29.831273 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221604\n",
            "INFO:tensorflow:examples/sec: 0.709134\n",
            "I0410 13:14:29.832726 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709134\n",
            "INFO:tensorflow:global_step/sec: 0.0219521\n",
            "I0410 13:15:15.385074 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219521\n",
            "INFO:tensorflow:examples/sec: 0.702466\n",
            "I0410 13:15:15.385570 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702466\n",
            "INFO:tensorflow:global_step/sec: 0.0219522\n",
            "I0410 13:16:00.938469 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219522\n",
            "INFO:tensorflow:examples/sec: 0.702472\n",
            "I0410 13:16:00.938810 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702472\n",
            "INFO:tensorflow:global_step/sec: 0.0219861\n",
            "I0410 13:16:46.421684 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219861\n",
            "INFO:tensorflow:examples/sec: 0.703556\n",
            "I0410 13:16:46.423257 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703556\n",
            "INFO:tensorflow:global_step/sec: 0.0221101\n",
            "I0410 13:17:31.649963 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221101\n",
            "INFO:tensorflow:examples/sec: 0.707522\n",
            "I0410 13:17:31.650405 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707522\n",
            "INFO:tensorflow:global_step/sec: 0.0220781\n",
            "I0410 13:18:16.943753 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220781\n",
            "INFO:tensorflow:examples/sec: 0.706499\n",
            "I0410 13:18:16.944188 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706499\n",
            "INFO:tensorflow:global_step/sec: 0.0221542\n",
            "I0410 13:19:02.081835 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221542\n",
            "INFO:tensorflow:examples/sec: 0.708936\n",
            "I0410 13:19:02.083106 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708936\n",
            "INFO:tensorflow:global_step/sec: 0.022012\n",
            "I0410 13:19:47.511499 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022012\n",
            "INFO:tensorflow:examples/sec: 0.704385\n",
            "I0410 13:19:47.511968 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704385\n",
            "INFO:tensorflow:global_step/sec: 0.0219055\n",
            "I0410 13:20:33.162220 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219055\n",
            "INFO:tensorflow:examples/sec: 0.700975\n",
            "I0410 13:20:33.162501 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700975\n",
            "INFO:tensorflow:global_step/sec: 0.0218932\n",
            "I0410 13:21:18.838480 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218932\n",
            "INFO:tensorflow:examples/sec: 0.700582\n",
            "I0410 13:21:18.838752 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700582\n",
            "INFO:tensorflow:global_step/sec: 0.0219201\n",
            "I0410 13:22:04.458822 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219201\n",
            "INFO:tensorflow:examples/sec: 0.701443\n",
            "I0410 13:22:04.459268 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701443\n",
            "INFO:tensorflow:global_step/sec: 0.0217404\n",
            "I0410 13:22:50.456279 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217404\n",
            "INFO:tensorflow:examples/sec: 0.695694\n",
            "I0410 13:22:50.456747 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695694\n",
            "INFO:tensorflow:global_step/sec: 0.022115\n",
            "I0410 13:23:35.674334 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022115\n",
            "INFO:tensorflow:examples/sec: 0.707681\n",
            "I0410 13:23:35.675426 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707681\n",
            "INFO:tensorflow:global_step/sec: 0.0219763\n",
            "I0410 13:24:21.177779 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219763\n",
            "INFO:tensorflow:examples/sec: 0.703241\n",
            "I0410 13:24:21.178058 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703241\n",
            "INFO:tensorflow:Saving checkpoints for 700 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 13:25:06.289864 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 700 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0189348\n",
            "I0410 13:25:13.990700 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0189348\n",
            "INFO:tensorflow:examples/sec: 0.605913\n",
            "I0410 13:25:13.991016 140202582333312 tpu_estimator.py:2160] examples/sec: 0.605913\n",
            "INFO:tensorflow:global_step/sec: 0.0216712\n",
            "I0410 13:26:00.134778 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216712\n",
            "INFO:tensorflow:examples/sec: 0.69348\n",
            "I0410 13:26:00.136229 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69348\n",
            "INFO:tensorflow:global_step/sec: 0.0220234\n",
            "I0410 13:26:45.540956 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220234\n",
            "INFO:tensorflow:examples/sec: 0.704749\n",
            "I0410 13:26:45.541400 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704749\n",
            "INFO:tensorflow:global_step/sec: 0.0217169\n",
            "I0410 13:27:31.588097 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217169\n",
            "INFO:tensorflow:examples/sec: 0.694941\n",
            "I0410 13:27:31.588593 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694941\n",
            "INFO:tensorflow:global_step/sec: 0.022264\n",
            "I0410 13:28:16.503579 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022264\n",
            "INFO:tensorflow:examples/sec: 0.712449\n",
            "I0410 13:28:16.504736 140202582333312 tpu_estimator.py:2160] examples/sec: 0.712449\n",
            "INFO:tensorflow:global_step/sec: 0.0221355\n",
            "I0410 13:29:01.679899 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221355\n",
            "INFO:tensorflow:examples/sec: 0.708336\n",
            "I0410 13:29:01.680330 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708336\n",
            "INFO:tensorflow:global_step/sec: 0.0217971\n",
            "I0410 13:29:47.557605 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217971\n",
            "INFO:tensorflow:examples/sec: 0.697506\n",
            "I0410 13:29:47.558038 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697506\n",
            "INFO:tensorflow:global_step/sec: 0.0220106\n",
            "I0410 13:30:32.990379 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220106\n",
            "INFO:tensorflow:examples/sec: 0.704338\n",
            "I0410 13:30:32.991698 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704338\n",
            "INFO:tensorflow:global_step/sec: 0.0220435\n",
            "I0410 13:31:18.355162 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220435\n",
            "INFO:tensorflow:examples/sec: 0.705392\n",
            "I0410 13:31:18.355577 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705392\n",
            "INFO:tensorflow:global_step/sec: 0.0220166\n",
            "I0410 13:32:03.775597 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220166\n",
            "INFO:tensorflow:examples/sec: 0.704531\n",
            "I0410 13:32:03.776042 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704531\n",
            "INFO:tensorflow:global_step/sec: 0.0221857\n",
            "I0410 13:32:48.849590 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221857\n",
            "INFO:tensorflow:examples/sec: 0.709942\n",
            "I0410 13:32:48.850768 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709942\n",
            "INFO:tensorflow:global_step/sec: 0.0221632\n",
            "I0410 13:33:33.969402 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221632\n",
            "INFO:tensorflow:examples/sec: 0.709223\n",
            "I0410 13:33:33.969878 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709223\n",
            "INFO:tensorflow:global_step/sec: 0.0219449\n",
            "I0410 13:34:19.538036 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219449\n",
            "INFO:tensorflow:examples/sec: 0.702238\n",
            "I0410 13:34:19.538430 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702238\n",
            "INFO:tensorflow:global_step/sec: 0.0220002\n",
            "I0410 13:35:04.992181 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220002\n",
            "INFO:tensorflow:examples/sec: 0.704005\n",
            "I0410 13:35:04.994071 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704005\n",
            "INFO:tensorflow:global_step/sec: 0.0220784\n",
            "I0410 13:35:50.285444 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220784\n",
            "INFO:tensorflow:examples/sec: 0.706507\n",
            "I0410 13:35:50.285878 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706507\n",
            "INFO:tensorflow:global_step/sec: 0.0221074\n",
            "I0410 13:36:35.519213 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221074\n",
            "INFO:tensorflow:examples/sec: 0.707436\n",
            "I0410 13:36:35.519634 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707436\n",
            "INFO:tensorflow:global_step/sec: 0.0221419\n",
            "I0410 13:37:20.682467 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221419\n",
            "INFO:tensorflow:examples/sec: 0.70854\n",
            "I0410 13:37:20.683591 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70854\n",
            "INFO:tensorflow:global_step/sec: 0.0222252\n",
            "I0410 13:38:05.676495 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222252\n",
            "INFO:tensorflow:examples/sec: 0.711206\n",
            "I0410 13:38:05.676936 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711206\n",
            "INFO:tensorflow:global_step/sec: 0.0220176\n",
            "I0410 13:38:51.094692 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220176\n",
            "INFO:tensorflow:examples/sec: 0.704563\n",
            "I0410 13:38:51.095103 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704563\n",
            "INFO:tensorflow:global_step/sec: 0.0219012\n",
            "I0410 13:39:36.754344 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219012\n",
            "INFO:tensorflow:examples/sec: 0.700838\n",
            "I0410 13:39:36.755871 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700838\n",
            "INFO:tensorflow:Saving checkpoints for 720 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 13:40:22.364828 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 720 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0188594\n",
            "I0410 13:40:29.778254 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0188594\n",
            "INFO:tensorflow:examples/sec: 0.603501\n",
            "I0410 13:40:29.778529 140202582333312 tpu_estimator.py:2160] examples/sec: 0.603501\n",
            "INFO:tensorflow:global_step/sec: 0.0212651\n",
            "I0410 13:41:16.803600 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0212651\n",
            "INFO:tensorflow:examples/sec: 0.680484\n",
            "I0410 13:41:16.803878 140202582333312 tpu_estimator.py:2160] examples/sec: 0.680484\n",
            "INFO:tensorflow:global_step/sec: 0.0218829\n",
            "I0410 13:42:02.501407 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218829\n",
            "INFO:tensorflow:examples/sec: 0.700253\n",
            "I0410 13:42:02.502881 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700253\n",
            "INFO:tensorflow:global_step/sec: 0.0219125\n",
            "I0410 13:42:48.137342 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219125\n",
            "INFO:tensorflow:examples/sec: 0.701201\n",
            "I0410 13:42:48.137754 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701201\n",
            "INFO:tensorflow:global_step/sec: 0.0221169\n",
            "I0410 13:43:33.351644 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221169\n",
            "INFO:tensorflow:examples/sec: 0.707741\n",
            "I0410 13:43:33.352143 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707741\n",
            "INFO:tensorflow:global_step/sec: 0.0220367\n",
            "I0410 13:44:18.730594 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220367\n",
            "INFO:tensorflow:examples/sec: 0.705173\n",
            "I0410 13:44:18.731898 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705173\n",
            "INFO:tensorflow:global_step/sec: 0.0221331\n",
            "I0410 13:45:03.911889 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221331\n",
            "INFO:tensorflow:examples/sec: 0.708258\n",
            "I0410 13:45:03.912330 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708258\n",
            "INFO:tensorflow:global_step/sec: 0.0219825\n",
            "I0410 13:45:49.402697 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219825\n",
            "INFO:tensorflow:examples/sec: 0.703439\n",
            "I0410 13:45:49.403080 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703439\n",
            "INFO:tensorflow:global_step/sec: 0.0220673\n",
            "I0410 13:46:34.718619 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220673\n",
            "INFO:tensorflow:examples/sec: 0.706153\n",
            "I0410 13:46:34.719732 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706153\n",
            "INFO:tensorflow:global_step/sec: 0.0220233\n",
            "I0410 13:47:20.125184 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220233\n",
            "INFO:tensorflow:examples/sec: 0.704745\n",
            "I0410 13:47:20.125461 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704745\n",
            "INFO:tensorflow:global_step/sec: 0.022047\n",
            "I0410 13:48:05.482953 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022047\n",
            "INFO:tensorflow:examples/sec: 0.705502\n",
            "I0410 13:48:05.483421 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705502\n",
            "INFO:tensorflow:global_step/sec: 0.0221695\n",
            "I0410 13:48:50.589928 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221695\n",
            "INFO:tensorflow:examples/sec: 0.709424\n",
            "I0410 13:48:50.590276 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709424\n",
            "INFO:tensorflow:global_step/sec: 0.0217233\n",
            "I0410 13:49:36.623380 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217233\n",
            "INFO:tensorflow:examples/sec: 0.695147\n",
            "I0410 13:49:36.623816 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695147\n",
            "INFO:tensorflow:global_step/sec: 0.0222057\n",
            "I0410 13:50:21.656853 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222057\n",
            "INFO:tensorflow:examples/sec: 0.710582\n",
            "I0410 13:50:21.657293 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710582\n",
            "INFO:tensorflow:global_step/sec: 0.0219891\n",
            "I0410 13:51:07.133869 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219891\n",
            "INFO:tensorflow:examples/sec: 0.703652\n",
            "I0410 13:51:07.135002 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703652\n",
            "INFO:tensorflow:global_step/sec: 0.0217372\n",
            "I0410 13:51:53.138012 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217372\n",
            "INFO:tensorflow:examples/sec: 0.69559\n",
            "I0410 13:51:53.138508 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69559\n",
            "INFO:tensorflow:global_step/sec: 0.0218284\n",
            "I0410 13:52:38.950083 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218284\n",
            "INFO:tensorflow:examples/sec: 0.698508\n",
            "I0410 13:52:38.950613 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698508\n",
            "INFO:tensorflow:global_step/sec: 0.0219019\n",
            "I0410 13:53:24.608350 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219019\n",
            "INFO:tensorflow:examples/sec: 0.700859\n",
            "I0410 13:53:24.609538 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700859\n",
            "INFO:tensorflow:global_step/sec: 0.0220716\n",
            "I0410 13:54:09.915170 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220716\n",
            "INFO:tensorflow:examples/sec: 0.706292\n",
            "I0410 13:54:09.915603 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706292\n",
            "INFO:tensorflow:global_step/sec: 0.0220133\n",
            "I0410 13:54:55.342211 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220133\n",
            "INFO:tensorflow:examples/sec: 0.704425\n",
            "I0410 13:54:55.342476 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704425\n",
            "INFO:tensorflow:Saving checkpoints for 740 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 13:55:41.205265 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 740 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0188183\n",
            "I0410 13:55:48.482013 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0188183\n",
            "INFO:tensorflow:examples/sec: 0.602185\n",
            "I0410 13:55:48.482400 140202582333312 tpu_estimator.py:2160] examples/sec: 0.602185\n",
            "INFO:tensorflow:global_step/sec: 0.0213356\n",
            "I0410 13:56:35.352096 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0213356\n",
            "INFO:tensorflow:examples/sec: 0.682739\n",
            "I0410 13:56:35.352498 140202582333312 tpu_estimator.py:2160] examples/sec: 0.682739\n",
            "INFO:tensorflow:global_step/sec: 0.0218798\n",
            "I0410 13:57:21.056292 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218798\n",
            "INFO:tensorflow:examples/sec: 0.700154\n",
            "I0410 13:57:21.056632 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700154\n",
            "INFO:tensorflow:global_step/sec: 0.0221455\n",
            "I0410 13:58:06.212214 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221455\n",
            "INFO:tensorflow:examples/sec: 0.708656\n",
            "I0410 13:58:06.212491 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708656\n",
            "INFO:tensorflow:global_step/sec: 0.0221302\n",
            "I0410 13:58:51.399365 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221302\n",
            "INFO:tensorflow:examples/sec: 0.708168\n",
            "I0410 13:58:51.399704 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708168\n",
            "INFO:tensorflow:global_step/sec: 0.0221447\n",
            "I0410 13:59:36.556780 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221447\n",
            "INFO:tensorflow:examples/sec: 0.70863\n",
            "I0410 13:59:36.557121 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70863\n",
            "INFO:tensorflow:global_step/sec: 0.0221418\n",
            "I0410 14:00:21.720319 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221418\n",
            "INFO:tensorflow:examples/sec: 0.708538\n",
            "I0410 14:00:21.721717 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708538\n",
            "INFO:tensorflow:global_step/sec: 0.02205\n",
            "I0410 14:01:07.071718 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.02205\n",
            "INFO:tensorflow:examples/sec: 0.7056\n",
            "I0410 14:01:07.072053 140202582333312 tpu_estimator.py:2160] examples/sec: 0.7056\n",
            "INFO:tensorflow:global_step/sec: 0.0216886\n",
            "I0410 14:01:53.178774 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216886\n",
            "INFO:tensorflow:examples/sec: 0.694037\n",
            "I0410 14:01:53.179326 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694037\n",
            "INFO:tensorflow:global_step/sec: 0.0217901\n",
            "I0410 14:02:39.071202 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217901\n",
            "INFO:tensorflow:examples/sec: 0.697284\n",
            "I0410 14:02:39.071482 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697284\n",
            "INFO:tensorflow:global_step/sec: 0.0217858\n",
            "I0410 14:03:24.972538 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217858\n",
            "INFO:tensorflow:examples/sec: 0.697147\n",
            "I0410 14:03:24.972949 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697147\n",
            "INFO:tensorflow:global_step/sec: 0.0220336\n",
            "I0410 14:04:10.357815 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220336\n",
            "INFO:tensorflow:examples/sec: 0.705076\n",
            "I0410 14:04:10.358273 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705076\n",
            "INFO:tensorflow:global_step/sec: 0.0219459\n",
            "I0410 14:04:55.924284 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219459\n",
            "INFO:tensorflow:examples/sec: 0.70227\n",
            "I0410 14:04:55.924555 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70227\n",
            "INFO:tensorflow:global_step/sec: 0.0221239\n",
            "I0410 14:05:41.124166 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221239\n",
            "INFO:tensorflow:examples/sec: 0.707966\n",
            "I0410 14:05:41.124591 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707966\n",
            "INFO:tensorflow:global_step/sec: 0.0219812\n",
            "I0410 14:06:26.617582 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219812\n",
            "INFO:tensorflow:examples/sec: 0.703399\n",
            "I0410 14:06:26.617998 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703399\n",
            "INFO:tensorflow:global_step/sec: 0.0220496\n",
            "I0410 14:07:11.969826 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220496\n",
            "INFO:tensorflow:examples/sec: 0.705588\n",
            "I0410 14:07:11.970149 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705588\n",
            "INFO:tensorflow:global_step/sec: 0.0221741\n",
            "I0410 14:07:57.067421 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221741\n",
            "INFO:tensorflow:examples/sec: 0.709572\n",
            "I0410 14:07:57.067897 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709572\n",
            "INFO:tensorflow:global_step/sec: 0.0221395\n",
            "I0410 14:08:42.235553 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221395\n",
            "INFO:tensorflow:examples/sec: 0.708464\n",
            "I0410 14:08:42.236070 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708464\n",
            "INFO:tensorflow:global_step/sec: 0.0219353\n",
            "I0410 14:09:27.824198 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219353\n",
            "INFO:tensorflow:examples/sec: 0.701931\n",
            "I0410 14:09:27.825373 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701931\n",
            "INFO:tensorflow:global_step/sec: 0.0220231\n",
            "I0410 14:10:13.231051 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220231\n",
            "INFO:tensorflow:examples/sec: 0.704738\n",
            "I0410 14:10:13.231535 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704738\n",
            "INFO:tensorflow:Saving checkpoints for 760 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 14:10:58.484404 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 760 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0191526\n",
            "I0410 14:11:05.443127 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0191526\n",
            "INFO:tensorflow:examples/sec: 0.612884\n",
            "I0410 14:11:05.443486 140202582333312 tpu_estimator.py:2160] examples/sec: 0.612884\n",
            "INFO:tensorflow:global_step/sec: 0.0213213\n",
            "I0410 14:11:52.344760 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0213213\n",
            "INFO:tensorflow:examples/sec: 0.682281\n",
            "I0410 14:11:52.368309 140202582333312 tpu_estimator.py:2160] examples/sec: 0.682281\n",
            "INFO:tensorflow:global_step/sec: 0.0220723\n",
            "I0410 14:12:37.650319 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220723\n",
            "INFO:tensorflow:examples/sec: 0.706315\n",
            "I0410 14:12:37.650740 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706315\n",
            "INFO:tensorflow:global_step/sec: 0.0219596\n",
            "I0410 14:13:23.188486 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219596\n",
            "INFO:tensorflow:examples/sec: 0.702707\n",
            "I0410 14:13:23.188759 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702707\n",
            "INFO:tensorflow:global_step/sec: 0.02188\n",
            "I0410 14:14:08.892276 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.02188\n",
            "INFO:tensorflow:examples/sec: 0.700161\n",
            "I0410 14:14:08.893450 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700161\n",
            "INFO:tensorflow:global_step/sec: 0.0220052\n",
            "I0410 14:14:54.336055 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220052\n",
            "INFO:tensorflow:examples/sec: 0.704167\n",
            "I0410 14:14:54.336495 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704167\n",
            "INFO:tensorflow:global_step/sec: 0.0221051\n",
            "I0410 14:15:39.574429 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221051\n",
            "INFO:tensorflow:examples/sec: 0.707364\n",
            "I0410 14:15:39.574867 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707364\n",
            "INFO:tensorflow:global_step/sec: 0.0219282\n",
            "I0410 14:16:25.177863 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219282\n",
            "INFO:tensorflow:examples/sec: 0.701701\n",
            "I0410 14:16:25.179010 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701701\n",
            "INFO:tensorflow:global_step/sec: 0.0221611\n",
            "I0410 14:17:10.301968 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221611\n",
            "INFO:tensorflow:examples/sec: 0.709156\n",
            "I0410 14:17:10.302305 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709156\n",
            "INFO:tensorflow:global_step/sec: 0.0220781\n",
            "I0410 14:17:55.595745 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220781\n",
            "INFO:tensorflow:examples/sec: 0.706499\n",
            "I0410 14:17:55.596031 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706499\n",
            "INFO:tensorflow:global_step/sec: 0.0219115\n",
            "I0410 14:18:41.233782 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219115\n",
            "INFO:tensorflow:examples/sec: 0.701169\n",
            "I0410 14:18:41.235007 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701169\n",
            "INFO:tensorflow:global_step/sec: 0.0220193\n",
            "I0410 14:19:26.648511 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220193\n",
            "INFO:tensorflow:examples/sec: 0.704617\n",
            "I0410 14:19:26.648935 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704617\n",
            "INFO:tensorflow:global_step/sec: 0.0218587\n",
            "I0410 14:20:12.396886 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218587\n",
            "INFO:tensorflow:examples/sec: 0.699479\n",
            "I0410 14:20:12.397340 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699479\n",
            "INFO:tensorflow:global_step/sec: 0.0219066\n",
            "I0410 14:20:58.045200 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219066\n",
            "INFO:tensorflow:examples/sec: 0.701012\n",
            "I0410 14:20:58.046466 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701012\n",
            "INFO:tensorflow:global_step/sec: 0.0217519\n",
            "I0410 14:21:44.018103 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217519\n",
            "INFO:tensorflow:examples/sec: 0.696062\n",
            "I0410 14:21:44.018431 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696062\n",
            "INFO:tensorflow:global_step/sec: 0.0220259\n",
            "I0410 14:22:29.419151 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220259\n",
            "INFO:tensorflow:examples/sec: 0.704829\n",
            "I0410 14:22:29.419683 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704829\n",
            "INFO:tensorflow:global_step/sec: 0.0220603\n",
            "I0410 14:23:14.749525 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220603\n",
            "INFO:tensorflow:examples/sec: 0.705929\n",
            "I0410 14:23:14.750891 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705929\n",
            "INFO:tensorflow:global_step/sec: 0.0221024\n",
            "I0410 14:23:59.993512 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221024\n",
            "INFO:tensorflow:examples/sec: 0.707276\n",
            "I0410 14:23:59.993942 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707276\n",
            "INFO:tensorflow:global_step/sec: 0.0220516\n",
            "I0410 14:24:45.341809 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220516\n",
            "INFO:tensorflow:examples/sec: 0.705652\n",
            "I0410 14:24:45.342267 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705652\n",
            "INFO:tensorflow:global_step/sec: 0.0222122\n",
            "I0410 14:25:30.362110 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222122\n",
            "INFO:tensorflow:examples/sec: 0.710791\n",
            "I0410 14:25:30.363694 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710791\n",
            "INFO:tensorflow:Saving checkpoints for 780 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 14:26:15.576063 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 780 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0189244\n",
            "I0410 14:26:23.203557 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0189244\n",
            "INFO:tensorflow:examples/sec: 0.605582\n",
            "I0410 14:26:23.203976 140202582333312 tpu_estimator.py:2160] examples/sec: 0.605582\n",
            "INFO:tensorflow:global_step/sec: 0.0215813\n",
            "I0410 14:27:09.540156 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215813\n",
            "INFO:tensorflow:examples/sec: 0.6906\n",
            "I0410 14:27:09.540450 140202582333312 tpu_estimator.py:2160] examples/sec: 0.6906\n",
            "INFO:tensorflow:global_step/sec: 0.0221033\n",
            "I0410 14:27:54.782205 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221033\n",
            "INFO:tensorflow:examples/sec: 0.707306\n",
            "I0410 14:27:54.782478 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707306\n",
            "INFO:tensorflow:global_step/sec: 0.0220995\n",
            "I0410 14:28:40.032157 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220995\n",
            "INFO:tensorflow:examples/sec: 0.707183\n",
            "I0410 14:28:40.032589 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707183\n",
            "INFO:tensorflow:global_step/sec: 0.0218175\n",
            "I0410 14:29:25.866907 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218175\n",
            "INFO:tensorflow:examples/sec: 0.69816\n",
            "I0410 14:29:25.867346 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69816\n",
            "INFO:tensorflow:global_step/sec: 0.0220981\n",
            "I0410 14:30:11.119681 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220981\n",
            "INFO:tensorflow:examples/sec: 0.707139\n",
            "I0410 14:30:11.120811 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707139\n",
            "INFO:tensorflow:global_step/sec: 0.0218829\n",
            "I0410 14:30:56.817618 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218829\n",
            "INFO:tensorflow:examples/sec: 0.700252\n",
            "I0410 14:30:56.818075 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700252\n",
            "INFO:tensorflow:global_step/sec: 0.0218941\n",
            "I0410 14:31:42.492002 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218941\n",
            "INFO:tensorflow:examples/sec: 0.70061\n",
            "I0410 14:31:42.492428 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70061\n",
            "INFO:tensorflow:global_step/sec: 0.0220479\n",
            "I0410 14:32:27.847889 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220479\n",
            "INFO:tensorflow:examples/sec: 0.705532\n",
            "I0410 14:32:27.849394 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705532\n",
            "INFO:tensorflow:global_step/sec: 0.0220321\n",
            "I0410 14:33:13.236257 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220321\n",
            "INFO:tensorflow:examples/sec: 0.705026\n",
            "I0410 14:33:13.236704 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705026\n",
            "INFO:tensorflow:global_step/sec: 0.0220664\n",
            "I0410 14:33:58.553974 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220664\n",
            "INFO:tensorflow:examples/sec: 0.706125\n",
            "I0410 14:33:58.554414 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706125\n",
            "INFO:tensorflow:global_step/sec: 0.0220702\n",
            "I0410 14:34:43.864034 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220702\n",
            "INFO:tensorflow:examples/sec: 0.706245\n",
            "I0410 14:34:43.865946 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706245\n",
            "INFO:tensorflow:global_step/sec: 0.0220151\n",
            "I0410 14:35:29.287446 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220151\n",
            "INFO:tensorflow:examples/sec: 0.704482\n",
            "I0410 14:35:29.287867 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704482\n",
            "INFO:tensorflow:global_step/sec: 0.0220916\n",
            "I0410 14:36:14.553511 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220916\n",
            "INFO:tensorflow:examples/sec: 0.706932\n",
            "I0410 14:36:14.553810 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706932\n",
            "INFO:tensorflow:global_step/sec: 0.0219924\n",
            "I0410 14:37:00.023620 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219924\n",
            "INFO:tensorflow:examples/sec: 0.703758\n",
            "I0410 14:37:00.024012 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703758\n",
            "INFO:tensorflow:global_step/sec: 0.0218402\n",
            "I0410 14:37:45.810775 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218402\n",
            "INFO:tensorflow:examples/sec: 0.698887\n",
            "I0410 14:37:45.811250 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698887\n",
            "INFO:tensorflow:global_step/sec: 0.0218487\n",
            "I0410 14:38:31.580174 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218487\n",
            "INFO:tensorflow:examples/sec: 0.699157\n",
            "I0410 14:38:31.580600 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699157\n",
            "INFO:tensorflow:global_step/sec: 0.0218952\n",
            "I0410 14:39:17.252277 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218952\n",
            "INFO:tensorflow:examples/sec: 0.700646\n",
            "I0410 14:39:17.253843 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700646\n",
            "INFO:tensorflow:global_step/sec: 0.0221854\n",
            "I0410 14:40:02.327009 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221854\n",
            "INFO:tensorflow:examples/sec: 0.709932\n",
            "I0410 14:40:02.327447 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709932\n",
            "INFO:tensorflow:global_step/sec: 0.0219569\n",
            "I0410 14:40:47.870727 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219569\n",
            "INFO:tensorflow:examples/sec: 0.702622\n",
            "I0410 14:40:47.871260 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702622\n",
            "INFO:tensorflow:Saving checkpoints for 800 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 14:41:33.416717 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 800 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0189634\n",
            "I0410 14:41:40.603700 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0189634\n",
            "INFO:tensorflow:examples/sec: 0.60683\n",
            "I0410 14:41:40.604011 140202582333312 tpu_estimator.py:2160] examples/sec: 0.60683\n",
            "INFO:tensorflow:global_step/sec: 0.0212967\n",
            "I0410 14:42:27.559357 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0212967\n",
            "INFO:tensorflow:examples/sec: 0.681496\n",
            "I0410 14:42:27.559669 140202582333312 tpu_estimator.py:2160] examples/sec: 0.681496\n",
            "INFO:tensorflow:global_step/sec: 0.0222437\n",
            "I0410 14:43:12.515843 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222437\n",
            "INFO:tensorflow:examples/sec: 0.711799\n",
            "I0410 14:43:12.516383 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711799\n",
            "INFO:tensorflow:global_step/sec: 0.0220261\n",
            "I0410 14:43:57.916473 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220261\n",
            "INFO:tensorflow:examples/sec: 0.704836\n",
            "I0410 14:43:57.916751 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704836\n",
            "INFO:tensorflow:global_step/sec: 0.0222124\n",
            "I0410 14:44:42.936362 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222124\n",
            "INFO:tensorflow:examples/sec: 0.710797\n",
            "I0410 14:44:42.936826 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710797\n",
            "INFO:tensorflow:global_step/sec: 0.0220081\n",
            "I0410 14:45:28.374081 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220081\n",
            "INFO:tensorflow:examples/sec: 0.704261\n",
            "I0410 14:45:28.374598 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704261\n",
            "INFO:tensorflow:global_step/sec: 0.0218507\n",
            "I0410 14:46:14.139119 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218507\n",
            "INFO:tensorflow:examples/sec: 0.699224\n",
            "I0410 14:46:14.140542 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699224\n",
            "INFO:tensorflow:global_step/sec: 0.0216817\n",
            "I0410 14:47:00.260892 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216817\n",
            "INFO:tensorflow:examples/sec: 0.693815\n",
            "I0410 14:47:00.261351 140202582333312 tpu_estimator.py:2160] examples/sec: 0.693815\n",
            "INFO:tensorflow:global_step/sec: 0.0220021\n",
            "I0410 14:47:45.711200 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220021\n",
            "INFO:tensorflow:examples/sec: 0.704066\n",
            "I0410 14:47:45.711494 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704066\n",
            "INFO:tensorflow:global_step/sec: 0.0219095\n",
            "I0410 14:48:31.353521 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219095\n",
            "INFO:tensorflow:examples/sec: 0.701105\n",
            "I0410 14:48:31.354634 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701105\n",
            "INFO:tensorflow:global_step/sec: 0.0220263\n",
            "I0410 14:49:16.753676 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220263\n",
            "INFO:tensorflow:examples/sec: 0.704842\n",
            "I0410 14:49:16.754105 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704842\n",
            "INFO:tensorflow:global_step/sec: 0.0221055\n",
            "I0410 14:50:01.991327 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221055\n",
            "INFO:tensorflow:examples/sec: 0.707376\n",
            "I0410 14:50:01.991777 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707376\n",
            "INFO:tensorflow:global_step/sec: 0.0220786\n",
            "I0410 14:50:47.284015 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220786\n",
            "INFO:tensorflow:examples/sec: 0.706515\n",
            "I0410 14:50:47.285494 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706515\n",
            "INFO:tensorflow:global_step/sec: 0.0217582\n",
            "I0410 14:51:33.243629 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217582\n",
            "INFO:tensorflow:examples/sec: 0.696264\n",
            "I0410 14:51:33.244046 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696264\n",
            "INFO:tensorflow:global_step/sec: 0.0219235\n",
            "I0410 14:52:18.856775 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219235\n",
            "INFO:tensorflow:examples/sec: 0.701552\n",
            "I0410 14:52:18.857220 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701552\n",
            "INFO:tensorflow:global_step/sec: 0.0219464\n",
            "I0410 14:53:04.422325 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219464\n",
            "INFO:tensorflow:examples/sec: 0.702285\n",
            "I0410 14:53:04.423794 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702285\n",
            "INFO:tensorflow:global_step/sec: 0.0221721\n",
            "I0410 14:53:49.524521 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221721\n",
            "INFO:tensorflow:examples/sec: 0.709506\n",
            "I0410 14:53:49.524807 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709506\n",
            "INFO:tensorflow:global_step/sec: 0.02214\n",
            "I0410 14:54:34.691329 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.02214\n",
            "INFO:tensorflow:examples/sec: 0.708479\n",
            "I0410 14:54:34.691802 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708479\n",
            "INFO:tensorflow:global_step/sec: 0.0221537\n",
            "I0410 14:55:19.830601 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221537\n",
            "INFO:tensorflow:examples/sec: 0.708918\n",
            "I0410 14:55:19.832114 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708918\n",
            "INFO:tensorflow:global_step/sec: 0.022216\n",
            "I0410 14:56:04.843248 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022216\n",
            "INFO:tensorflow:examples/sec: 0.710911\n",
            "I0410 14:56:04.843678 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710911\n",
            "INFO:tensorflow:Saving checkpoints for 820 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 14:56:49.903946 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 820 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0192061\n",
            "I0410 14:56:56.910061 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0192061\n",
            "INFO:tensorflow:examples/sec: 0.614594\n",
            "I0410 14:56:56.910408 140202582333312 tpu_estimator.py:2160] examples/sec: 0.614594\n",
            "INFO:tensorflow:global_step/sec: 0.0217968\n",
            "I0410 14:57:42.788532 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217968\n",
            "INFO:tensorflow:examples/sec: 0.697497\n",
            "I0410 14:57:42.789944 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697497\n",
            "INFO:tensorflow:global_step/sec: 0.0222051\n",
            "I0410 14:58:27.823152 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222051\n",
            "INFO:tensorflow:examples/sec: 0.710564\n",
            "I0410 14:58:27.823624 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710564\n",
            "INFO:tensorflow:global_step/sec: 0.0220811\n",
            "I0410 14:59:13.110855 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220811\n",
            "INFO:tensorflow:examples/sec: 0.706594\n",
            "I0410 14:59:13.111273 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706594\n",
            "INFO:tensorflow:global_step/sec: 0.0221995\n",
            "I0410 14:59:58.157016 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221995\n",
            "INFO:tensorflow:examples/sec: 0.710385\n",
            "I0410 14:59:58.157318 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710385\n",
            "INFO:tensorflow:global_step/sec: 0.0219948\n",
            "I0410 15:00:43.622192 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219948\n",
            "INFO:tensorflow:examples/sec: 0.703833\n",
            "I0410 15:00:43.622464 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703833\n",
            "INFO:tensorflow:global_step/sec: 0.0221699\n",
            "I0410 15:01:28.728350 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221699\n",
            "INFO:tensorflow:examples/sec: 0.709438\n",
            "I0410 15:01:28.728701 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709438\n",
            "INFO:tensorflow:global_step/sec: 0.0219515\n",
            "I0410 15:02:14.283166 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219515\n",
            "INFO:tensorflow:examples/sec: 0.702449\n",
            "I0410 15:02:14.284720 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702449\n",
            "INFO:tensorflow:global_step/sec: 0.021975\n",
            "I0410 15:02:59.789381 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021975\n",
            "INFO:tensorflow:examples/sec: 0.703201\n",
            "I0410 15:02:59.789711 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703201\n",
            "INFO:tensorflow:global_step/sec: 0.0221752\n",
            "I0410 15:03:44.884873 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221752\n",
            "INFO:tensorflow:examples/sec: 0.709606\n",
            "I0410 15:03:44.885235 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709606\n",
            "INFO:tensorflow:global_step/sec: 0.0220836\n",
            "I0410 15:04:30.167284 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220836\n",
            "INFO:tensorflow:examples/sec: 0.706675\n",
            "I0410 15:04:30.168480 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706675\n",
            "INFO:tensorflow:global_step/sec: 0.0221289\n",
            "I0410 15:05:15.357161 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221289\n",
            "INFO:tensorflow:examples/sec: 0.708123\n",
            "I0410 15:05:15.357601 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708123\n",
            "INFO:tensorflow:global_step/sec: 0.0219192\n",
            "I0410 15:06:00.979263 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219192\n",
            "INFO:tensorflow:examples/sec: 0.701414\n",
            "I0410 15:06:00.979609 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701414\n",
            "INFO:tensorflow:global_step/sec: 0.0222075\n",
            "I0410 15:06:46.008990 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222075\n",
            "INFO:tensorflow:examples/sec: 0.710641\n",
            "I0410 15:06:46.010404 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710641\n",
            "INFO:tensorflow:global_step/sec: 0.0219617\n",
            "I0410 15:07:31.542849 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219617\n",
            "INFO:tensorflow:examples/sec: 0.702774\n",
            "I0410 15:07:31.543149 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702774\n",
            "INFO:tensorflow:global_step/sec: 0.0218905\n",
            "I0410 15:08:17.224784 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218905\n",
            "INFO:tensorflow:examples/sec: 0.700496\n",
            "I0410 15:08:17.225121 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700496\n",
            "INFO:tensorflow:global_step/sec: 0.0220033\n",
            "I0410 15:09:02.672522 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220033\n",
            "INFO:tensorflow:examples/sec: 0.704105\n",
            "I0410 15:09:02.672793 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704105\n",
            "INFO:tensorflow:global_step/sec: 0.0218562\n",
            "I0410 15:09:48.426223 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218562\n",
            "INFO:tensorflow:examples/sec: 0.699397\n",
            "I0410 15:09:48.426496 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699397\n",
            "INFO:tensorflow:global_step/sec: 0.0217331\n",
            "I0410 15:10:34.439026 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217331\n",
            "INFO:tensorflow:examples/sec: 0.695459\n",
            "I0410 15:10:34.439494 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695459\n",
            "INFO:tensorflow:global_step/sec: 0.0219346\n",
            "I0410 15:11:20.029000 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219346\n",
            "INFO:tensorflow:examples/sec: 0.701909\n",
            "I0410 15:11:20.030394 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701909\n",
            "INFO:tensorflow:Saving checkpoints for 840 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 15:12:05.893021 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 840 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0190462\n",
            "I0410 15:12:12.532899 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0190462\n",
            "INFO:tensorflow:examples/sec: 0.609478\n",
            "I0410 15:12:12.533322 140202582333312 tpu_estimator.py:2160] examples/sec: 0.609478\n",
            "INFO:tensorflow:global_step/sec: 0.0213705\n",
            "I0410 15:12:59.326492 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0213705\n",
            "INFO:tensorflow:examples/sec: 0.683855\n",
            "I0410 15:12:59.326964 140202582333312 tpu_estimator.py:2160] examples/sec: 0.683855\n",
            "INFO:tensorflow:global_step/sec: 0.022119\n",
            "I0410 15:13:44.536541 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022119\n",
            "INFO:tensorflow:examples/sec: 0.707807\n",
            "I0410 15:13:44.536810 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707807\n",
            "INFO:tensorflow:global_step/sec: 0.0219028\n",
            "I0410 15:14:30.192812 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219028\n",
            "INFO:tensorflow:examples/sec: 0.700891\n",
            "I0410 15:14:30.193253 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700891\n",
            "INFO:tensorflow:global_step/sec: 0.0218269\n",
            "I0410 15:15:16.007828 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218269\n",
            "INFO:tensorflow:examples/sec: 0.69846\n",
            "I0410 15:15:16.008295 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69846\n",
            "INFO:tensorflow:global_step/sec: 0.0221786\n",
            "I0410 15:16:01.096342 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221786\n",
            "INFO:tensorflow:examples/sec: 0.709715\n",
            "I0410 15:16:01.097788 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709715\n",
            "INFO:tensorflow:global_step/sec: 0.0221131\n",
            "I0410 15:16:46.318380 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221131\n",
            "INFO:tensorflow:examples/sec: 0.707621\n",
            "I0410 15:16:46.318796 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707621\n",
            "INFO:tensorflow:global_step/sec: 0.0220721\n",
            "I0410 15:17:31.624383 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220721\n",
            "INFO:tensorflow:examples/sec: 0.706307\n",
            "I0410 15:17:31.624854 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706307\n",
            "INFO:tensorflow:global_step/sec: 0.0219561\n",
            "I0410 15:18:17.169805 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219561\n",
            "INFO:tensorflow:examples/sec: 0.702596\n",
            "I0410 15:18:17.170930 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702596\n",
            "INFO:tensorflow:global_step/sec: 0.0220921\n",
            "I0410 15:19:02.434813 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220921\n",
            "INFO:tensorflow:examples/sec: 0.706947\n",
            "I0410 15:19:02.435084 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706947\n",
            "INFO:tensorflow:global_step/sec: 0.0220031\n",
            "I0410 15:19:47.883006 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220031\n",
            "INFO:tensorflow:examples/sec: 0.704099\n",
            "I0410 15:19:47.883504 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704099\n",
            "INFO:tensorflow:global_step/sec: 0.0220197\n",
            "I0410 15:20:33.296847 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220197\n",
            "INFO:tensorflow:examples/sec: 0.704631\n",
            "I0410 15:20:33.298345 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704631\n",
            "INFO:tensorflow:global_step/sec: 0.0220246\n",
            "I0410 15:21:18.700654 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220246\n",
            "INFO:tensorflow:examples/sec: 0.704787\n",
            "I0410 15:21:18.701071 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704787\n",
            "INFO:tensorflow:global_step/sec: 0.021858\n",
            "I0410 15:22:04.450479 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021858\n",
            "INFO:tensorflow:examples/sec: 0.699456\n",
            "I0410 15:22:04.450922 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699456\n",
            "INFO:tensorflow:global_step/sec: 0.0218709\n",
            "I0410 15:22:50.173257 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218709\n",
            "INFO:tensorflow:examples/sec: 0.69987\n",
            "I0410 15:22:50.173529 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69987\n",
            "INFO:tensorflow:global_step/sec: 0.0221929\n",
            "I0410 15:23:35.232685 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221929\n",
            "INFO:tensorflow:examples/sec: 0.710173\n",
            "I0410 15:23:35.233097 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710173\n",
            "INFO:tensorflow:global_step/sec: 0.022009\n",
            "I0410 15:24:20.668723 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022009\n",
            "INFO:tensorflow:examples/sec: 0.704287\n",
            "I0410 15:24:20.669025 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704287\n",
            "INFO:tensorflow:global_step/sec: 0.0221454\n",
            "I0410 15:25:05.825087 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221454\n",
            "INFO:tensorflow:examples/sec: 0.708654\n",
            "I0410 15:25:05.825408 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708654\n",
            "INFO:tensorflow:global_step/sec: 0.0220295\n",
            "I0410 15:25:51.218411 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220295\n",
            "INFO:tensorflow:examples/sec: 0.704944\n",
            "I0410 15:25:51.218806 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704944\n",
            "INFO:tensorflow:global_step/sec: 0.022096\n",
            "I0410 15:26:36.475476 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022096\n",
            "INFO:tensorflow:examples/sec: 0.707072\n",
            "I0410 15:26:36.475805 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707072\n",
            "INFO:tensorflow:Saving checkpoints for 860 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 15:27:22.076914 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 860 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0190535\n",
            "I0410 15:27:28.959221 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0190535\n",
            "INFO:tensorflow:examples/sec: 0.609713\n",
            "I0410 15:27:28.959496 140202582333312 tpu_estimator.py:2160] examples/sec: 0.609713\n",
            "INFO:tensorflow:global_step/sec: 0.0213147\n",
            "I0410 15:28:15.875216 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0213147\n",
            "INFO:tensorflow:examples/sec: 0.682071\n",
            "I0410 15:28:15.875721 140202582333312 tpu_estimator.py:2160] examples/sec: 0.682071\n",
            "INFO:tensorflow:global_step/sec: 0.0220145\n",
            "I0410 15:29:01.299885 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220145\n",
            "INFO:tensorflow:examples/sec: 0.704463\n",
            "I0410 15:29:01.300329 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704463\n",
            "INFO:tensorflow:global_step/sec: 0.0216671\n",
            "I0410 15:29:47.452844 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216671\n",
            "INFO:tensorflow:examples/sec: 0.693347\n",
            "I0410 15:29:47.454432 140202582333312 tpu_estimator.py:2160] examples/sec: 0.693347\n",
            "INFO:tensorflow:global_step/sec: 0.0221577\n",
            "I0410 15:30:32.583802 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221577\n",
            "INFO:tensorflow:examples/sec: 0.709048\n",
            "I0410 15:30:32.584258 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709048\n",
            "INFO:tensorflow:global_step/sec: 0.0216516\n",
            "I0410 15:31:18.769799 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216516\n",
            "INFO:tensorflow:examples/sec: 0.692853\n",
            "I0410 15:31:18.770265 140202582333312 tpu_estimator.py:2160] examples/sec: 0.692853\n",
            "INFO:tensorflow:global_step/sec: 0.0218002\n",
            "I0410 15:32:04.640815 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218002\n",
            "INFO:tensorflow:examples/sec: 0.697607\n",
            "I0410 15:32:04.642025 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697607\n",
            "INFO:tensorflow:global_step/sec: 0.0218475\n",
            "I0410 15:32:50.412604 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218475\n",
            "INFO:tensorflow:examples/sec: 0.699119\n",
            "I0410 15:32:50.413052 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699119\n",
            "INFO:tensorflow:global_step/sec: 0.0220786\n",
            "I0410 15:33:35.705356 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220786\n",
            "INFO:tensorflow:examples/sec: 0.706516\n",
            "I0410 15:33:35.705832 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706516\n",
            "INFO:tensorflow:global_step/sec: 0.022131\n",
            "I0410 15:34:20.890889 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022131\n",
            "INFO:tensorflow:examples/sec: 0.708191\n",
            "I0410 15:34:20.892426 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708191\n",
            "INFO:tensorflow:global_step/sec: 0.0220358\n",
            "I0410 15:35:06.271547 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220358\n",
            "INFO:tensorflow:examples/sec: 0.705146\n",
            "I0410 15:35:06.272018 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705146\n",
            "INFO:tensorflow:global_step/sec: 0.0216901\n",
            "I0410 15:35:52.375525 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216901\n",
            "INFO:tensorflow:examples/sec: 0.694084\n",
            "I0410 15:35:52.375994 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694084\n",
            "INFO:tensorflow:global_step/sec: 0.0220132\n",
            "I0410 15:36:37.802871 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220132\n",
            "INFO:tensorflow:examples/sec: 0.704421\n",
            "I0410 15:36:37.804341 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704421\n",
            "INFO:tensorflow:global_step/sec: 0.0219442\n",
            "I0410 15:37:23.372877 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219442\n",
            "INFO:tensorflow:examples/sec: 0.702216\n",
            "I0410 15:37:23.373339 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702216\n",
            "INFO:tensorflow:global_step/sec: 0.0220253\n",
            "I0410 15:38:08.775253 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220253\n",
            "INFO:tensorflow:examples/sec: 0.704809\n",
            "I0410 15:38:08.775748 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704809\n",
            "INFO:tensorflow:global_step/sec: 0.0218062\n",
            "I0410 15:38:54.633844 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218062\n",
            "INFO:tensorflow:examples/sec: 0.697797\n",
            "I0410 15:38:54.635423 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697797\n",
            "INFO:tensorflow:global_step/sec: 0.0219104\n",
            "I0410 15:39:40.274350 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219104\n",
            "INFO:tensorflow:examples/sec: 0.701132\n",
            "I0410 15:39:40.274832 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701132\n",
            "INFO:tensorflow:global_step/sec: 0.0219923\n",
            "I0410 15:40:25.744951 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219923\n",
            "INFO:tensorflow:examples/sec: 0.703753\n",
            "I0410 15:40:25.745423 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703753\n",
            "INFO:tensorflow:global_step/sec: 0.0218448\n",
            "I0410 15:41:11.522442 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218448\n",
            "INFO:tensorflow:examples/sec: 0.699034\n",
            "I0410 15:41:11.523829 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699034\n",
            "INFO:tensorflow:global_step/sec: 0.021771\n",
            "I0410 15:41:57.454904 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021771\n",
            "INFO:tensorflow:examples/sec: 0.696673\n",
            "I0410 15:41:57.455365 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696673\n",
            "INFO:tensorflow:Saving checkpoints for 880 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 15:42:42.948717 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 880 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0189314\n",
            "I0410 15:42:50.277085 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0189314\n",
            "INFO:tensorflow:examples/sec: 0.605805\n",
            "I0410 15:42:50.277426 140202582333312 tpu_estimator.py:2160] examples/sec: 0.605805\n",
            "INFO:tensorflow:global_step/sec: 0.0214759\n",
            "I0410 15:43:36.840968 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0214759\n",
            "INFO:tensorflow:examples/sec: 0.68723\n",
            "I0410 15:43:36.841295 140202582333312 tpu_estimator.py:2160] examples/sec: 0.68723\n",
            "INFO:tensorflow:global_step/sec: 0.0216588\n",
            "I0410 15:44:23.011488 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216588\n",
            "INFO:tensorflow:examples/sec: 0.693082\n",
            "I0410 15:44:23.011861 140202582333312 tpu_estimator.py:2160] examples/sec: 0.693082\n",
            "INFO:tensorflow:global_step/sec: 0.0219906\n",
            "I0410 15:45:08.485549 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219906\n",
            "INFO:tensorflow:examples/sec: 0.703698\n",
            "I0410 15:45:08.485975 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703698\n",
            "INFO:tensorflow:global_step/sec: 0.0220317\n",
            "I0410 15:45:53.874755 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220317\n",
            "INFO:tensorflow:examples/sec: 0.705013\n",
            "I0410 15:45:53.876152 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705013\n",
            "INFO:tensorflow:global_step/sec: 0.0217942\n",
            "I0410 15:46:39.758568 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217942\n",
            "INFO:tensorflow:examples/sec: 0.697414\n",
            "I0410 15:46:39.759034 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697414\n",
            "INFO:tensorflow:global_step/sec: 0.0217271\n",
            "I0410 15:47:25.784084 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217271\n",
            "INFO:tensorflow:examples/sec: 0.695266\n",
            "I0410 15:47:25.784520 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695266\n",
            "INFO:tensorflow:global_step/sec: 0.0219192\n",
            "I0410 15:48:11.406309 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219192\n",
            "INFO:tensorflow:examples/sec: 0.701413\n",
            "I0410 15:48:11.407836 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701413\n",
            "INFO:tensorflow:global_step/sec: 0.0221498\n",
            "I0410 15:48:56.553372 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221498\n",
            "INFO:tensorflow:examples/sec: 0.708794\n",
            "I0410 15:48:56.553805 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708794\n",
            "INFO:tensorflow:global_step/sec: 0.0220875\n",
            "I0410 15:49:41.827829 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220875\n",
            "INFO:tensorflow:examples/sec: 0.706801\n",
            "I0410 15:49:41.828357 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706801\n",
            "INFO:tensorflow:global_step/sec: 0.0216763\n",
            "I0410 15:50:27.961146 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216763\n",
            "INFO:tensorflow:examples/sec: 0.693642\n",
            "I0410 15:50:27.962250 140202582333312 tpu_estimator.py:2160] examples/sec: 0.693642\n",
            "INFO:tensorflow:global_step/sec: 0.0218712\n",
            "I0410 15:51:13.683327 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218712\n",
            "INFO:tensorflow:examples/sec: 0.69988\n",
            "I0410 15:51:13.683616 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69988\n",
            "INFO:tensorflow:global_step/sec: 0.0217296\n",
            "I0410 15:51:59.703351 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217296\n",
            "INFO:tensorflow:examples/sec: 0.695349\n",
            "I0410 15:51:59.703778 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695349\n",
            "INFO:tensorflow:global_step/sec: 0.0219714\n",
            "I0410 15:52:45.216973 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219714\n",
            "INFO:tensorflow:examples/sec: 0.703085\n",
            "I0410 15:52:45.217391 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703085\n",
            "INFO:tensorflow:global_step/sec: 0.021973\n",
            "I0410 15:53:30.727423 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021973\n",
            "INFO:tensorflow:examples/sec: 0.703136\n",
            "I0410 15:53:30.727774 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703136\n",
            "INFO:tensorflow:global_step/sec: 0.0216738\n",
            "I0410 15:54:16.866190 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216738\n",
            "INFO:tensorflow:examples/sec: 0.69356\n",
            "I0410 15:54:16.866641 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69356\n",
            "INFO:tensorflow:global_step/sec: 0.0219405\n",
            "I0410 15:55:02.444102 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219405\n",
            "INFO:tensorflow:examples/sec: 0.702095\n",
            "I0410 15:55:02.445305 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702095\n",
            "INFO:tensorflow:global_step/sec: 0.0218202\n",
            "I0410 15:55:48.273535 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218202\n",
            "INFO:tensorflow:examples/sec: 0.698247\n",
            "I0410 15:55:48.273976 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698247\n",
            "INFO:tensorflow:global_step/sec: 0.0220253\n",
            "I0410 15:56:33.675471 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220253\n",
            "INFO:tensorflow:examples/sec: 0.70481\n",
            "I0410 15:56:33.675946 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70481\n",
            "INFO:tensorflow:global_step/sec: 0.0220157\n",
            "I0410 15:57:19.097690 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220157\n",
            "INFO:tensorflow:examples/sec: 0.704501\n",
            "I0410 15:57:19.099128 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704501\n",
            "INFO:tensorflow:Saving checkpoints for 900 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 15:58:04.486939 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 900 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.019214\n",
            "I0410 15:58:11.143020 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.019214\n",
            "INFO:tensorflow:examples/sec: 0.614848\n",
            "I0410 15:58:11.143411 140202582333312 tpu_estimator.py:2160] examples/sec: 0.614848\n",
            "INFO:tensorflow:global_step/sec: 0.0216035\n",
            "I0410 15:58:57.431918 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216035\n",
            "INFO:tensorflow:examples/sec: 0.691311\n",
            "I0410 15:58:57.432230 140202582333312 tpu_estimator.py:2160] examples/sec: 0.691311\n",
            "INFO:tensorflow:global_step/sec: 0.0220036\n",
            "I0410 15:59:42.879036 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220036\n",
            "INFO:tensorflow:examples/sec: 0.704115\n",
            "I0410 15:59:42.880492 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704115\n",
            "INFO:tensorflow:global_step/sec: 0.0221208\n",
            "I0410 16:00:28.085268 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221208\n",
            "INFO:tensorflow:examples/sec: 0.707867\n",
            "I0410 16:00:28.085672 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707867\n",
            "INFO:tensorflow:global_step/sec: 0.0220321\n",
            "I0410 16:01:13.473656 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220321\n",
            "INFO:tensorflow:examples/sec: 0.705027\n",
            "I0410 16:01:13.473941 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705027\n",
            "INFO:tensorflow:global_step/sec: 0.0220783\n",
            "I0410 16:01:58.767069 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220783\n",
            "INFO:tensorflow:examples/sec: 0.706506\n",
            "I0410 16:01:58.768559 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706506\n",
            "INFO:tensorflow:global_step/sec: 0.0218998\n",
            "I0410 16:02:44.429559 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218998\n",
            "INFO:tensorflow:examples/sec: 0.700793\n",
            "I0410 16:02:44.429985 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700793\n",
            "INFO:tensorflow:global_step/sec: 0.0219741\n",
            "I0410 16:03:29.937719 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219741\n",
            "INFO:tensorflow:examples/sec: 0.70317\n",
            "I0410 16:03:29.938150 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70317\n",
            "INFO:tensorflow:global_step/sec: 0.0221518\n",
            "I0410 16:04:15.080723 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221518\n",
            "INFO:tensorflow:examples/sec: 0.708859\n",
            "I0410 16:04:15.081948 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708859\n",
            "INFO:tensorflow:global_step/sec: 0.0218795\n",
            "I0410 16:05:00.785602 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218795\n",
            "INFO:tensorflow:examples/sec: 0.700144\n",
            "I0410 16:05:00.786013 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700144\n",
            "INFO:tensorflow:global_step/sec: 0.02199\n",
            "I0410 16:05:46.260830 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.02199\n",
            "INFO:tensorflow:examples/sec: 0.70368\n",
            "I0410 16:05:46.261291 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70368\n",
            "INFO:tensorflow:global_step/sec: 0.0220004\n",
            "I0410 16:06:31.714584 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220004\n",
            "INFO:tensorflow:examples/sec: 0.704012\n",
            "I0410 16:06:31.716044 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704012\n",
            "INFO:tensorflow:global_step/sec: 0.0218673\n",
            "I0410 16:07:17.445051 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218673\n",
            "INFO:tensorflow:examples/sec: 0.699752\n",
            "I0410 16:07:17.445489 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699752\n",
            "INFO:tensorflow:global_step/sec: 0.0220149\n",
            "I0410 16:08:02.868816 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220149\n",
            "INFO:tensorflow:examples/sec: 0.704478\n",
            "I0410 16:08:02.869296 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704478\n",
            "INFO:tensorflow:global_step/sec: 0.0219942\n",
            "I0410 16:08:48.335290 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219942\n",
            "INFO:tensorflow:examples/sec: 0.703815\n",
            "I0410 16:08:48.336763 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703815\n",
            "INFO:tensorflow:global_step/sec: 0.0220793\n",
            "I0410 16:09:33.626581 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220793\n",
            "INFO:tensorflow:examples/sec: 0.706537\n",
            "I0410 16:09:33.626996 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706537\n",
            "INFO:tensorflow:global_step/sec: 0.0218284\n",
            "I0410 16:10:19.438396 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218284\n",
            "INFO:tensorflow:examples/sec: 0.69851\n",
            "I0410 16:10:19.438828 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69851\n",
            "INFO:tensorflow:global_step/sec: 0.0220639\n",
            "I0410 16:11:04.761281 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220639\n",
            "INFO:tensorflow:examples/sec: 0.706045\n",
            "I0410 16:11:04.762425 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706045\n",
            "INFO:tensorflow:global_step/sec: 0.0220065\n",
            "I0410 16:11:50.202325 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220065\n",
            "INFO:tensorflow:examples/sec: 0.704209\n",
            "I0410 16:11:50.202839 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704209\n",
            "INFO:tensorflow:global_step/sec: 0.0221064\n",
            "I0410 16:12:35.438010 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221064\n",
            "INFO:tensorflow:examples/sec: 0.707406\n",
            "I0410 16:12:35.438466 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707406\n",
            "INFO:tensorflow:Saving checkpoints for 920 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 16:13:20.968316 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 920 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0190771\n",
            "I0410 16:13:27.856849 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0190771\n",
            "INFO:tensorflow:examples/sec: 0.610467\n",
            "I0410 16:13:27.857229 140202582333312 tpu_estimator.py:2160] examples/sec: 0.610467\n",
            "INFO:tensorflow:global_step/sec: 0.021635\n",
            "I0410 16:14:14.078264 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021635\n",
            "INFO:tensorflow:examples/sec: 0.692321\n",
            "I0410 16:14:14.078715 140202582333312 tpu_estimator.py:2160] examples/sec: 0.692321\n",
            "INFO:tensorflow:global_step/sec: 0.0216445\n",
            "I0410 16:15:00.279334 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216445\n",
            "INFO:tensorflow:examples/sec: 0.692624\n",
            "I0410 16:15:00.279767 140202582333312 tpu_estimator.py:2160] examples/sec: 0.692624\n",
            "INFO:tensorflow:global_step/sec: 0.0220144\n",
            "I0410 16:15:45.704255 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220144\n",
            "INFO:tensorflow:examples/sec: 0.704459\n",
            "I0410 16:15:45.705420 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704459\n",
            "INFO:tensorflow:global_step/sec: 0.0219381\n",
            "I0410 16:16:31.287014 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219381\n",
            "INFO:tensorflow:examples/sec: 0.70202\n",
            "I0410 16:16:31.287523 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70202\n",
            "INFO:tensorflow:global_step/sec: 0.0219278\n",
            "I0410 16:17:16.891333 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219278\n",
            "INFO:tensorflow:examples/sec: 0.701688\n",
            "I0410 16:17:16.891743 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701688\n",
            "INFO:tensorflow:global_step/sec: 0.0219276\n",
            "I0410 16:18:02.495899 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219276\n",
            "INFO:tensorflow:examples/sec: 0.701684\n",
            "I0410 16:18:02.497068 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701684\n",
            "INFO:tensorflow:global_step/sec: 0.0220472\n",
            "I0410 16:18:47.853113 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220472\n",
            "INFO:tensorflow:examples/sec: 0.705511\n",
            "I0410 16:18:47.853634 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705511\n",
            "INFO:tensorflow:global_step/sec: 0.0222054\n",
            "I0410 16:19:32.887182 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222054\n",
            "INFO:tensorflow:examples/sec: 0.710573\n",
            "I0410 16:19:32.887664 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710573\n",
            "INFO:tensorflow:global_step/sec: 0.0220362\n",
            "I0410 16:20:18.267143 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220362\n",
            "INFO:tensorflow:examples/sec: 0.705158\n",
            "I0410 16:20:18.268564 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705158\n",
            "INFO:tensorflow:global_step/sec: 0.021918\n",
            "I0410 16:21:03.891855 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021918\n",
            "INFO:tensorflow:examples/sec: 0.701376\n",
            "I0410 16:21:03.892301 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701376\n",
            "INFO:tensorflow:global_step/sec: 0.0219365\n",
            "I0410 16:21:49.477800 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219365\n",
            "INFO:tensorflow:examples/sec: 0.701969\n",
            "I0410 16:21:49.478247 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701969\n",
            "INFO:tensorflow:global_step/sec: 0.0220138\n",
            "I0410 16:22:34.903907 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220138\n",
            "INFO:tensorflow:examples/sec: 0.704441\n",
            "I0410 16:22:34.904987 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704441\n",
            "INFO:tensorflow:global_step/sec: 0.0220963\n",
            "I0410 16:23:20.160376 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220963\n",
            "INFO:tensorflow:examples/sec: 0.707081\n",
            "I0410 16:23:20.160651 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707081\n",
            "INFO:tensorflow:global_step/sec: 0.0216665\n",
            "I0410 16:24:06.314670 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216665\n",
            "INFO:tensorflow:examples/sec: 0.693327\n",
            "I0410 16:24:06.315115 140202582333312 tpu_estimator.py:2160] examples/sec: 0.693327\n",
            "INFO:tensorflow:global_step/sec: 0.0220148\n",
            "I0410 16:24:51.738733 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220148\n",
            "INFO:tensorflow:examples/sec: 0.704472\n",
            "I0410 16:24:51.740144 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704472\n",
            "INFO:tensorflow:global_step/sec: 0.0219506\n",
            "I0410 16:25:37.295616 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219506\n",
            "INFO:tensorflow:examples/sec: 0.702419\n",
            "I0410 16:25:37.296023 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702419\n",
            "INFO:tensorflow:global_step/sec: 0.0218583\n",
            "I0410 16:26:23.044745 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218583\n",
            "INFO:tensorflow:examples/sec: 0.699467\n",
            "I0410 16:26:23.045240 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699467\n",
            "INFO:tensorflow:global_step/sec: 0.0218562\n",
            "I0410 16:27:08.798440 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218562\n",
            "INFO:tensorflow:examples/sec: 0.699397\n",
            "I0410 16:27:08.799620 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699397\n",
            "INFO:tensorflow:global_step/sec: 0.0220833\n",
            "I0410 16:27:54.081934 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220833\n",
            "INFO:tensorflow:examples/sec: 0.706665\n",
            "I0410 16:27:54.082395 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706665\n",
            "INFO:tensorflow:Saving checkpoints for 940 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 16:28:39.449789 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 940 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0189342\n",
            "I0410 16:28:46.895905 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0189342\n",
            "INFO:tensorflow:examples/sec: 0.605896\n",
            "I0410 16:28:46.896337 140202582333312 tpu_estimator.py:2160] examples/sec: 0.605896\n",
            "INFO:tensorflow:global_step/sec: 0.0215992\n",
            "I0410 16:29:33.193959 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215992\n",
            "INFO:tensorflow:examples/sec: 0.691174\n",
            "I0410 16:29:33.195169 140202582333312 tpu_estimator.py:2160] examples/sec: 0.691174\n",
            "INFO:tensorflow:global_step/sec: 0.0219036\n",
            "I0410 16:30:18.848509 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219036\n",
            "INFO:tensorflow:examples/sec: 0.700916\n",
            "I0410 16:30:18.848939 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700916\n",
            "INFO:tensorflow:global_step/sec: 0.0219678\n",
            "I0410 16:31:04.369752 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219678\n",
            "INFO:tensorflow:examples/sec: 0.702968\n",
            "I0410 16:31:04.370268 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702968\n",
            "INFO:tensorflow:global_step/sec: 0.0217631\n",
            "I0410 16:31:50.319214 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217631\n",
            "INFO:tensorflow:examples/sec: 0.696418\n",
            "I0410 16:31:50.320942 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696418\n",
            "INFO:tensorflow:global_step/sec: 0.0216971\n",
            "I0410 16:32:36.408319 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216971\n",
            "INFO:tensorflow:examples/sec: 0.694307\n",
            "I0410 16:32:36.408659 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694307\n",
            "INFO:tensorflow:global_step/sec: 0.021784\n",
            "I0410 16:33:22.313567 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021784\n",
            "INFO:tensorflow:examples/sec: 0.697087\n",
            "I0410 16:33:22.313997 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697087\n",
            "INFO:tensorflow:global_step/sec: 0.0217453\n",
            "I0410 16:34:08.300638 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217453\n",
            "INFO:tensorflow:examples/sec: 0.69585\n",
            "I0410 16:34:08.300932 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69585\n",
            "INFO:tensorflow:global_step/sec: 0.021784\n",
            "I0410 16:34:54.205629 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021784\n",
            "INFO:tensorflow:examples/sec: 0.697089\n",
            "I0410 16:34:54.206161 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697089\n",
            "INFO:tensorflow:global_step/sec: 0.0218166\n",
            "I0410 16:35:40.042374 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218166\n",
            "INFO:tensorflow:examples/sec: 0.698133\n",
            "I0410 16:35:40.042827 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698133\n",
            "INFO:tensorflow:global_step/sec: 0.0216869\n",
            "I0410 16:36:26.153030 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216869\n",
            "INFO:tensorflow:examples/sec: 0.69398\n",
            "I0410 16:36:26.154099 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69398\n",
            "INFO:tensorflow:global_step/sec: 0.0217755\n",
            "I0410 16:37:12.076114 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217755\n",
            "INFO:tensorflow:examples/sec: 0.696818\n",
            "I0410 16:37:12.076433 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696818\n",
            "INFO:tensorflow:global_step/sec: 0.0219421\n",
            "I0410 16:37:57.650645 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219421\n",
            "INFO:tensorflow:examples/sec: 0.702147\n",
            "I0410 16:37:57.650944 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702147\n",
            "INFO:tensorflow:global_step/sec: 0.0218279\n",
            "I0410 16:38:43.463455 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218279\n",
            "INFO:tensorflow:examples/sec: 0.698494\n",
            "I0410 16:38:43.464532 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698494\n",
            "INFO:tensorflow:global_step/sec: 0.0220958\n",
            "I0410 16:39:28.721151 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220958\n",
            "INFO:tensorflow:examples/sec: 0.707065\n",
            "I0410 16:39:28.721488 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707065\n",
            "INFO:tensorflow:global_step/sec: 0.021962\n",
            "I0410 16:40:14.254174 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021962\n",
            "INFO:tensorflow:examples/sec: 0.702785\n",
            "I0410 16:40:14.254472 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702785\n",
            "INFO:tensorflow:global_step/sec: 0.0220045\n",
            "I0410 16:40:59.699458 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220045\n",
            "INFO:tensorflow:examples/sec: 0.704143\n",
            "I0410 16:40:59.700614 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704143\n",
            "INFO:tensorflow:global_step/sec: 0.0220372\n",
            "I0410 16:41:45.077390 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220372\n",
            "INFO:tensorflow:examples/sec: 0.705189\n",
            "I0410 16:41:45.077866 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705189\n",
            "INFO:tensorflow:global_step/sec: 0.0216983\n",
            "I0410 16:42:31.164016 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216983\n",
            "INFO:tensorflow:examples/sec: 0.694344\n",
            "I0410 16:42:31.164435 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694344\n",
            "INFO:tensorflow:global_step/sec: 0.0219696\n",
            "I0410 16:43:16.681447 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219696\n",
            "INFO:tensorflow:examples/sec: 0.703027\n",
            "I0410 16:43:16.682564 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703027\n",
            "INFO:tensorflow:Saving checkpoints for 960 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 16:44:01.771533 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 960 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0190501\n",
            "I0410 16:44:09.174598 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0190501\n",
            "INFO:tensorflow:examples/sec: 0.609603\n",
            "I0410 16:44:09.175027 140202582333312 tpu_estimator.py:2160] examples/sec: 0.609603\n",
            "INFO:tensorflow:global_step/sec: 0.0216578\n",
            "I0410 16:44:55.347403 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216578\n",
            "INFO:tensorflow:examples/sec: 0.693051\n",
            "I0410 16:44:55.347881 140202582333312 tpu_estimator.py:2160] examples/sec: 0.693051\n",
            "INFO:tensorflow:global_step/sec: 0.0219029\n",
            "I0410 16:45:41.003629 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219029\n",
            "INFO:tensorflow:examples/sec: 0.700891\n",
            "I0410 16:45:41.005271 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700891\n",
            "INFO:tensorflow:global_step/sec: 0.0219779\n",
            "I0410 16:46:26.503855 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219779\n",
            "INFO:tensorflow:examples/sec: 0.703291\n",
            "I0410 16:46:26.504151 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703291\n",
            "INFO:tensorflow:global_step/sec: 0.022101\n",
            "I0410 16:47:11.750766 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022101\n",
            "INFO:tensorflow:examples/sec: 0.70723\n",
            "I0410 16:47:11.751201 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70723\n",
            "INFO:tensorflow:global_step/sec: 0.0219949\n",
            "I0410 16:47:57.215777 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219949\n",
            "INFO:tensorflow:examples/sec: 0.703838\n",
            "I0410 16:47:57.216938 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703838\n",
            "INFO:tensorflow:global_step/sec: 0.0220477\n",
            "I0410 16:48:42.572020 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220477\n",
            "INFO:tensorflow:examples/sec: 0.705525\n",
            "I0410 16:48:42.572510 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705525\n",
            "INFO:tensorflow:global_step/sec: 0.0219018\n",
            "I0410 16:49:28.230353 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219018\n",
            "INFO:tensorflow:examples/sec: 0.700858\n",
            "I0410 16:49:28.230765 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700858\n",
            "INFO:tensorflow:global_step/sec: 0.022065\n",
            "I0410 16:50:13.550903 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022065\n",
            "INFO:tensorflow:examples/sec: 0.706082\n",
            "I0410 16:50:13.552073 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706082\n",
            "INFO:tensorflow:global_step/sec: 0.0220189\n",
            "I0410 16:50:58.966464 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220189\n",
            "INFO:tensorflow:examples/sec: 0.704605\n",
            "I0410 16:50:58.966908 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704605\n",
            "INFO:tensorflow:global_step/sec: 0.0218208\n",
            "I0410 16:51:44.794240 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218208\n",
            "INFO:tensorflow:examples/sec: 0.698266\n",
            "I0410 16:51:44.794646 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698266\n",
            "INFO:tensorflow:global_step/sec: 0.0216699\n",
            "I0410 16:52:30.941289 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216699\n",
            "INFO:tensorflow:examples/sec: 0.693435\n",
            "I0410 16:52:30.942387 140202582333312 tpu_estimator.py:2160] examples/sec: 0.693435\n",
            "INFO:tensorflow:global_step/sec: 0.0217926\n",
            "I0410 16:53:16.828351 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217926\n",
            "INFO:tensorflow:examples/sec: 0.697364\n",
            "I0410 16:53:16.828781 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697364\n",
            "INFO:tensorflow:global_step/sec: 0.0216693\n",
            "I0410 16:54:02.976837 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216693\n",
            "INFO:tensorflow:examples/sec: 0.693418\n",
            "I0410 16:54:02.977175 140202582333312 tpu_estimator.py:2160] examples/sec: 0.693418\n",
            "INFO:tensorflow:global_step/sec: 0.0219788\n",
            "I0410 16:54:48.474773 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219788\n",
            "INFO:tensorflow:examples/sec: 0.703323\n",
            "I0410 16:54:48.475110 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703323\n",
            "INFO:tensorflow:global_step/sec: 0.0220972\n",
            "I0410 16:55:33.729402 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220972\n",
            "INFO:tensorflow:examples/sec: 0.70711\n",
            "I0410 16:55:33.729686 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70711\n",
            "INFO:tensorflow:global_step/sec: 0.0219221\n",
            "I0410 16:56:19.345452 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219221\n",
            "INFO:tensorflow:examples/sec: 0.701508\n",
            "I0410 16:56:19.345732 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701508\n",
            "INFO:tensorflow:global_step/sec: 0.0220036\n",
            "I0410 16:57:04.792654 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220036\n",
            "INFO:tensorflow:examples/sec: 0.704114\n",
            "I0410 16:57:04.794039 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704114\n",
            "INFO:tensorflow:global_step/sec: 0.0218895\n",
            "I0410 16:57:50.476660 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218895\n",
            "INFO:tensorflow:examples/sec: 0.700464\n",
            "I0410 16:57:50.477078 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700464\n",
            "INFO:tensorflow:global_step/sec: 0.0220427\n",
            "I0410 16:58:35.843147 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220427\n",
            "INFO:tensorflow:examples/sec: 0.705366\n",
            "I0410 16:58:35.843654 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705366\n",
            "INFO:tensorflow:Saving checkpoints for 980 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 16:59:21.578769 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 980 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0188143\n",
            "I0410 16:59:28.994055 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0188143\n",
            "INFO:tensorflow:examples/sec: 0.602059\n",
            "I0410 16:59:28.994329 140202582333312 tpu_estimator.py:2160] examples/sec: 0.602059\n",
            "INFO:tensorflow:global_step/sec: 0.0213499\n",
            "I0410 17:00:15.832743 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0213499\n",
            "INFO:tensorflow:examples/sec: 0.683197\n",
            "I0410 17:00:15.833208 140202582333312 tpu_estimator.py:2160] examples/sec: 0.683197\n",
            "INFO:tensorflow:global_step/sec: 0.0222205\n",
            "I0410 17:01:00.836332 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0222205\n",
            "INFO:tensorflow:examples/sec: 0.711055\n",
            "I0410 17:01:00.836794 140202582333312 tpu_estimator.py:2160] examples/sec: 0.711055\n",
            "INFO:tensorflow:global_step/sec: 0.021945\n",
            "I0410 17:01:46.404844 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021945\n",
            "INFO:tensorflow:examples/sec: 0.70224\n",
            "I0410 17:01:46.406123 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70224\n",
            "INFO:tensorflow:global_step/sec: 0.0219739\n",
            "I0410 17:02:31.913307 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219739\n",
            "INFO:tensorflow:examples/sec: 0.703165\n",
            "I0410 17:02:31.913705 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703165\n",
            "INFO:tensorflow:global_step/sec: 0.0218491\n",
            "I0410 17:03:17.681882 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218491\n",
            "INFO:tensorflow:examples/sec: 0.69917\n",
            "I0410 17:03:17.682170 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69917\n",
            "INFO:tensorflow:global_step/sec: 0.0220083\n",
            "I0410 17:04:03.119328 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220083\n",
            "INFO:tensorflow:examples/sec: 0.704265\n",
            "I0410 17:04:03.120628 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704265\n",
            "INFO:tensorflow:global_step/sec: 0.0221379\n",
            "I0410 17:04:48.290907 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221379\n",
            "INFO:tensorflow:examples/sec: 0.708412\n",
            "I0410 17:04:48.291298 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708412\n",
            "INFO:tensorflow:global_step/sec: 0.0218252\n",
            "I0410 17:05:34.109314 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218252\n",
            "INFO:tensorflow:examples/sec: 0.698407\n",
            "I0410 17:05:34.109642 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698407\n",
            "INFO:tensorflow:global_step/sec: 0.0219486\n",
            "I0410 17:06:19.670367 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219486\n",
            "INFO:tensorflow:examples/sec: 0.702355\n",
            "I0410 17:06:19.670715 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702355\n",
            "INFO:tensorflow:global_step/sec: 0.0217713\n",
            "I0410 17:07:05.602377 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217713\n",
            "INFO:tensorflow:examples/sec: 0.696681\n",
            "I0410 17:07:05.602818 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696681\n",
            "INFO:tensorflow:global_step/sec: 0.0218202\n",
            "I0410 17:07:51.431514 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218202\n",
            "INFO:tensorflow:examples/sec: 0.698246\n",
            "I0410 17:07:51.431922 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698246\n",
            "INFO:tensorflow:global_step/sec: 0.0219126\n",
            "I0410 17:08:37.067341 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219126\n",
            "INFO:tensorflow:examples/sec: 0.701203\n",
            "I0410 17:08:37.067624 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701203\n",
            "INFO:tensorflow:global_step/sec: 0.0217807\n",
            "I0410 17:09:22.979644 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217807\n",
            "INFO:tensorflow:examples/sec: 0.696982\n",
            "I0410 17:09:22.980100 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696982\n",
            "INFO:tensorflow:global_step/sec: 0.0219004\n",
            "I0410 17:10:08.640885 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219004\n",
            "INFO:tensorflow:examples/sec: 0.700813\n",
            "I0410 17:10:08.641347 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700813\n",
            "INFO:tensorflow:global_step/sec: 0.0219559\n",
            "I0410 17:10:54.186805 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219559\n",
            "INFO:tensorflow:examples/sec: 0.702588\n",
            "I0410 17:10:54.188291 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702588\n",
            "INFO:tensorflow:global_step/sec: 0.022052\n",
            "I0410 17:11:39.534214 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022052\n",
            "INFO:tensorflow:examples/sec: 0.705663\n",
            "I0410 17:11:39.534500 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705663\n",
            "INFO:tensorflow:global_step/sec: 0.0217546\n",
            "I0410 17:12:25.501583 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217546\n",
            "INFO:tensorflow:examples/sec: 0.696146\n",
            "I0410 17:12:25.502037 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696146\n",
            "INFO:tensorflow:global_step/sec: 0.0219649\n",
            "I0410 17:13:11.028746 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219649\n",
            "INFO:tensorflow:examples/sec: 0.702876\n",
            "I0410 17:13:11.030380 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702876\n",
            "INFO:tensorflow:global_step/sec: 0.0217879\n",
            "I0410 17:13:56.925761 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217879\n",
            "INFO:tensorflow:examples/sec: 0.697213\n",
            "I0410 17:13:56.926035 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697213\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 17:14:42.556913 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 1000 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0188437\n",
            "I0410 17:14:49.993924 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0188437\n",
            "INFO:tensorflow:examples/sec: 0.602998\n",
            "I0410 17:14:49.994272 140202582333312 tpu_estimator.py:2160] examples/sec: 0.602998\n",
            "INFO:tensorflow:global_step/sec: 0.0213101\n",
            "I0410 17:15:36.920098 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0213101\n",
            "INFO:tensorflow:examples/sec: 0.681922\n",
            "I0410 17:15:36.921699 140202582333312 tpu_estimator.py:2160] examples/sec: 0.681922\n",
            "INFO:tensorflow:global_step/sec: 0.0218979\n",
            "I0410 17:16:22.586711 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218979\n",
            "INFO:tensorflow:examples/sec: 0.700732\n",
            "I0410 17:16:22.587187 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700732\n",
            "INFO:tensorflow:global_step/sec: 0.0217617\n",
            "I0410 17:17:08.539009 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217617\n",
            "INFO:tensorflow:examples/sec: 0.696374\n",
            "I0410 17:17:08.539427 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696374\n",
            "INFO:tensorflow:global_step/sec: 0.0220216\n",
            "I0410 17:17:53.948990 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220216\n",
            "INFO:tensorflow:examples/sec: 0.704691\n",
            "I0410 17:17:53.950407 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704691\n",
            "INFO:tensorflow:global_step/sec: 0.0219873\n",
            "I0410 17:18:39.429836 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219873\n",
            "INFO:tensorflow:examples/sec: 0.703593\n",
            "I0410 17:18:39.430279 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703593\n",
            "INFO:tensorflow:global_step/sec: 0.0220399\n",
            "I0410 17:19:24.801984 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220399\n",
            "INFO:tensorflow:examples/sec: 0.705278\n",
            "I0410 17:19:24.802468 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705278\n",
            "INFO:tensorflow:global_step/sec: 0.0220725\n",
            "I0410 17:20:10.107210 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220725\n",
            "INFO:tensorflow:examples/sec: 0.70632\n",
            "I0410 17:20:10.107549 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70632\n",
            "INFO:tensorflow:global_step/sec: 0.0218428\n",
            "I0410 17:20:55.888870 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218428\n",
            "INFO:tensorflow:examples/sec: 0.698969\n",
            "I0410 17:20:55.889406 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698969\n",
            "INFO:tensorflow:global_step/sec: 0.0218412\n",
            "I0410 17:21:41.673913 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218412\n",
            "INFO:tensorflow:examples/sec: 0.698919\n",
            "I0410 17:21:41.674218 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698919\n",
            "INFO:tensorflow:global_step/sec: 0.021538\n",
            "I0410 17:22:28.103514 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021538\n",
            "INFO:tensorflow:examples/sec: 0.689215\n",
            "I0410 17:22:28.104683 140202582333312 tpu_estimator.py:2160] examples/sec: 0.689215\n",
            "INFO:tensorflow:global_step/sec: 0.0219973\n",
            "I0410 17:23:13.563652 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219973\n",
            "INFO:tensorflow:examples/sec: 0.703913\n",
            "I0410 17:23:13.563933 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703913\n",
            "INFO:tensorflow:global_step/sec: 0.0220871\n",
            "I0410 17:23:58.839059 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220871\n",
            "INFO:tensorflow:examples/sec: 0.706786\n",
            "I0410 17:23:58.839527 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706786\n",
            "INFO:tensorflow:global_step/sec: 0.021882\n",
            "I0410 17:24:44.538711 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021882\n",
            "INFO:tensorflow:examples/sec: 0.700224\n",
            "I0410 17:24:44.539001 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700224\n",
            "INFO:tensorflow:global_step/sec: 0.0220379\n",
            "I0410 17:25:29.915415 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220379\n",
            "INFO:tensorflow:examples/sec: 0.705213\n",
            "I0410 17:25:29.915777 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705213\n",
            "INFO:tensorflow:global_step/sec: 0.0219651\n",
            "I0410 17:26:15.441819 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219651\n",
            "INFO:tensorflow:examples/sec: 0.702883\n",
            "I0410 17:26:15.442184 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702883\n",
            "INFO:tensorflow:global_step/sec: 0.0219748\n",
            "I0410 17:27:00.948426 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219748\n",
            "INFO:tensorflow:examples/sec: 0.703194\n",
            "I0410 17:27:00.948692 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703194\n",
            "INFO:tensorflow:global_step/sec: 0.0219663\n",
            "I0410 17:27:46.472779 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219663\n",
            "INFO:tensorflow:examples/sec: 0.702922\n",
            "I0410 17:27:46.473224 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702922\n",
            "INFO:tensorflow:global_step/sec: 0.0220293\n",
            "I0410 17:28:31.866981 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220293\n",
            "INFO:tensorflow:examples/sec: 0.704938\n",
            "I0410 17:28:31.867401 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704938\n",
            "INFO:tensorflow:global_step/sec: 0.0220937\n",
            "I0410 17:29:17.128567 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220937\n",
            "INFO:tensorflow:examples/sec: 0.706999\n",
            "I0410 17:29:17.129787 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706999\n",
            "INFO:tensorflow:Saving checkpoints for 1020 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 17:30:02.526799 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 1020 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0189843\n",
            "I0410 17:30:09.803733 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0189843\n",
            "INFO:tensorflow:examples/sec: 0.607496\n",
            "I0410 17:30:09.804100 140202582333312 tpu_estimator.py:2160] examples/sec: 0.607496\n",
            "INFO:tensorflow:global_step/sec: 0.0216581\n",
            "I0410 17:30:55.975889 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216581\n",
            "INFO:tensorflow:examples/sec: 0.693059\n",
            "I0410 17:30:55.976186 140202582333312 tpu_estimator.py:2160] examples/sec: 0.693059\n",
            "INFO:tensorflow:global_step/sec: 0.0219855\n",
            "I0410 17:31:41.460531 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219855\n",
            "INFO:tensorflow:examples/sec: 0.703536\n",
            "I0410 17:31:41.461935 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703536\n",
            "INFO:tensorflow:global_step/sec: 0.0217595\n",
            "I0410 17:32:27.417481 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217595\n",
            "INFO:tensorflow:examples/sec: 0.696305\n",
            "I0410 17:32:27.417922 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696305\n",
            "INFO:tensorflow:global_step/sec: 0.0220698\n",
            "I0410 17:33:12.728055 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220698\n",
            "INFO:tensorflow:examples/sec: 0.706234\n",
            "I0410 17:33:12.728483 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706234\n",
            "INFO:tensorflow:global_step/sec: 0.0220361\n",
            "I0410 17:33:58.108182 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220361\n",
            "INFO:tensorflow:examples/sec: 0.705155\n",
            "I0410 17:33:58.109327 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705155\n",
            "INFO:tensorflow:global_step/sec: 0.0219954\n",
            "I0410 17:34:43.572170 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219954\n",
            "INFO:tensorflow:examples/sec: 0.703853\n",
            "I0410 17:34:43.572618 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703853\n",
            "INFO:tensorflow:global_step/sec: 0.021705\n",
            "I0410 17:35:29.644543 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021705\n",
            "INFO:tensorflow:examples/sec: 0.69456\n",
            "I0410 17:35:29.644969 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69456\n",
            "INFO:tensorflow:global_step/sec: 0.0220528\n",
            "I0410 17:36:14.990269 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220528\n",
            "INFO:tensorflow:examples/sec: 0.705691\n",
            "I0410 17:36:14.991528 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705691\n",
            "INFO:tensorflow:global_step/sec: 0.0218537\n",
            "I0410 17:37:00.749098 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218537\n",
            "INFO:tensorflow:examples/sec: 0.699317\n",
            "I0410 17:37:00.749559 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699317\n",
            "INFO:tensorflow:global_step/sec: 0.0220916\n",
            "I0410 17:37:46.015216 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220916\n",
            "INFO:tensorflow:examples/sec: 0.706931\n",
            "I0410 17:37:46.015486 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706931\n",
            "INFO:tensorflow:global_step/sec: 0.0219072\n",
            "I0410 17:38:31.662247 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219072\n",
            "INFO:tensorflow:examples/sec: 0.701032\n",
            "I0410 17:38:31.663721 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701032\n",
            "INFO:tensorflow:global_step/sec: 0.0219598\n",
            "I0410 17:39:17.199962 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219598\n",
            "INFO:tensorflow:examples/sec: 0.702714\n",
            "I0410 17:39:17.200484 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702714\n",
            "INFO:tensorflow:global_step/sec: 0.0221015\n",
            "I0410 17:40:02.445887 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221015\n",
            "INFO:tensorflow:examples/sec: 0.707247\n",
            "I0410 17:40:02.446367 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707247\n",
            "INFO:tensorflow:global_step/sec: 0.0218611\n",
            "I0410 17:40:48.189252 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218611\n",
            "INFO:tensorflow:examples/sec: 0.699554\n",
            "I0410 17:40:48.190356 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699554\n",
            "INFO:tensorflow:global_step/sec: 0.0220966\n",
            "I0410 17:41:33.445179 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220966\n",
            "INFO:tensorflow:examples/sec: 0.70709\n",
            "I0410 17:41:33.445617 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70709\n",
            "INFO:tensorflow:global_step/sec: 0.0220714\n",
            "I0410 17:42:18.752572 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220714\n",
            "INFO:tensorflow:examples/sec: 0.706286\n",
            "I0410 17:42:18.752998 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706286\n",
            "INFO:tensorflow:global_step/sec: 0.0219568\n",
            "I0410 17:43:04.296561 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219568\n",
            "INFO:tensorflow:examples/sec: 0.702618\n",
            "I0410 17:43:04.297778 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702618\n",
            "INFO:tensorflow:global_step/sec: 0.0220224\n",
            "I0410 17:43:49.704927 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220224\n",
            "INFO:tensorflow:examples/sec: 0.704717\n",
            "I0410 17:43:49.705384 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704717\n",
            "INFO:tensorflow:global_step/sec: 0.0219165\n",
            "I0410 17:44:35.332537 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219165\n",
            "INFO:tensorflow:examples/sec: 0.701329\n",
            "I0410 17:44:35.332970 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701329\n",
            "INFO:tensorflow:Saving checkpoints for 1040 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 17:45:20.724835 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 1040 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0190111\n",
            "I0410 17:45:27.933448 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0190111\n",
            "INFO:tensorflow:examples/sec: 0.608354\n",
            "I0410 17:45:27.933843 140202582333312 tpu_estimator.py:2160] examples/sec: 0.608354\n",
            "INFO:tensorflow:global_step/sec: 0.0215433\n",
            "I0410 17:46:14.351757 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215433\n",
            "INFO:tensorflow:examples/sec: 0.689384\n",
            "I0410 17:46:14.352054 140202582333312 tpu_estimator.py:2160] examples/sec: 0.689384\n",
            "INFO:tensorflow:global_step/sec: 0.0217747\n",
            "I0410 17:47:00.276583 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217747\n",
            "INFO:tensorflow:examples/sec: 0.69679\n",
            "I0410 17:47:00.276858 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69679\n",
            "INFO:tensorflow:global_step/sec: 0.0220078\n",
            "I0410 17:47:45.715075 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220078\n",
            "INFO:tensorflow:examples/sec: 0.704249\n",
            "I0410 17:47:45.715391 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704249\n",
            "INFO:tensorflow:global_step/sec: 0.021946\n",
            "I0410 17:48:31.281377 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021946\n",
            "INFO:tensorflow:examples/sec: 0.702273\n",
            "I0410 17:48:31.281787 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702273\n",
            "INFO:tensorflow:global_step/sec: 0.0218624\n",
            "I0410 17:49:17.022012 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218624\n",
            "INFO:tensorflow:examples/sec: 0.699596\n",
            "I0410 17:49:17.022406 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699596\n",
            "INFO:tensorflow:global_step/sec: 0.0219899\n",
            "I0410 17:50:02.497546 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219899\n",
            "INFO:tensorflow:examples/sec: 0.703675\n",
            "I0410 17:50:02.498676 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703675\n",
            "INFO:tensorflow:global_step/sec: 0.0219127\n",
            "I0410 17:50:48.133232 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219127\n",
            "INFO:tensorflow:examples/sec: 0.701206\n",
            "I0410 17:50:48.133502 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701206\n",
            "INFO:tensorflow:global_step/sec: 0.0220109\n",
            "I0410 17:51:33.565247 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220109\n",
            "INFO:tensorflow:examples/sec: 0.704349\n",
            "I0410 17:51:33.565665 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704349\n",
            "INFO:tensorflow:global_step/sec: 0.0217797\n",
            "I0410 17:52:19.479540 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217797\n",
            "INFO:tensorflow:examples/sec: 0.696951\n",
            "I0410 17:52:19.479933 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696951\n",
            "INFO:tensorflow:global_step/sec: 0.0220186\n",
            "I0410 17:53:04.895753 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220186\n",
            "INFO:tensorflow:examples/sec: 0.704594\n",
            "I0410 17:53:04.896038 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704594\n",
            "INFO:tensorflow:global_step/sec: 0.0220883\n",
            "I0410 17:53:50.168539 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220883\n",
            "INFO:tensorflow:examples/sec: 0.706827\n",
            "I0410 17:53:50.168962 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706827\n",
            "INFO:tensorflow:global_step/sec: 0.0218583\n",
            "I0410 17:54:35.917787 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218583\n",
            "INFO:tensorflow:examples/sec: 0.699465\n",
            "I0410 17:54:35.918899 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699465\n",
            "INFO:tensorflow:global_step/sec: 0.0218682\n",
            "I0410 17:55:21.646346 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218682\n",
            "INFO:tensorflow:examples/sec: 0.699781\n",
            "I0410 17:55:21.646635 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699781\n",
            "INFO:tensorflow:global_step/sec: 0.0220779\n",
            "I0410 17:56:06.940485 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220779\n",
            "INFO:tensorflow:examples/sec: 0.706493\n",
            "I0410 17:56:06.940968 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706493\n",
            "INFO:tensorflow:global_step/sec: 0.0219295\n",
            "I0410 17:56:52.541393 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219295\n",
            "INFO:tensorflow:examples/sec: 0.701745\n",
            "I0410 17:56:52.542828 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701745\n",
            "INFO:tensorflow:global_step/sec: 0.0219737\n",
            "I0410 17:57:38.049900 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219737\n",
            "INFO:tensorflow:examples/sec: 0.70316\n",
            "I0410 17:57:38.050406 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70316\n",
            "INFO:tensorflow:global_step/sec: 0.0218079\n",
            "I0410 17:58:23.904805 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218079\n",
            "INFO:tensorflow:examples/sec: 0.697854\n",
            "I0410 17:58:23.905086 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697854\n",
            "INFO:tensorflow:global_step/sec: 0.0217915\n",
            "I0410 17:59:09.794105 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217915\n",
            "INFO:tensorflow:examples/sec: 0.69733\n",
            "I0410 17:59:09.795326 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69733\n",
            "INFO:tensorflow:global_step/sec: 0.0215326\n",
            "I0410 17:59:56.235365 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215326\n",
            "INFO:tensorflow:examples/sec: 0.689043\n",
            "I0410 17:59:56.235792 140202582333312 tpu_estimator.py:2160] examples/sec: 0.689043\n",
            "INFO:tensorflow:Saving checkpoints for 1060 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 18:00:41.818072 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 1060 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0190409\n",
            "I0410 18:00:48.753872 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0190409\n",
            "INFO:tensorflow:examples/sec: 0.609308\n",
            "I0410 18:00:48.754321 140202582333312 tpu_estimator.py:2160] examples/sec: 0.609308\n",
            "INFO:tensorflow:global_step/sec: 0.0217096\n",
            "I0410 18:01:34.816676 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217096\n",
            "INFO:tensorflow:examples/sec: 0.694706\n",
            "I0410 18:01:34.818295 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694706\n",
            "INFO:tensorflow:global_step/sec: 0.0219377\n",
            "I0410 18:02:20.400305 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219377\n",
            "INFO:tensorflow:examples/sec: 0.702006\n",
            "I0410 18:02:20.400601 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702006\n",
            "INFO:tensorflow:global_step/sec: 0.0218655\n",
            "I0410 18:03:06.134504 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218655\n",
            "INFO:tensorflow:examples/sec: 0.699696\n",
            "I0410 18:03:06.134926 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699696\n",
            "INFO:tensorflow:global_step/sec: 0.0220654\n",
            "I0410 18:03:51.454440 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220654\n",
            "INFO:tensorflow:examples/sec: 0.706093\n",
            "I0410 18:03:51.454734 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706093\n",
            "INFO:tensorflow:global_step/sec: 0.022141\n",
            "I0410 18:04:36.619383 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022141\n",
            "INFO:tensorflow:examples/sec: 0.708513\n",
            "I0410 18:04:36.619771 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708513\n",
            "INFO:tensorflow:global_step/sec: 0.0220082\n",
            "I0410 18:05:22.056883 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220082\n",
            "INFO:tensorflow:examples/sec: 0.704262\n",
            "I0410 18:05:22.057297 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704262\n",
            "INFO:tensorflow:global_step/sec: 0.0218692\n",
            "I0410 18:06:07.783368 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218692\n",
            "INFO:tensorflow:examples/sec: 0.699814\n",
            "I0410 18:06:07.783672 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699814\n",
            "INFO:tensorflow:global_step/sec: 0.0219123\n",
            "I0410 18:06:53.419876 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219123\n",
            "INFO:tensorflow:examples/sec: 0.701192\n",
            "I0410 18:06:53.420318 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701192\n",
            "INFO:tensorflow:global_step/sec: 0.0220709\n",
            "I0410 18:07:38.728354 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220709\n",
            "INFO:tensorflow:examples/sec: 0.70627\n",
            "I0410 18:07:38.728789 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70627\n",
            "INFO:tensorflow:global_step/sec: 0.022025\n",
            "I0410 18:08:24.131276 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022025\n",
            "INFO:tensorflow:examples/sec: 0.704801\n",
            "I0410 18:08:24.132725 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704801\n",
            "INFO:tensorflow:global_step/sec: 0.0219235\n",
            "I0410 18:09:09.744336 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219235\n",
            "INFO:tensorflow:examples/sec: 0.701553\n",
            "I0410 18:09:09.744680 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701553\n",
            "INFO:tensorflow:global_step/sec: 0.0219991\n",
            "I0410 18:09:55.200802 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219991\n",
            "INFO:tensorflow:examples/sec: 0.70397\n",
            "I0410 18:09:55.201187 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70397\n",
            "INFO:tensorflow:global_step/sec: 0.0221451\n",
            "I0410 18:10:40.357539 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221451\n",
            "INFO:tensorflow:examples/sec: 0.708643\n",
            "I0410 18:10:40.357815 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708643\n",
            "INFO:tensorflow:global_step/sec: 0.0220275\n",
            "I0410 18:11:25.755279 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220275\n",
            "INFO:tensorflow:examples/sec: 0.704881\n",
            "I0410 18:11:25.755800 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704881\n",
            "INFO:tensorflow:global_step/sec: 0.0219915\n",
            "I0410 18:12:11.227475 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219915\n",
            "INFO:tensorflow:examples/sec: 0.703727\n",
            "I0410 18:12:11.227898 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703727\n",
            "INFO:tensorflow:global_step/sec: 0.0220122\n",
            "I0410 18:12:56.656752 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220122\n",
            "INFO:tensorflow:examples/sec: 0.704392\n",
            "I0410 18:12:56.658348 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704392\n",
            "INFO:tensorflow:global_step/sec: 0.0220709\n",
            "I0410 18:13:41.965329 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220709\n",
            "INFO:tensorflow:examples/sec: 0.706268\n",
            "I0410 18:13:41.965762 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706268\n",
            "INFO:tensorflow:global_step/sec: 0.0217897\n",
            "I0410 18:14:27.858843 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217897\n",
            "INFO:tensorflow:examples/sec: 0.697269\n",
            "I0410 18:14:27.859179 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697269\n",
            "INFO:tensorflow:global_step/sec: 0.0221299\n",
            "I0410 18:15:13.046392 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221299\n",
            "INFO:tensorflow:examples/sec: 0.708157\n",
            "I0410 18:15:13.046670 140202582333312 tpu_estimator.py:2160] examples/sec: 0.708157\n",
            "INFO:tensorflow:Saving checkpoints for 1080 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 18:15:58.255608 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 1080 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0191507\n",
            "I0410 18:16:05.263820 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0191507\n",
            "INFO:tensorflow:examples/sec: 0.612821\n",
            "I0410 18:16:05.264291 140202582333312 tpu_estimator.py:2160] examples/sec: 0.612821\n",
            "INFO:tensorflow:global_step/sec: 0.02147\n",
            "I0410 18:16:51.840462 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.02147\n",
            "INFO:tensorflow:examples/sec: 0.68704\n",
            "I0410 18:16:51.840761 140202582333312 tpu_estimator.py:2160] examples/sec: 0.68704\n",
            "INFO:tensorflow:global_step/sec: 0.0220581\n",
            "I0410 18:17:37.175260 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220581\n",
            "INFO:tensorflow:examples/sec: 0.70586\n",
            "I0410 18:17:37.176857 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70586\n",
            "INFO:tensorflow:global_step/sec: 0.0221604\n",
            "I0410 18:18:22.300839 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221604\n",
            "INFO:tensorflow:examples/sec: 0.709132\n",
            "I0410 18:18:22.301107 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709132\n",
            "INFO:tensorflow:global_step/sec: 0.0218389\n",
            "I0410 18:19:08.090692 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218389\n",
            "INFO:tensorflow:examples/sec: 0.698845\n",
            "I0410 18:19:08.091011 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698845\n",
            "INFO:tensorflow:global_step/sec: 0.0221603\n",
            "I0410 18:19:53.216467 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221603\n",
            "INFO:tensorflow:examples/sec: 0.709128\n",
            "I0410 18:19:53.216749 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709128\n",
            "INFO:tensorflow:global_step/sec: 0.0219356\n",
            "I0410 18:20:38.804532 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219356\n",
            "INFO:tensorflow:examples/sec: 0.701938\n",
            "I0410 18:20:38.804957 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701938\n",
            "INFO:tensorflow:global_step/sec: 0.0220374\n",
            "I0410 18:21:24.182004 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220374\n",
            "INFO:tensorflow:examples/sec: 0.705196\n",
            "I0410 18:21:24.182455 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705196\n",
            "INFO:tensorflow:global_step/sec: 0.0219406\n",
            "I0410 18:22:09.759674 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219406\n",
            "INFO:tensorflow:examples/sec: 0.702099\n",
            "I0410 18:22:09.761165 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702099\n",
            "INFO:tensorflow:global_step/sec: 0.0215624\n",
            "I0410 18:22:56.136631 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215624\n",
            "INFO:tensorflow:examples/sec: 0.689998\n",
            "I0410 18:22:56.137091 140202582333312 tpu_estimator.py:2160] examples/sec: 0.689998\n",
            "INFO:tensorflow:global_step/sec: 0.0219649\n",
            "I0410 18:23:41.663886 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219649\n",
            "INFO:tensorflow:examples/sec: 0.702876\n",
            "I0410 18:23:41.664303 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702876\n",
            "INFO:tensorflow:global_step/sec: 0.0216486\n",
            "I0410 18:24:27.856254 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216486\n",
            "INFO:tensorflow:examples/sec: 0.692755\n",
            "I0410 18:24:27.856536 140202582333312 tpu_estimator.py:2160] examples/sec: 0.692755\n",
            "INFO:tensorflow:global_step/sec: 0.02177\n",
            "I0410 18:25:13.790989 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.02177\n",
            "INFO:tensorflow:examples/sec: 0.696641\n",
            "I0410 18:25:13.791291 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696641\n",
            "INFO:tensorflow:global_step/sec: 0.0218475\n",
            "I0410 18:25:59.562766 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218475\n",
            "INFO:tensorflow:examples/sec: 0.699121\n",
            "I0410 18:25:59.563059 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699121\n",
            "INFO:tensorflow:global_step/sec: 0.0218639\n",
            "I0410 18:26:45.300212 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218639\n",
            "INFO:tensorflow:examples/sec: 0.699645\n",
            "I0410 18:26:45.301687 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699645\n",
            "INFO:tensorflow:global_step/sec: 0.0218092\n",
            "I0410 18:27:31.152366 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218092\n",
            "INFO:tensorflow:examples/sec: 0.697895\n",
            "I0410 18:27:31.152801 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697895\n",
            "INFO:tensorflow:global_step/sec: 0.0220734\n",
            "I0410 18:28:16.455671 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220734\n",
            "INFO:tensorflow:examples/sec: 0.70635\n",
            "I0410 18:28:16.456093 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70635\n",
            "INFO:tensorflow:global_step/sec: 0.022111\n",
            "I0410 18:29:01.682341 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022111\n",
            "INFO:tensorflow:examples/sec: 0.707552\n",
            "I0410 18:29:01.683764 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707552\n",
            "INFO:tensorflow:global_step/sec: 0.0218557\n",
            "I0410 18:29:47.436748 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218557\n",
            "INFO:tensorflow:examples/sec: 0.699381\n",
            "I0410 18:29:47.437077 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699381\n",
            "INFO:tensorflow:global_step/sec: 0.0220453\n",
            "I0410 18:30:32.797797 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220453\n",
            "INFO:tensorflow:examples/sec: 0.705451\n",
            "I0410 18:30:32.798063 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705451\n",
            "INFO:tensorflow:Saving checkpoints for 1100 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 18:31:18.104438 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 1100 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0189973\n",
            "I0410 18:31:25.436717 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0189973\n",
            "INFO:tensorflow:examples/sec: 0.607915\n",
            "I0410 18:31:25.437029 140202582333312 tpu_estimator.py:2160] examples/sec: 0.607915\n",
            "INFO:tensorflow:global_step/sec: 0.0214197\n",
            "I0410 18:32:12.122829 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0214197\n",
            "INFO:tensorflow:examples/sec: 0.68543\n",
            "I0410 18:32:12.123229 140202582333312 tpu_estimator.py:2160] examples/sec: 0.68543\n",
            "INFO:tensorflow:global_step/sec: 0.0218831\n",
            "I0410 18:32:57.820127 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218831\n",
            "INFO:tensorflow:examples/sec: 0.70026\n",
            "I0410 18:32:57.820428 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70026\n",
            "INFO:tensorflow:global_step/sec: 0.0217652\n",
            "I0410 18:33:43.765068 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217652\n",
            "INFO:tensorflow:examples/sec: 0.696486\n",
            "I0410 18:33:43.766249 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696486\n",
            "INFO:tensorflow:global_step/sec: 0.0219532\n",
            "I0410 18:34:29.316428 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219532\n",
            "INFO:tensorflow:examples/sec: 0.702504\n",
            "I0410 18:34:29.316717 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702504\n",
            "INFO:tensorflow:global_step/sec: 0.0217339\n",
            "I0410 18:35:15.327626 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217339\n",
            "INFO:tensorflow:examples/sec: 0.695483\n",
            "I0410 18:35:15.328034 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695483\n",
            "INFO:tensorflow:global_step/sec: 0.0217\n",
            "I0410 18:36:01.410782 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217\n",
            "INFO:tensorflow:examples/sec: 0.694399\n",
            "I0410 18:36:01.412056 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694399\n",
            "INFO:tensorflow:global_step/sec: 0.0218808\n",
            "I0410 18:36:47.112734 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218808\n",
            "INFO:tensorflow:examples/sec: 0.700187\n",
            "I0410 18:36:47.113195 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700187\n",
            "INFO:tensorflow:global_step/sec: 0.0215417\n",
            "I0410 18:37:33.534337 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215417\n",
            "INFO:tensorflow:examples/sec: 0.689334\n",
            "I0410 18:37:33.534781 140202582333312 tpu_estimator.py:2160] examples/sec: 0.689334\n",
            "INFO:tensorflow:global_step/sec: 0.0217112\n",
            "I0410 18:38:19.593519 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217112\n",
            "INFO:tensorflow:examples/sec: 0.694758\n",
            "I0410 18:38:19.594729 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694758\n",
            "INFO:tensorflow:global_step/sec: 0.0218095\n",
            "I0410 18:39:05.445210 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218095\n",
            "INFO:tensorflow:examples/sec: 0.697903\n",
            "I0410 18:39:05.445631 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697903\n",
            "INFO:tensorflow:global_step/sec: 0.0219369\n",
            "I0410 18:39:51.030429 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219369\n",
            "INFO:tensorflow:examples/sec: 0.701981\n",
            "I0410 18:39:51.030879 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701981\n",
            "INFO:tensorflow:global_step/sec: 0.0220011\n",
            "I0410 18:40:36.482752 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220011\n",
            "INFO:tensorflow:examples/sec: 0.704035\n",
            "I0410 18:40:36.485052 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704035\n",
            "INFO:tensorflow:global_step/sec: 0.0220571\n",
            "I0410 18:41:21.819668 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220571\n",
            "INFO:tensorflow:examples/sec: 0.705827\n",
            "I0410 18:41:21.820119 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705827\n",
            "INFO:tensorflow:global_step/sec: 0.021961\n",
            "I0410 18:42:07.355017 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021961\n",
            "INFO:tensorflow:examples/sec: 0.702751\n",
            "I0410 18:42:07.355515 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702751\n",
            "INFO:tensorflow:global_step/sec: 0.0216018\n",
            "I0410 18:42:53.647518 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216018\n",
            "INFO:tensorflow:examples/sec: 0.691256\n",
            "I0410 18:42:53.648683 140202582333312 tpu_estimator.py:2160] examples/sec: 0.691256\n",
            "INFO:tensorflow:global_step/sec: 0.0218112\n",
            "I0410 18:43:39.495595 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218112\n",
            "INFO:tensorflow:examples/sec: 0.697957\n",
            "I0410 18:43:39.496018 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697957\n",
            "INFO:tensorflow:global_step/sec: 0.0217554\n",
            "I0410 18:44:25.461167 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217554\n",
            "INFO:tensorflow:examples/sec: 0.696174\n",
            "I0410 18:44:25.461601 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696174\n",
            "INFO:tensorflow:global_step/sec: 0.0220332\n",
            "I0410 18:45:10.847122 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220332\n",
            "INFO:tensorflow:examples/sec: 0.705063\n",
            "I0410 18:45:10.848630 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705063\n",
            "INFO:tensorflow:global_step/sec: 0.0219777\n",
            "I0410 18:45:56.347805 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219777\n",
            "INFO:tensorflow:examples/sec: 0.703287\n",
            "I0410 18:45:56.348261 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703287\n",
            "INFO:tensorflow:Saving checkpoints for 1120 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 18:46:41.913146 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 1120 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.018727\n",
            "I0410 18:46:49.746528 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.018727\n",
            "INFO:tensorflow:examples/sec: 0.599264\n",
            "I0410 18:46:49.746921 140202582333312 tpu_estimator.py:2160] examples/sec: 0.599264\n",
            "INFO:tensorflow:global_step/sec: 0.0214954\n",
            "I0410 18:47:36.268173 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0214954\n",
            "INFO:tensorflow:examples/sec: 0.687853\n",
            "I0410 18:47:36.268462 140202582333312 tpu_estimator.py:2160] examples/sec: 0.687853\n",
            "INFO:tensorflow:global_step/sec: 0.0217933\n",
            "I0410 18:48:22.153848 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217933\n",
            "INFO:tensorflow:examples/sec: 0.697385\n",
            "I0410 18:48:22.154296 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697385\n",
            "INFO:tensorflow:global_step/sec: 0.0221571\n",
            "I0410 18:49:07.286112 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221571\n",
            "INFO:tensorflow:examples/sec: 0.709026\n",
            "I0410 18:49:07.286585 140202582333312 tpu_estimator.py:2160] examples/sec: 0.709026\n",
            "INFO:tensorflow:global_step/sec: 0.0219814\n",
            "I0410 18:49:52.779214 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219814\n",
            "INFO:tensorflow:examples/sec: 0.703404\n",
            "I0410 18:49:52.780749 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703404\n",
            "INFO:tensorflow:global_step/sec: 0.0218474\n",
            "I0410 18:50:38.551168 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218474\n",
            "INFO:tensorflow:examples/sec: 0.699118\n",
            "I0410 18:50:38.551673 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699118\n",
            "INFO:tensorflow:global_step/sec: 0.0215144\n",
            "I0410 18:51:25.031590 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215144\n",
            "INFO:tensorflow:examples/sec: 0.688462\n",
            "I0410 18:51:25.032066 140202582333312 tpu_estimator.py:2160] examples/sec: 0.688462\n",
            "INFO:tensorflow:global_step/sec: 0.0218744\n",
            "I0410 18:52:10.747048 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218744\n",
            "INFO:tensorflow:examples/sec: 0.699982\n",
            "I0410 18:52:10.748641 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699982\n",
            "INFO:tensorflow:global_step/sec: 0.0216803\n",
            "I0410 18:52:56.871934 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216803\n",
            "INFO:tensorflow:examples/sec: 0.693769\n",
            "I0410 18:52:56.872225 140202582333312 tpu_estimator.py:2160] examples/sec: 0.693769\n",
            "INFO:tensorflow:global_step/sec: 0.0215493\n",
            "I0410 18:53:43.277031 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215493\n",
            "INFO:tensorflow:examples/sec: 0.689578\n",
            "I0410 18:53:43.277515 140202582333312 tpu_estimator.py:2160] examples/sec: 0.689578\n",
            "INFO:tensorflow:global_step/sec: 0.021718\n",
            "I0410 18:54:29.321814 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021718\n",
            "INFO:tensorflow:examples/sec: 0.694976\n",
            "I0410 18:54:29.322086 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694976\n",
            "INFO:tensorflow:global_step/sec: 0.0218768\n",
            "I0410 18:55:15.032418 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218768\n",
            "INFO:tensorflow:examples/sec: 0.700057\n",
            "I0410 18:55:15.032863 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700057\n",
            "INFO:tensorflow:global_step/sec: 0.0215929\n",
            "I0410 18:56:01.343825 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215929\n",
            "INFO:tensorflow:examples/sec: 0.690974\n",
            "I0410 18:56:01.344347 140202582333312 tpu_estimator.py:2160] examples/sec: 0.690974\n",
            "INFO:tensorflow:global_step/sec: 0.0218913\n",
            "I0410 18:56:47.024030 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218913\n",
            "INFO:tensorflow:examples/sec: 0.700521\n",
            "I0410 18:56:47.025664 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700521\n",
            "INFO:tensorflow:global_step/sec: 0.0221066\n",
            "I0410 18:57:32.259369 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221066\n",
            "INFO:tensorflow:examples/sec: 0.707412\n",
            "I0410 18:57:32.259786 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707412\n",
            "INFO:tensorflow:global_step/sec: 0.0220921\n",
            "I0410 18:58:17.524482 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220921\n",
            "INFO:tensorflow:examples/sec: 0.706946\n",
            "I0410 18:58:17.524918 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706946\n",
            "INFO:tensorflow:global_step/sec: 0.0218629\n",
            "I0410 18:59:03.264163 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218629\n",
            "INFO:tensorflow:examples/sec: 0.699611\n",
            "I0410 18:59:03.265370 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699611\n",
            "INFO:tensorflow:global_step/sec: 0.0220442\n",
            "I0410 18:59:48.627447 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220442\n",
            "INFO:tensorflow:examples/sec: 0.705416\n",
            "I0410 18:59:48.627729 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705416\n",
            "INFO:tensorflow:global_step/sec: 0.0221923\n",
            "I0410 19:00:33.688564 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221923\n",
            "INFO:tensorflow:examples/sec: 0.710152\n",
            "I0410 19:00:33.688998 140202582333312 tpu_estimator.py:2160] examples/sec: 0.710152\n",
            "INFO:tensorflow:global_step/sec: 0.0218183\n",
            "I0410 19:01:19.521409 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218183\n",
            "INFO:tensorflow:examples/sec: 0.698184\n",
            "I0410 19:01:19.522649 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698184\n",
            "INFO:tensorflow:Saving checkpoints for 1140 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 19:02:04.838871 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 1140 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0187846\n",
            "I0410 19:02:12.756552 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0187846\n",
            "INFO:tensorflow:examples/sec: 0.601106\n",
            "I0410 19:02:12.756948 140202582333312 tpu_estimator.py:2160] examples/sec: 0.601106\n",
            "INFO:tensorflow:global_step/sec: 0.0212068\n",
            "I0410 19:02:59.911270 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0212068\n",
            "INFO:tensorflow:examples/sec: 0.678618\n",
            "I0410 19:02:59.911739 140202582333312 tpu_estimator.py:2160] examples/sec: 0.678618\n",
            "INFO:tensorflow:global_step/sec: 0.0220719\n",
            "I0410 19:03:45.217790 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220719\n",
            "INFO:tensorflow:examples/sec: 0.7063\n",
            "I0410 19:03:45.218936 140202582333312 tpu_estimator.py:2160] examples/sec: 0.7063\n",
            "INFO:tensorflow:global_step/sec: 0.022037\n",
            "I0410 19:04:30.596035 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022037\n",
            "INFO:tensorflow:examples/sec: 0.705185\n",
            "I0410 19:04:30.596475 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705185\n",
            "INFO:tensorflow:global_step/sec: 0.0219795\n",
            "I0410 19:05:16.092859 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219795\n",
            "INFO:tensorflow:examples/sec: 0.703345\n",
            "I0410 19:05:16.093276 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703345\n",
            "INFO:tensorflow:global_step/sec: 0.0218425\n",
            "I0410 19:06:01.875337 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218425\n",
            "INFO:tensorflow:examples/sec: 0.698958\n",
            "I0410 19:06:01.876801 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698958\n",
            "INFO:tensorflow:global_step/sec: 0.0220349\n",
            "I0410 19:06:47.257909 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220349\n",
            "INFO:tensorflow:examples/sec: 0.705117\n",
            "I0410 19:06:47.258208 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705117\n",
            "INFO:tensorflow:global_step/sec: 0.0219501\n",
            "I0410 19:07:32.815706 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219501\n",
            "INFO:tensorflow:examples/sec: 0.702402\n",
            "I0410 19:07:32.816114 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702402\n",
            "INFO:tensorflow:global_step/sec: 0.0218858\n",
            "I0410 19:08:18.507370 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218858\n",
            "INFO:tensorflow:examples/sec: 0.700347\n",
            "I0410 19:08:18.508568 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700347\n",
            "INFO:tensorflow:global_step/sec: 0.0220355\n",
            "I0410 19:09:03.888747 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220355\n",
            "INFO:tensorflow:examples/sec: 0.705135\n",
            "I0410 19:09:03.889215 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705135\n",
            "INFO:tensorflow:global_step/sec: 0.0219663\n",
            "I0410 19:09:49.412971 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219663\n",
            "INFO:tensorflow:examples/sec: 0.702922\n",
            "I0410 19:09:49.413450 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702922\n",
            "INFO:tensorflow:global_step/sec: 0.0217868\n",
            "I0410 19:10:35.312409 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217868\n",
            "INFO:tensorflow:examples/sec: 0.697178\n",
            "I0410 19:10:35.313819 140202582333312 tpu_estimator.py:2160] examples/sec: 0.697178\n",
            "INFO:tensorflow:global_step/sec: 0.0216999\n",
            "I0410 19:11:21.395461 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216999\n",
            "INFO:tensorflow:examples/sec: 0.694397\n",
            "I0410 19:11:21.395985 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694397\n",
            "INFO:tensorflow:global_step/sec: 0.0219643\n",
            "I0410 19:12:06.923850 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219643\n",
            "INFO:tensorflow:examples/sec: 0.702859\n",
            "I0410 19:12:06.924291 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702859\n",
            "INFO:tensorflow:global_step/sec: 0.02187\n",
            "I0410 19:12:52.648668 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.02187\n",
            "INFO:tensorflow:examples/sec: 0.699839\n",
            "I0410 19:12:52.650161 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699839\n",
            "INFO:tensorflow:global_step/sec: 0.0216781\n",
            "I0410 19:13:38.778301 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216781\n",
            "INFO:tensorflow:examples/sec: 0.693698\n",
            "I0410 19:13:38.778782 140202582333312 tpu_estimator.py:2160] examples/sec: 0.693698\n",
            "INFO:tensorflow:global_step/sec: 0.021961\n",
            "I0410 19:14:24.313597 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021961\n",
            "INFO:tensorflow:examples/sec: 0.702751\n",
            "I0410 19:14:24.314022 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702751\n",
            "INFO:tensorflow:global_step/sec: 0.0218213\n",
            "I0410 19:15:10.140346 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218213\n",
            "INFO:tensorflow:examples/sec: 0.698283\n",
            "I0410 19:15:10.141651 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698283\n",
            "INFO:tensorflow:global_step/sec: 0.0218358\n",
            "I0410 19:15:55.936601 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218358\n",
            "INFO:tensorflow:examples/sec: 0.698747\n",
            "I0410 19:15:55.937043 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698747\n",
            "INFO:tensorflow:global_step/sec: 0.0219515\n",
            "I0410 19:16:41.491622 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219515\n",
            "INFO:tensorflow:examples/sec: 0.702447\n",
            "I0410 19:16:41.491910 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702447\n",
            "INFO:tensorflow:Saving checkpoints for 1160 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 19:17:28.034052 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 1160 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0183638\n",
            "I0410 19:17:35.946803 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0183638\n",
            "INFO:tensorflow:examples/sec: 0.587641\n",
            "I0410 19:17:35.947290 140202582333312 tpu_estimator.py:2160] examples/sec: 0.587641\n",
            "INFO:tensorflow:global_step/sec: 0.0215909\n",
            "I0410 19:18:22.262535 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215909\n",
            "INFO:tensorflow:examples/sec: 0.690908\n",
            "I0410 19:18:22.262978 140202582333312 tpu_estimator.py:2160] examples/sec: 0.690908\n",
            "INFO:tensorflow:global_step/sec: 0.021672\n",
            "I0410 19:19:08.404931 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021672\n",
            "INFO:tensorflow:examples/sec: 0.693505\n",
            "I0410 19:19:08.405354 140202582333312 tpu_estimator.py:2160] examples/sec: 0.693505\n",
            "INFO:tensorflow:global_step/sec: 0.0216914\n",
            "I0410 19:19:54.506272 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216914\n",
            "INFO:tensorflow:examples/sec: 0.694123\n",
            "I0410 19:19:54.506572 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694123\n",
            "INFO:tensorflow:global_step/sec: 0.0217116\n",
            "I0410 19:20:40.564626 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217116\n",
            "INFO:tensorflow:examples/sec: 0.69477\n",
            "I0410 19:20:40.565038 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69477\n",
            "INFO:tensorflow:global_step/sec: 0.0216577\n",
            "I0410 19:21:26.737647 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216577\n",
            "INFO:tensorflow:examples/sec: 0.693046\n",
            "I0410 19:21:26.737934 140202582333312 tpu_estimator.py:2160] examples/sec: 0.693046\n",
            "INFO:tensorflow:global_step/sec: 0.0218797\n",
            "I0410 19:22:12.442098 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218797\n",
            "INFO:tensorflow:examples/sec: 0.700152\n",
            "I0410 19:22:12.482445 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700152\n",
            "INFO:tensorflow:global_step/sec: 0.0220784\n",
            "I0410 19:22:57.735084 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220784\n",
            "INFO:tensorflow:examples/sec: 0.70651\n",
            "I0410 19:22:57.735509 140202582333312 tpu_estimator.py:2160] examples/sec: 0.70651\n",
            "INFO:tensorflow:global_step/sec: 0.0220474\n",
            "I0410 19:23:43.091825 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220474\n",
            "INFO:tensorflow:examples/sec: 0.705518\n",
            "I0410 19:23:43.092292 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705518\n",
            "INFO:tensorflow:global_step/sec: 0.0217479\n",
            "I0410 19:24:29.073295 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217479\n",
            "INFO:tensorflow:examples/sec: 0.695933\n",
            "I0410 19:24:29.074400 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695933\n",
            "INFO:tensorflow:global_step/sec: 0.0220034\n",
            "I0410 19:25:14.520798 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220034\n",
            "INFO:tensorflow:examples/sec: 0.704109\n",
            "I0410 19:25:14.521251 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704109\n",
            "INFO:tensorflow:global_step/sec: 0.02199\n",
            "I0410 19:25:59.995920 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.02199\n",
            "INFO:tensorflow:examples/sec: 0.703681\n",
            "I0410 19:25:59.996426 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703681\n",
            "INFO:tensorflow:global_step/sec: 0.0214923\n",
            "I0410 19:26:46.524276 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0214923\n",
            "INFO:tensorflow:examples/sec: 0.687753\n",
            "I0410 19:26:46.525726 140202582333312 tpu_estimator.py:2160] examples/sec: 0.687753\n",
            "INFO:tensorflow:global_step/sec: 0.0216911\n",
            "I0410 19:27:32.626018 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216911\n",
            "INFO:tensorflow:examples/sec: 0.694117\n",
            "I0410 19:27:32.626528 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694117\n",
            "INFO:tensorflow:global_step/sec: 0.0219476\n",
            "I0410 19:28:18.189081 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219476\n",
            "INFO:tensorflow:examples/sec: 0.702324\n",
            "I0410 19:28:18.189554 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702324\n",
            "INFO:tensorflow:global_step/sec: 0.0219522\n",
            "I0410 19:29:03.742618 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219522\n",
            "INFO:tensorflow:examples/sec: 0.702469\n",
            "I0410 19:29:03.743747 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702469\n",
            "INFO:tensorflow:global_step/sec: 0.0220071\n",
            "I0410 19:29:49.182576 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220071\n",
            "INFO:tensorflow:examples/sec: 0.704226\n",
            "I0410 19:29:49.183038 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704226\n",
            "INFO:tensorflow:global_step/sec: 0.0215934\n",
            "I0410 19:30:35.493480 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215934\n",
            "INFO:tensorflow:examples/sec: 0.690988\n",
            "I0410 19:30:35.493920 140202582333312 tpu_estimator.py:2160] examples/sec: 0.690988\n",
            "INFO:tensorflow:global_step/sec: 0.0216991\n",
            "I0410 19:31:21.577871 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216991\n",
            "INFO:tensorflow:examples/sec: 0.694373\n",
            "I0410 19:31:21.579489 140202582333312 tpu_estimator.py:2160] examples/sec: 0.694373\n",
            "INFO:tensorflow:global_step/sec: 0.0220526\n",
            "I0410 19:32:06.924081 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220526\n",
            "INFO:tensorflow:examples/sec: 0.705682\n",
            "I0410 19:32:06.924483 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705682\n",
            "INFO:tensorflow:Saving checkpoints for 1180 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 19:32:52.441048 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 1180 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0189127\n",
            "I0410 19:32:59.798597 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0189127\n",
            "INFO:tensorflow:examples/sec: 0.605206\n",
            "I0410 19:32:59.798949 140202582333312 tpu_estimator.py:2160] examples/sec: 0.605206\n",
            "INFO:tensorflow:global_step/sec: 0.021418\n",
            "I0410 19:33:46.488316 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021418\n",
            "INFO:tensorflow:examples/sec: 0.685376\n",
            "I0410 19:33:46.489414 140202582333312 tpu_estimator.py:2160] examples/sec: 0.685376\n",
            "INFO:tensorflow:global_step/sec: 0.0217088\n",
            "I0410 19:34:32.552671 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217088\n",
            "INFO:tensorflow:examples/sec: 0.69468\n",
            "I0410 19:34:32.553015 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69468\n",
            "INFO:tensorflow:global_step/sec: 0.0219248\n",
            "I0410 19:35:18.163238 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219248\n",
            "INFO:tensorflow:examples/sec: 0.701592\n",
            "I0410 19:35:18.163510 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701592\n",
            "INFO:tensorflow:global_step/sec: 0.0216222\n",
            "I0410 19:36:04.412062 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216222\n",
            "INFO:tensorflow:examples/sec: 0.69191\n",
            "I0410 19:36:04.412367 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69191\n",
            "INFO:tensorflow:global_step/sec: 0.021871\n",
            "I0410 19:36:50.134656 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021871\n",
            "INFO:tensorflow:examples/sec: 0.699873\n",
            "I0410 19:36:50.134931 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699873\n",
            "INFO:tensorflow:global_step/sec: 0.021728\n",
            "I0410 19:37:36.158324 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021728\n",
            "INFO:tensorflow:examples/sec: 0.695295\n",
            "I0410 19:37:36.158793 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695295\n",
            "INFO:tensorflow:global_step/sec: 0.0218711\n",
            "I0410 19:38:21.880986 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218711\n",
            "INFO:tensorflow:examples/sec: 0.699874\n",
            "I0410 19:38:21.882156 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699874\n",
            "INFO:tensorflow:global_step/sec: 0.0216591\n",
            "I0410 19:39:08.050879 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216591\n",
            "INFO:tensorflow:examples/sec: 0.69309\n",
            "I0410 19:39:08.051332 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69309\n",
            "INFO:tensorflow:global_step/sec: 0.0217759\n",
            "I0410 19:39:53.973147 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217759\n",
            "INFO:tensorflow:examples/sec: 0.69683\n",
            "I0410 19:39:53.973500 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69683\n",
            "INFO:tensorflow:global_step/sec: 0.0214977\n",
            "I0410 19:40:40.489610 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0214977\n",
            "INFO:tensorflow:examples/sec: 0.687927\n",
            "I0410 19:40:40.490006 140202582333312 tpu_estimator.py:2160] examples/sec: 0.687927\n",
            "INFO:tensorflow:global_step/sec: 0.0218416\n",
            "I0410 19:41:26.273853 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218416\n",
            "INFO:tensorflow:examples/sec: 0.698932\n",
            "I0410 19:41:26.274287 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698932\n",
            "INFO:tensorflow:global_step/sec: 0.0218932\n",
            "I0410 19:42:11.950209 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218932\n",
            "INFO:tensorflow:examples/sec: 0.700582\n",
            "I0410 19:42:11.950674 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700582\n",
            "INFO:tensorflow:global_step/sec: 0.0219293\n",
            "I0410 19:42:57.551163 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219293\n",
            "INFO:tensorflow:examples/sec: 0.701739\n",
            "I0410 19:42:57.552258 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701739\n",
            "INFO:tensorflow:global_step/sec: 0.0220361\n",
            "I0410 19:43:42.931326 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220361\n",
            "INFO:tensorflow:examples/sec: 0.705154\n",
            "I0410 19:43:42.931917 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705154\n",
            "INFO:tensorflow:global_step/sec: 0.0221163\n",
            "I0410 19:44:28.146914 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221163\n",
            "INFO:tensorflow:examples/sec: 0.707721\n",
            "I0410 19:44:28.147413 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707721\n",
            "INFO:tensorflow:global_step/sec: 0.0220218\n",
            "I0410 19:45:13.556368 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220218\n",
            "INFO:tensorflow:examples/sec: 0.704699\n",
            "I0410 19:45:13.557552 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704699\n",
            "INFO:tensorflow:global_step/sec: 0.0218407\n",
            "I0410 19:45:59.342533 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218407\n",
            "INFO:tensorflow:examples/sec: 0.698901\n",
            "I0410 19:45:59.342838 140202582333312 tpu_estimator.py:2160] examples/sec: 0.698901\n",
            "INFO:tensorflow:global_step/sec: 0.021771\n",
            "I0410 19:46:45.275171 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021771\n",
            "INFO:tensorflow:examples/sec: 0.696672\n",
            "I0410 19:46:45.275591 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696672\n",
            "INFO:tensorflow:global_step/sec: 0.0221014\n",
            "I0410 19:47:30.521106 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0221014\n",
            "INFO:tensorflow:examples/sec: 0.707246\n",
            "I0410 19:47:30.522551 140202582333312 tpu_estimator.py:2160] examples/sec: 0.707246\n",
            "INFO:tensorflow:Saving checkpoints for 1200 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 19:48:16.414616 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 1200 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.0189309\n",
            "I0410 19:48:23.344750 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0189309\n",
            "INFO:tensorflow:examples/sec: 0.605789\n",
            "I0410 19:48:23.345024 140202582333312 tpu_estimator.py:2160] examples/sec: 0.605789\n",
            "INFO:tensorflow:global_step/sec: 0.0214936\n",
            "I0410 19:49:09.870337 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0214936\n",
            "INFO:tensorflow:examples/sec: 0.687794\n",
            "I0410 19:49:09.870780 140202582333312 tpu_estimator.py:2160] examples/sec: 0.687794\n",
            "INFO:tensorflow:global_step/sec: 0.021859\n",
            "I0410 19:49:55.618174 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.021859\n",
            "INFO:tensorflow:examples/sec: 0.699487\n",
            "I0410 19:49:55.618451 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699487\n",
            "INFO:tensorflow:global_step/sec: 0.0218585\n",
            "I0410 19:50:41.366843 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218585\n",
            "INFO:tensorflow:examples/sec: 0.699473\n",
            "I0410 19:50:41.367276 140202582333312 tpu_estimator.py:2160] examples/sec: 0.699473\n",
            "INFO:tensorflow:global_step/sec: 0.0218759\n",
            "I0410 19:51:27.079252 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218759\n",
            "INFO:tensorflow:examples/sec: 0.700029\n",
            "I0410 19:51:27.079669 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700029\n",
            "INFO:tensorflow:global_step/sec: 0.0217451\n",
            "I0410 19:52:13.066588 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217451\n",
            "INFO:tensorflow:examples/sec: 0.695844\n",
            "I0410 19:52:13.066936 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695844\n",
            "INFO:tensorflow:global_step/sec: 0.0218979\n",
            "I0410 19:52:58.733036 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218979\n",
            "INFO:tensorflow:examples/sec: 0.700733\n",
            "I0410 19:52:58.733583 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700733\n",
            "INFO:tensorflow:global_step/sec: 0.0220532\n",
            "I0410 19:53:44.077965 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220532\n",
            "INFO:tensorflow:examples/sec: 0.705702\n",
            "I0410 19:53:44.078413 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705702\n",
            "INFO:tensorflow:global_step/sec: 0.0220806\n",
            "I0410 19:54:29.366682 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220806\n",
            "INFO:tensorflow:examples/sec: 0.706578\n",
            "I0410 19:54:29.368054 140202582333312 tpu_estimator.py:2160] examples/sec: 0.706578\n",
            "INFO:tensorflow:global_step/sec: 0.02184\n",
            "I0410 19:55:15.154233 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.02184\n",
            "INFO:tensorflow:examples/sec: 0.69888\n",
            "I0410 19:55:15.154640 140202582333312 tpu_estimator.py:2160] examples/sec: 0.69888\n",
            "INFO:tensorflow:global_step/sec: 0.0220224\n",
            "I0410 19:56:00.562554 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220224\n",
            "INFO:tensorflow:examples/sec: 0.704716\n",
            "I0410 19:56:00.562927 140202582333312 tpu_estimator.py:2160] examples/sec: 0.704716\n",
            "INFO:tensorflow:global_step/sec: 0.0219692\n",
            "I0410 19:56:46.081101 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219692\n",
            "INFO:tensorflow:examples/sec: 0.703015\n",
            "I0410 19:56:46.081423 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703015\n",
            "INFO:tensorflow:global_step/sec: 0.0217713\n",
            "I0410 19:57:32.012837 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217713\n",
            "INFO:tensorflow:examples/sec: 0.696681\n",
            "I0410 19:57:32.013321 140202582333312 tpu_estimator.py:2160] examples/sec: 0.696681\n",
            "INFO:tensorflow:global_step/sec: 0.0217232\n",
            "I0410 19:58:18.046494 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217232\n",
            "INFO:tensorflow:examples/sec: 0.695144\n",
            "I0410 19:58:18.046813 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695144\n",
            "INFO:tensorflow:global_step/sec: 0.0218765\n",
            "I0410 19:59:03.757533 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0218765\n",
            "INFO:tensorflow:examples/sec: 0.700049\n",
            "I0410 19:59:03.757817 140202582333312 tpu_estimator.py:2160] examples/sec: 0.700049\n",
            "INFO:tensorflow:global_step/sec: 0.0219844\n",
            "I0410 19:59:49.244302 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219844\n",
            "INFO:tensorflow:examples/sec: 0.703502\n",
            "I0410 19:59:49.244574 140202582333312 tpu_estimator.py:2160] examples/sec: 0.703502\n",
            "INFO:tensorflow:global_step/sec: 0.0219395\n",
            "I0410 20:00:34.824306 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219395\n",
            "INFO:tensorflow:examples/sec: 0.702063\n",
            "I0410 20:00:34.824781 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702063\n",
            "INFO:tensorflow:global_step/sec: 0.022054\n",
            "I0410 20:01:20.167533 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.022054\n",
            "INFO:tensorflow:examples/sec: 0.705727\n",
            "I0410 20:01:20.168683 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705727\n",
            "INFO:tensorflow:global_step/sec: 0.0215384\n",
            "I0410 20:02:06.596357 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215384\n",
            "INFO:tensorflow:examples/sec: 0.689227\n",
            "I0410 20:02:06.596816 140202582333312 tpu_estimator.py:2160] examples/sec: 0.689227\n",
            "INFO:tensorflow:global_step/sec: 0.0215379\n",
            "I0410 20:02:53.026276 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215379\n",
            "INFO:tensorflow:examples/sec: 0.689211\n",
            "I0410 20:02:53.026692 140202582333312 tpu_estimator.py:2160] examples/sec: 0.689211\n",
            "INFO:tensorflow:Saving checkpoints for 1220 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 20:03:39.588350 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 1220 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.018679\n",
            "I0410 20:03:46.562236 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.018679\n",
            "INFO:tensorflow:examples/sec: 0.597729\n",
            "I0410 20:03:46.562585 140202582333312 tpu_estimator.py:2160] examples/sec: 0.597729\n",
            "INFO:tensorflow:global_step/sec: 0.0215114\n",
            "I0410 20:04:33.049083 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215114\n",
            "INFO:tensorflow:examples/sec: 0.688366\n",
            "I0410 20:04:33.049499 140202582333312 tpu_estimator.py:2160] examples/sec: 0.688366\n",
            "INFO:tensorflow:global_step/sec: 0.0220451\n",
            "I0410 20:05:18.410669 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0220451\n",
            "INFO:tensorflow:examples/sec: 0.705443\n",
            "I0410 20:05:18.411007 140202582333312 tpu_estimator.py:2160] examples/sec: 0.705443\n",
            "INFO:tensorflow:global_step/sec: 0.0219156\n",
            "I0410 20:06:04.040225 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219156\n",
            "INFO:tensorflow:examples/sec: 0.701301\n",
            "I0410 20:06:04.041664 140202582333312 tpu_estimator.py:2160] examples/sec: 0.701301\n",
            "INFO:tensorflow:global_step/sec: 0.0215012\n",
            "I0410 20:06:50.549122 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0215012\n",
            "INFO:tensorflow:examples/sec: 0.688039\n",
            "I0410 20:06:50.549431 140202582333312 tpu_estimator.py:2160] examples/sec: 0.688039\n",
            "INFO:tensorflow:global_step/sec: 0.0219431\n",
            "I0410 20:07:36.121563 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0219431\n",
            "INFO:tensorflow:examples/sec: 0.702179\n",
            "I0410 20:07:36.121969 140202582333312 tpu_estimator.py:2160] examples/sec: 0.702179\n",
            "INFO:tensorflow:global_step/sec: 0.0217268\n",
            "I0410 20:08:22.147626 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0217268\n",
            "INFO:tensorflow:examples/sec: 0.695259\n",
            "I0410 20:08:22.148816 140202582333312 tpu_estimator.py:2160] examples/sec: 0.695259\n",
            "INFO:tensorflow:global_step/sec: 0.0216129\n",
            "I0410 20:09:08.416276 140202582333312 tpu_estimator.py:2159] global_step/sec: 0.0216129\n",
            "INFO:tensorflow:examples/sec: 0.691613\n",
            "I0410 20:09:08.416700 140202582333312 tpu_estimator.py:2160] examples/sec: 0.691613\n",
            "INFO:tensorflow:Saving checkpoints for 1227 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "I0410 20:09:08.417168 140202582333312 basic_session_run_hooks.py:606] Saving checkpoints for 1227 into drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.28140703.\n",
            "I0410 20:09:17.038258 140202582333312 estimator.py:368] Loss for final step: 0.28140703.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "I0410 20:09:17.052431 140202582333312 error_handling.py:96] training_loop marked as finished\n",
            "INFO:tensorflow:Writing example 0 of 1636\n",
            "I0410 20:09:17.590818 140202582333312 run_classifier.py:499] Writing example 0 of 1636\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0410 20:09:17.593852 140202582333312 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: dev-0\n",
            "I0410 20:09:17.594091 140202582333312 run_classifier.py:475] guid: dev-0\n",
            "INFO:tensorflow:tokens: [CLS] 업데이트 ##후 실시간 ##방송 채널 ##변 ##경 ##이 불편 ##해 ##졌 ##어 ##요 ##. [SEP]\n",
            "I0410 20:09:17.594295 140202582333312 run_classifier.py:477] tokens: [CLS] 업데이트 ##후 실시간 ##방송 채널 ##변 ##경 ##이 불편 ##해 ##졌 ##어 ##요 ##. [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4597 5914 2349 14344 1392 7272 2621 1291 2171 3074 6915 2479 5721 37606 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.594570 140202582333312 run_classifier.py:478] input_ids: 101 4597 5914 2349 14344 1392 7272 2621 1291 2171 3074 6915 2479 5721 37606 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.594725 140202582333312 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.594899 140202582333312 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "I0410 20:09:17.595010 140202582333312 run_classifier.py:481] label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0410 20:09:17.595723 140202582333312 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: dev-1\n",
            "I0410 20:09:17.595885 140202582333312 run_classifier.py:475] guid: dev-1\n",
            "INFO:tensorflow:tokens: [CLS] 댓글 ##기능 부활 ##시 ##켜 ##주 ##세 ##요 ##. [SEP]\n",
            "I0410 20:09:17.595996 140202582333312 run_classifier.py:477] tokens: [CLS] 댓글 ##기능 부활 ##시 ##켜 ##주 ##세 ##요 ##. [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1061 29913 4341 1468 12997 1510 2960 5721 37606 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.596175 140202582333312 run_classifier.py:478] input_ids: 101 1061 29913 4341 1468 12997 1510 2960 5721 37606 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.596328 140202582333312 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.596473 140202582333312 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "I0410 20:09:17.596564 140202582333312 run_classifier.py:481] label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0410 20:09:17.597146 140202582333312 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: dev-2\n",
            "I0410 20:09:17.597288 140202582333312 run_classifier.py:475] guid: dev-2\n",
            "INFO:tensorflow:tokens: [CLS] 업데이트 ##하 ##고 왜 공중 ##파 방송이 없 ##죠 ##? ##? ##? [SEP]\n",
            "I0410 20:09:17.597398 140202582333312 run_classifier.py:477] tokens: [CLS] 업데이트 ##하 ##고 왜 공중 ##파 방송이 없 ##죠 ##? ##? ##? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4597 2283 1590 1407 6843 2623 46509 181 32059 20689 20689 20689 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.597542 140202582333312 run_classifier.py:478] input_ids: 101 4597 2283 1590 1407 6843 2623 46509 181 32059 20689 20689 20689 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.597685 140202582333312 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.597824 140202582333312 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0410 20:09:17.597913 140202582333312 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0410 20:09:17.598654 140202582333312 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: dev-3\n",
            "I0410 20:09:17.598797 140202582333312 run_classifier.py:475] guid: dev-3\n",
            "INFO:tensorflow:tokens: [CLS] 네트 ##웍 ##연 ##결 ##안 ##된 ##다 ##고 자꾸 ##뜨 ##는 ##데 데이터 ##켜 ##놓 ##고 [UNK] 이것 ##만 ##안 ##되 ##네요 계속 왜 ##자 ##꾸 ##안 ##틀 ##어지 ##죠 [SEP]\n",
            "I0410 20:09:17.598912 140202582333312 run_classifier.py:477] tokens: [CLS] 네트 ##웍 ##연 ##결 ##안 ##된 ##다 ##고 자꾸 ##뜨 ##는 ##데 데이터 ##켜 ##놓 ##고 [UNK] 이것 ##만 ##안 ##되 ##네요 계속 왜 ##자 ##꾸 ##안 ##틀 ##어지 ##죠 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 32995 45665 2600 8509 2838 32283 3305 1590 6957 20411 12333 6029 2266 12997 20109 1590 100 3133 2582 2838 32143 35405 646 1407 1082 23230 2838 11299 12174 32059 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.599058 140202582333312 run_classifier.py:478] input_ids: 101 32995 45665 2600 8509 2838 32283 3305 1590 6957 20411 12333 6029 2266 12997 20109 1590 100 3133 2582 2838 32143 35405 646 1407 1082 23230 2838 11299 12174 32059 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.599218 140202582333312 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.599363 140202582333312 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0410 20:09:17.599457 140202582333312 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0410 20:09:17.600269 140202582333312 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: dev-4\n",
            "I0410 20:09:17.600408 140202582333312 run_classifier.py:475] guid: dev-4\n",
            "INFO:tensorflow:tokens: [CLS] [UNK] 이게 ##뭐 ##임 ##? ##? 무료 ##도 이거 ##보 ##단 ##낫 ##겟 ##네 삭제 ##하 ##고 다시 ##깔 ##아 ##도 [UNK] [UNK] 고치 ##든 ##지 [UNK] 확 ##바 ##꿔 ##버릴 ##까 ##부 ##다 [SEP]\n",
            "I0410 20:09:17.600533 140202582333312 run_classifier.py:477] tokens: [CLS] [UNK] 이게 ##뭐 ##임 ##? ##? 무료 ##도 이거 ##보 ##단 ##낫 ##겟 ##네 삭제 ##하 ##고 다시 ##깔 ##아 ##도 [UNK] [UNK] 고치 ##든 ##지 [UNK] 확 ##바 ##꿔 ##버릴 ##까 ##부 ##다 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 100 5682 47539 4720 20689 20689 1563 1701 15081 2649 2556 46230 45443 5428 1873 2283 1590 458 36671 2532 1701 100 100 12663 5815 1161 100 9211 3202 36654 35945 22970 1494 3305 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.600690 140202582333312 run_classifier.py:478] input_ids: 101 100 5682 47539 4720 20689 20689 1563 1701 15081 2649 2556 46230 45443 5428 1873 2283 1590 458 36671 2532 1701 100 100 12663 5815 1161 100 9211 3202 36654 35945 22970 1494 3305 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.600860 140202582333312 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:09:17.601001 140202582333312 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0410 20:09:17.601090 140202582333312 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:***** Running evaluation *****\n",
            "I0410 20:09:18.222711 140202582333312 run_classifier.py:885] ***** Running evaluation *****\n",
            "INFO:tensorflow:  Num examples = 1636\n",
            "I0410 20:09:18.222983 140202582333312 run_classifier.py:886]   Num examples = 1636\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I0410 20:09:18.223124 140202582333312 run_classifier.py:887]   Batch size = 8\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0410 20:09:18.304512 140202582333312 estimator.py:1145] Calling model_fn.\n",
            "INFO:tensorflow:Running eval on CPU\n",
            "I0410 20:09:18.304864 140202582333312 tpu_estimator.py:2965] Running eval on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0410 20:09:18.305354 140202582333312 run_classifier.py:635] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "I0410 20:09:18.305557 140202582333312 run_classifier.py:637]   name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "I0410 20:09:18.305706 140202582333312 run_classifier.py:637]   name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "I0410 20:09:18.305830 140202582333312 run_classifier.py:637]   name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "I0410 20:09:18.305963 140202582333312 run_classifier.py:637]   name = segment_ids, shape = (?, 128)\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83356a8fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83356a8fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:18.511844 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83356a8fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83356a8fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8325633e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8325633e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:18.621022 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8325633e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8325633e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316c0e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316c0e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:18.724434 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316c0e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316c0e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256337d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256337d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:18.870585 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256337d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256337d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8325633bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8325633bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:18.996261 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8325633bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8325633bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fc890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fc890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:19.108227 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fc890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fc890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256335d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256335d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:19.253510 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256335d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256335d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256335d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256335d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:19.354703 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256335d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256335d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83307d2710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83307d2710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:19.494987 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83307d2710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83307d2710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8325633910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8325633910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:19.630652 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8325633910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8325633910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:19.768061 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fe510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fe510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:19.875292 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fe510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fe510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330778310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330778310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:20.007269 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330778310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330778310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83307e9b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83307e9b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:20.107432 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83307e9b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83307e9b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83307e9b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83307e9b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:20.207706 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83307e9b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83307e9b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308a2550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308a2550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:20.343001 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308a2550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308a2550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fe210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fe210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:20.467751 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fe210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fe210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:20.576498 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330e99410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330e99410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:20.714411 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330e99410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330e99410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256338d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256338d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:20.826719 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256338d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256338d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833069bbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833069bbd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:20.933424 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833069bbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833069bbd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308e7dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308e7dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:21.072165 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308e7dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308e7dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:21.192099 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fe890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fe890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:21.303413 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fe890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308fe890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330cea510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330cea510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:21.438673 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330cea510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330cea510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330cea510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330cea510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:21.544550 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330cea510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330cea510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833308ce90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833308ce90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:21.653923 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833308ce90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833308ce90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330686950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330686950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:21.781579 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330686950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330686950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330480610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330480610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:21.921697 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330480610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330480610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:22.036810 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83308b1690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330246610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330246610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:22.177661 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330246610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330246610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330246610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330246610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:22.286447 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330246610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330246610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83302bc850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83302bc850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:22.387430 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83302bc850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83302bc850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83254f3dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83254f3dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:22.525754 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83254f3dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83254f3dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330593d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330593d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:22.643026 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330593d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330593d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832551be90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832551be90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:22.754257 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832551be90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832551be90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253527d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253527d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:22.891349 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253527d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253527d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253527d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253527d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:22.990951 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253527d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253527d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253527d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253527d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:23.106467 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253527d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253527d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253ece50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253ece50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:23.237227 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253ece50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253ece50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330593d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330593d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:23.372252 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330593d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330593d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832551be90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832551be90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:23.486148 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832551be90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832551be90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832528c990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832528c990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:23.610409 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832528c990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832528c990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832535e410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832535e410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:23.728472 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832535e410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832535e410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832541c550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832541c550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:23.837785 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832541c550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832541c550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83302ec490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83302ec490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:23.972595 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83302ec490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83302ec490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330593d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330593d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:24.093049 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330593d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330593d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832551be90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832551be90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:24.202166 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832551be90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832551be90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83235b6550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83235b6550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:25.021557 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83235b6550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83235b6550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83235b6550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83235b6550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:25.122989 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83235b6550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83235b6550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83235b6550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83235b6550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:25.224335 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83235b6550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83235b6550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83302ec710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83302ec710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:25.357708 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83302ec710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83302ec710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832523e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832523e310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:25.479882 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832523e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832523e310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253f9110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253f9110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:25.596153 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253f9110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83253f9110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83310063d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83310063d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:25.723827 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83310063d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83310063d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83304b9b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83304b9b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:25.824241 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83304b9b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83304b9b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83304b9b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83304b9b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:25.955870 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83304b9b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83304b9b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330895ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330895ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:26.087663 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330895ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330895ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832523e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832523e310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:26.224869 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832523e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832523e310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833059e950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833059e950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:26.330322 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833059e950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833059e950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332cbc710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332cbc710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:26.457507 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332cbc710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332cbc710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833136e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833136e550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:26.570651 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833136e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833136e550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833136e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833136e550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:26.680331 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833136e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833136e550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832528b390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832528b390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:26.811115 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832528b390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832528b390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832523e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832523e310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:26.949389 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832523e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832523e310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833035a250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833035a250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:27.055564 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833035a250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833035a250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d32e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d32e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:27.187976 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d32e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d32e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d32e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d32e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:27.296280 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d32e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d32e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d32e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d32e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:27.398038 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d32e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d32e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dba610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dba610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:27.538404 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dba610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dba610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332f09290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332f09290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:27.664254 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332f09290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332f09290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332bbf0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332bbf0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:27.781146 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332bbf0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332bbf0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83234f8290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83234f8290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:09:27.988008 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83234f8290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83234f8290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0410 20:09:28.789941 140202582333312 run_classifier.py:666] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (49541, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.790251 140202582333312 run_classifier.py:672]   name = bert/embeddings/word_embeddings:0, shape = (49541, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.790435 140202582333312 run_classifier.py:672]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.790575 140202582333312 run_classifier.py:672]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.790717 140202582333312 run_classifier.py:672]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.790842 140202582333312 run_classifier.py:672]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.790965 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.791095 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.791239 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.791370 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.791491 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.791621 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.791752 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.791879 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.791999 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.792145 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.792266 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.792397 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.792519 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.792647 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.792774 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.792899 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.793018 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.793157 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.793281 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.793406 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.793521 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.793643 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.793771 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.793895 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.794012 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.794142 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.794268 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.794395 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.794517 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.794645 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.794771 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.794895 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.795012 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.795153 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.795279 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.795406 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.795524 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.795649 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.795779 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.795905 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.796023 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.796154 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.796344 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.796478 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.796602 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.796739 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.796857 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.796973 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.797094 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.797235 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.797352 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.797479 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.797596 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.797724 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.797843 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.797966 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.798082 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.798218 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.798342 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.798468 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.881497 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.881831 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.882010 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.882193 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.882359 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.882525 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.882688 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.882876 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.883035 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.883222 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.883382 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.883547 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.883720 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.883877 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.884034 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.884225 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.884389 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.884565 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.884736 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.884895 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.885047 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.885239 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.885394 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.885555 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.885721 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.885894 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.886053 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.886241 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.886399 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.886558 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.886728 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.886900 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.887055 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.887242 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.887407 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.887566 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.887735 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.887911 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.888072 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.888263 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.888426 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.888595 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.888764 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.888930 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.889081 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.889246 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.889404 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.889570 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.889733 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.889900 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.890054 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.890229 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.890388 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.890552 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.890715 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.890883 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.891038 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.891217 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.891373 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.891542 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.891711 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.891872 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.892033 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.892221 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.892384 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.892557 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.892724 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.892884 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.893042 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.893226 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.893381 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.893544 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.893706 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.893872 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.894023 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.894201 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.894359 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.894511 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.894665 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.894839 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.895001 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.895179 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.895338 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.895490 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.895642 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.895817 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.895971 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.896148 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.896307 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.896470 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.896622 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.896794 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.896945 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.897084 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.897223 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.897355 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.897483 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.897609 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.897737 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.897858 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.897978 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.898106 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.898238 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.898366 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.898485 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.898611 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.898741 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.898868 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.898987 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.899105 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.899239 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.899365 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.899483 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.899613 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.899738 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.899858 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.899979 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.900105 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.900235 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.900366 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.900484 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.900608 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.900733 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.900862 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.900982 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.901099 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.901233 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.901359 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.901499 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.901627 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.901755 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.901874 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.901992 140202582333312 run_classifier.py:672]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.993492 140202582333312 run_classifier.py:672]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (3, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.993947 140202582333312 run_classifier.py:672]   name = output_weights:0, shape = (3, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (3,), *INIT_FROM_CKPT*\n",
            "I0410 20:09:28.994199 140202582333312 run_classifier.py:672]   name = output_bias:0, shape = (3,), *INIT_FROM_CKPT*\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:689: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "W0410 20:09:28.996738 140202582333312 deprecation_wrapper.py:119] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:689: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "WARNING:tensorflow:From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:690: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "W0410 20:09:29.012202 140202582333312 deprecation_wrapper.py:119] From drive/Shareddrives/capstone/Elegant_Friends/practice/src/make_bert_model/run_classifier.py:690: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0410 20:09:29.026959 140202582333312 estimator.py:1147] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-04-10T20:09:29Z\n",
            "I0410 20:09:29.046441 140202582333312 evaluation.py:255] Starting evaluation at 2021-04-10T20:09:29Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0410 20:09:29.585688 140202582333312 monitored_session.py:240] Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0410 20:09:29.586987 140202582333312 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt-1227\n",
            "I0410 20:09:29.607393 140202582333312 saver.py:1280] Restoring parameters from drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt-1227\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0410 20:09:31.103230 140202582333312 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0410 20:09:31.164656 140202582333312 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2021-04-10-20:29:39\n",
            "I0410 20:29:39.548267 140202582333312 evaluation.py:275] Finished evaluation at 2021-04-10-20:29:39\n",
            "INFO:tensorflow:Saving dict for global step 1227: eval_accuracy = 0.87347186, eval_loss = 0.36318523, global_step = 1227, loss = 0.3626312\n",
            "I0410 20:29:39.548807 140202582333312 estimator.py:2039] Saving dict for global step 1227: eval_accuracy = 0.87347186, eval_loss = 0.36318523, global_step = 1227, loss = 0.3626312\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1227: drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt-1227\n",
            "I0410 20:29:40.184379 140202582333312 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1227: drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt-1227\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n",
            "I0410 20:29:40.185698 140202582333312 error_handling.py:96] evaluation_loop marked as finished\n",
            "INFO:tensorflow:***** Eval results *****\n",
            "I0410 20:29:40.186001 140202582333312 run_classifier.py:909] ***** Eval results *****\n",
            "INFO:tensorflow:  eval_accuracy = 0.87347186\n",
            "I0410 20:29:40.186099 140202582333312 run_classifier.py:911]   eval_accuracy = 0.87347186\n",
            "INFO:tensorflow:  eval_loss = 0.36318523\n",
            "I0410 20:29:40.189065 140202582333312 run_classifier.py:911]   eval_loss = 0.36318523\n",
            "INFO:tensorflow:  global_step = 1227\n",
            "I0410 20:29:40.189306 140202582333312 run_classifier.py:911]   global_step = 1227\n",
            "INFO:tensorflow:  loss = 0.3626312\n",
            "I0410 20:29:40.189393 140202582333312 run_classifier.py:911]   loss = 0.3626312\n",
            "INFO:tensorflow:Writing example 0 of 1635\n",
            "I0410 20:29:41.063105 140202582333312 run_classifier.py:499] Writing example 0 of 1635\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0410 20:29:41.063538 140202582333312 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: test-1\n",
            "I0410 20:29:41.063641 140202582333312 run_classifier.py:475] guid: test-1\n",
            "INFO:tensorflow:tokens: [CLS] 최고 ##최고 [SEP]\n",
            "I0410 20:29:41.063721 140202582333312 run_classifier.py:477] tokens: [CLS] 최고 ##최고 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 423 42571 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.063819 140202582333312 run_classifier.py:478] input_ids: 101 423 42571 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.063910 140202582333312 run_classifier.py:479] input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.063997 140202582333312 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0410 20:29:41.064058 140202582333312 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0410 20:29:41.064947 140202582333312 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: test-2\n",
            "I0410 20:29:41.065108 140202582333312 run_classifier.py:475] guid: test-2\n",
            "INFO:tensorflow:tokens: [CLS] [UNK] 갑자기 [UNK] 삭제 ##했 ##다 ##가 다시 ##깔 ##아 ##도 안 ##되 ##는 ##데 왜 ##이 ##럴 ##까 ##요 [SEP]\n",
            "I0410 20:29:41.065229 140202582333312 run_classifier.py:477] tokens: [CLS] [UNK] 갑자기 [UNK] 삭제 ##했 ##다 ##가 다시 ##깔 ##아 ##도 안 ##되 ##는 ##데 왜 ##이 ##럴 ##까 ##요 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 100 2690 100 1873 8051 3305 1952 458 36671 2532 1701 273 32143 12333 6029 1407 1291 15505 22970 5721 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.065337 140202582333312 run_classifier.py:478] input_ids: 101 100 2690 100 1873 8051 3305 1952 458 36671 2532 1701 273 32143 12333 6029 1407 1291 15505 22970 5721 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.065429 140202582333312 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.065517 140202582333312 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0410 20:29:41.065576 140202582333312 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0410 20:29:41.066291 140202582333312 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: test-3\n",
            "I0410 20:29:41.066415 140202582333312 run_classifier.py:475] guid: test-3\n",
            "INFO:tensorflow:tokens: [CLS] 이것 ##들 미쳤 ##네 [UNK] 왕좌 ##의 ##게임 원래 6 ##편 ##까 ##진 무료 ##였 ##었 ##는 ##데 업 ##뎃 ##하면 ##서 다 막 ##아 ##놨 ##어 [UNK] 이럴 ##려 ##고 업 ##뎃 ##했 ##냐 ##? [SEP]\n",
            "I0410 20:29:41.066493 140202582333312 run_classifier.py:477] tokens: [CLS] 이것 ##들 미쳤 ##네 [UNK] 왕좌 ##의 ##게임 원래 6 ##편 ##까 ##진 무료 ##였 ##었 ##는 ##데 업 ##뎃 ##하면 ##서 다 막 ##아 ##놨 ##어 [UNK] 이럴 ##려 ##고 업 ##뎃 ##했 ##냐 ##? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 3133 4496 5227 5428 100 16261 4386 13511 3430 195 5920 22970 1663 1563 6240 18398 12333 6029 8196 45857 22194 2003 107 800 2532 26996 2479 100 11404 4250 1590 8196 45857 8051 14603 20689 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.066593 140202582333312 run_classifier.py:478] input_ids: 101 3133 4496 5227 5428 100 16261 4386 13511 3430 195 5920 22970 1663 1563 6240 18398 12333 6029 8196 45857 22194 2003 107 800 2532 26996 2479 100 11404 4250 1590 8196 45857 8051 14603 20689 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.066691 140202582333312 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.066779 140202582333312 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0410 20:29:41.066838 140202582333312 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0410 20:29:41.067360 140202582333312 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: test-4\n",
            "I0410 20:29:41.067464 140202582333312 run_classifier.py:475] guid: test-4\n",
            "INFO:tensorflow:tokens: [CLS] 끊겨 ##서 도저히 볼 ##수 ##가 없 ##네 [UNK] 폰 ##이 문제 ##가 통신사 ##가 문제 ##가 .. ##성 ##질 ##나 ##서 안 ##봄 [SEP]\n",
            "I0410 20:29:41.067536 140202582333312 run_classifier.py:477] tokens: [CLS] 끊겨 ##서 도저히 볼 ##수 ##가 없 ##네 [UNK] 폰 ##이 문제 ##가 통신사 ##가 문제 ##가 .. ##성 ##질 ##나 ##서 안 ##봄 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 16000 2003 9595 577 1606 1952 181 5428 100 4373 1291 290 1952 5917 1952 290 1952 5488 2089 5426 2353 2003 273 20189 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.067628 140202582333312 run_classifier.py:478] input_ids: 101 16000 2003 9595 577 1606 1952 181 5428 100 4373 1291 290 1952 5917 1952 290 1952 5488 2089 5426 2353 2003 273 20189 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.067727 140202582333312 run_classifier.py:479] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.067814 140202582333312 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0410 20:29:41.067873 140202582333312 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0410 20:29:41.068223 140202582333312 run_classifier.py:474] *** Example ***\n",
            "INFO:tensorflow:guid: test-5\n",
            "I0410 20:29:41.068307 140202582333312 run_classifier.py:475] guid: test-5\n",
            "INFO:tensorflow:tokens: [CLS] Good [SEP]\n",
            "I0410 20:29:41.068370 140202582333312 run_classifier.py:477] tokens: [CLS] Good [SEP]\n",
            "INFO:tensorflow:input_ids: 101 12844 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.068453 140202582333312 run_classifier.py:478] input_ids: 101 12844 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.068540 140202582333312 run_classifier.py:479] input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0410 20:29:41.068624 140202582333312 run_classifier.py:480] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "I0410 20:29:41.068691 140202582333312 run_classifier.py:481] label: 0 (id = 0)\n",
            "INFO:tensorflow:***** Running prediction*****\n",
            "I0410 20:29:41.695809 140202582333312 run_classifier.py:921] ***** Running prediction*****\n",
            "INFO:tensorflow:  Num examples = 1635\n",
            "I0410 20:29:41.696466 140202582333312 run_classifier.py:922]   Num examples = 1635\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I0410 20:29:41.696631 140202582333312 run_classifier.py:923]   Batch size = 8\n",
            "INFO:tensorflow:***** Predict results *****\n",
            "I0410 20:29:41.696944 140202582333312 run_classifier.py:941] ***** Predict results *****\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0410 20:29:41.741583 140202582333312 estimator.py:1145] Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "I0410 20:29:41.741907 140202582333312 tpu_estimator.py:2965] Running infer on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0410 20:29:41.742354 140202582333312 run_classifier.py:635] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "I0410 20:29:41.742548 140202582333312 run_classifier.py:637]   name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "I0410 20:29:41.742691 140202582333312 run_classifier.py:637]   name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "I0410 20:29:41.742830 140202582333312 run_classifier.py:637]   name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "I0410 20:29:41.742960 140202582333312 run_classifier.py:637]   name = segment_ids, shape = (?, 128)\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b0e6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b0e6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:41.970185 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b0e6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b0e6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b0e6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b0e6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:42.117854 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b0e6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b0e6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b0e6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b0e6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:42.225774 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b0e6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b0e6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316ee9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316ee9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:42.350208 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316ee9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316ee9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:42.483318 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:42.590610 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331524d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331524d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:42.714945 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331524d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331524d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316d9290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316d9290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:42.826853 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316d9290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316d9290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316d9290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316d9290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:42.926146 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316d9290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316d9290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316dd490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316dd490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:43.048909 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316dd490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316dd490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:43.452539 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:43.562366 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316dded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316dded0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:43.687773 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316dded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316dded0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316dded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316dded0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:43.796734 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316dded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83316dded0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83358f5950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83358f5950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:43.896786 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83358f5950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83358f5950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b08750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b08750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:44.022047 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b08750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b08750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:44.156158 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:44.267584 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83313d32d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83313d32d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:44.391198 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83313d32d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83313d32d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83313d32d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83313d32d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:44.504358 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83313d32d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83313d32d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83313d32d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83313d32d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:44.615820 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83313d32d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83313d32d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331705650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331705650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:44.747462 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331705650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331705650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331552990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331552990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:44.878322 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331552990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331552990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:44.984144 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8333051b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8333051b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:45.121487 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8333051b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8333051b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332c2c8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332c2c8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:45.249369 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332c2c8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332c2c8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83356a8fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83356a8fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:45.349099 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83356a8fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83356a8fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833ed1b950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833ed1b950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:45.496270 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833ed1b950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833ed1b950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:45.625890 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:45.749958 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332cf80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332cf80d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:45.879992 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332cf80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332cf80d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332cf80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332cf80d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:45.981462 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332cf80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332cf80d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8333106c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8333106c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:46.096102 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8333106c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8333106c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dda350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dda350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:46.230115 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dda350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dda350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:46.361591 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:46.473449 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256244d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256244d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:46.596353 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256244d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83256244d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d322d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d322d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:46.709822 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d322d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d322d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d322d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d322d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:46.814350 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d322d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d322d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332f6d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332f6d550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:46.941271 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332f6d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332f6d550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:47.088484 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e81f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e81f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:47.221579 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e81f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e81f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dcee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dcee90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:47.358815 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dcee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dcee90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332bffc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332bffc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:47.466786 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332bffc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332bffc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332bffc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332bffc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:47.570200 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332bffc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332bffc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83330c89d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83330c89d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:47.708534 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83330c89d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83330c89d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dda350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dda350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:47.974674 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dda350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dda350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:48.087530 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833317ee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833317ee90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:48.214710 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833317ee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833317ee90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d69090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d69090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:48.330610 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d69090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332d69090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330dc8510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330dc8510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:48.432884 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330dc8510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330dc8510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83234e1750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83234e1750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:48.569782 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83234e1750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83234e1750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833306f950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833306f950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:48.691011 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833306f950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f833306f950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dda350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dda350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:48.800615 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dda350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332dda350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332e5090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332e5090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:48.938047 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332e5090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332e5090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332e5090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332e5090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:49.048367 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332e5090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332e5090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332e5090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332e5090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:49.153339 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332e5090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332e5090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330dbdd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330dbdd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:49.301532 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330dbdd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330dbdd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332a1850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332a1850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:49.432776 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332a1850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332a1850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:49.552621 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b85c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83314eae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83314eae10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:49.686410 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83314eae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83314eae10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83314eae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83314eae10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:49.791095 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83314eae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83314eae10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83314eae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83314eae10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:49.908078 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83314eae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83314eae10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330dbdd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330dbdd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:50.036164 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330dbdd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8330dbdd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331f3c6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331f3c6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:50.165423 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331f3c6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331f3c6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332a1850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332a1850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:50.288565 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332a1850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332a1850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e6ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e6ff90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:50.417913 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e6ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e6ff90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e6ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e6ff90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:50.532189 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e6ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e6ff90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e6ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e6ff90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:50.635647 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e6ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332e6ff90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8329de1390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8329de1390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:50.760585 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8329de1390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8329de1390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332adf5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332adf5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:50.896358 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332adf5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8332adf5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332a1910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332a1910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:51.008306 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332a1910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83332a1910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b62d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b62d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0410 20:29:51.209841 140202582333312 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b62d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8331b62d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0410 20:29:52.025541 140202582333312 run_classifier.py:666] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (49541, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.025866 140202582333312 run_classifier.py:672]   name = bert/embeddings/word_embeddings:0, shape = (49541, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.026065 140202582333312 run_classifier.py:672]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.026335 140202582333312 run_classifier.py:672]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.026478 140202582333312 run_classifier.py:672]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.026615 140202582333312 run_classifier.py:672]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.026741 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.026875 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.027006 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.027162 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.027289 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.027417 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.027539 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.027671 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.027793 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.027913 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.028049 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.028207 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.028331 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.028465 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.028599 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.028720 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.028841 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.028975 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.029106 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.029249 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.029370 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.029493 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.029611 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.029740 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.029859 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.029976 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.030099 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.030249 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.030641 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.030803 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.030935 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.031074 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.031225 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.031372 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.031512 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.031658 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.031789 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.031929 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.032167 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.032320 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.032453 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.032579 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.032705 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.032838 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.032959 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.033099 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.033243 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.033370 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.033489 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.033618 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.033739 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.033868 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.033994 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.034148 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.034292 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.034431 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.034568 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.034706 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.034839 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.034985 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.035159 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.035330 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.035489 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.035633 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.035784 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.035951 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.036121 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.036306 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.036469 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.036641 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.036799 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.036966 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.037156 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.037320 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.037480 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.037653 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.037806 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.037966 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.038146 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.038305 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.038460 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.038631 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.038788 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.038956 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.039125 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.039313 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.039476 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.039650 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.039797 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.039921 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.040070 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.040242 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.040404 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.040569 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.040722 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.040874 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.041040 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.041219 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.041369 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.041533 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.041690 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.041853 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.042021 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.042219 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.042377 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.042539 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.042696 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.042888 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.043051 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.043235 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.043397 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.043562 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.043716 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.043878 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.044044 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.044233 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.044399 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.044725 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.044955 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.045182 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.045382 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.045553 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.045722 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.045897 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.046059 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.046255 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.046424 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.046594 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.046769 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.046939 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.047119 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.047334 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.047504 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.047696 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.047857 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.048028 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.048204 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.048370 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.048531 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.048712 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.048871 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.049039 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.049218 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.049366 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.049500 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.049643 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.049767 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.050213 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.050362 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.050497 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.050637 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.050769 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.050897 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.051030 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.051165 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.051299 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.051423 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.051553 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.051675 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.051803 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.051925 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.052065 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.052206 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.052338 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.052462 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.052593 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.052719 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.052848 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.052972 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.053105 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.053237 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.053371 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.053497 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.053637 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.053765 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.053893 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.054022 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.054166 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.054288 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.054418 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.054542 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.054671 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.054791 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.054929 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.055057 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.055195 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.055316 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.055442 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.055572 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.055718 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.055840 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.055958 140202582333312 run_classifier.py:672]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.056091 140202582333312 run_classifier.py:672]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.148245 140202582333312 run_classifier.py:672]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (3, 768), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.148610 140202582333312 run_classifier.py:672]   name = output_weights:0, shape = (3, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (3,), *INIT_FROM_CKPT*\n",
            "I0410 20:29:52.148826 140202582333312 run_classifier.py:672]   name = output_bias:0, shape = (3,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0410 20:29:52.149532 140202582333312 estimator.py:1147] Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0410 20:29:52.703507 140202582333312 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt-1227\n",
            "I0410 20:29:52.707817 140202582333312 saver.py:1280] Restoring parameters from drive/Shareddrives/capstone/Elegant_Friends/practice/rsc/lgup_output_3_new/model.ckpt-1227\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0410 20:29:53.905319 140202582333312 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0410 20:29:53.959816 140202582333312 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0410 20:50:01.010859 140202582333312 error_handling.py:96] prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0410 20:50:01.011173 140202582333312 error_handling.py:96] prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}